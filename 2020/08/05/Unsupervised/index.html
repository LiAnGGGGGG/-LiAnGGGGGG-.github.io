<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/L.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/L.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"liangggggg.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="无监督学习在“无监督学习”中，训练样本的标记信息时未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础 1 聚类算法1.1 K-means   关键概念：簇与质心    KMeans算法将一组N个样本的特征矩阵X划分为K个无交集的簇，直观上来看是簇是一组一组聚集在一起的数据，在一个簇中的数据就认为是同一类。簇就是聚类的结果表现。簇中所有数据的均值\mu_j">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记（七）无监督学习">
<meta property="og:url" content="https://liangggggg.github.io/2020/08/05/Unsupervised/index.html">
<meta property="og:site_name" content="LiAnG&#39;s Blog">
<meta property="og:description" content="无监督学习在“无监督学习”中，训练样本的标记信息时未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础 1 聚类算法1.1 K-means   关键概念：簇与质心    KMeans算法将一组N个样本的特征矩阵X划分为K个无交集的簇，直观上来看是簇是一组一组聚集在一起的数据，在一个簇中的数据就认为是同一类。簇就是聚类的结果表现。簇中所有数据的均值\mu_j">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/32020546C1AE4109A10AF82CB9898E86?method=download&shareKey=cd5356c9150e5202cc049f0c226a91c2">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/3CFC7255AEF5494EA28847EF8F53B986?method=download&shareKey=d0ab0fa0be730535ee659da645a0ca7d">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/77CEBDB3B8164208AF15C9BF40488424?method=download&shareKey=012cf4c589db2cea9df552ad9aa29fe7">
<meta property="article:published_time" content="2020-08-05T01:47:42.000Z">
<meta property="article:modified_time" content="2020-08-11T07:28:30.723Z">
<meta property="article:author" content="LiAnG">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://note.youdao.com/yws/api/personal/file/32020546C1AE4109A10AF82CB9898E86?method=download&shareKey=cd5356c9150e5202cc049f0c226a91c2">

<link rel="canonical" href="https://liangggggg.github.io/2020/08/05/Unsupervised/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习笔记（七）无监督学习 | LiAnG's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="LiAnG's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">LiAnG's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay hungry, stay foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liangggggg.github.io/2020/08/05/Unsupervised/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/timg.jpg">
      <meta itemprop="name" content="LiAnG">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiAnG's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习笔记（七）无监督学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-05 09:47:42" itemprop="dateCreated datePublished" datetime="2020-08-05T09:47:42+08:00">2020-08-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-11 15:28:30" itemprop="dateModified" datetime="2020-08-11T15:28:30+08:00">2020-08-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/08/05/Unsupervised/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/08/05/Unsupervised/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>在“无监督学习”中，训练样本的标记信息时未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础</p>
<h3 id="1-聚类算法"><a href="#1-聚类算法" class="headerlink" title="1 聚类算法"></a>1 聚类算法</h3><h4 id="1-1-K-means"><a href="#1-1-K-means" class="headerlink" title="1.1 K-means"></a>1.1 K-means</h4><table>
<thead>
<tr>
<th align="left">关键概念：簇与质心</th>
</tr>
</thead>
<tbody><tr>
<td align="left">KMeans算法将一组N个样本的特征矩阵X划分为K个无交集的簇，直观上来看是簇是一组一组聚集在一起的数据，在一个簇中的数据就认为是同一类。簇就是聚类的结果表现。簇中所有数据的均值\mu_j通常被称为这个簇的“质心”（centroids）。在一个二维平面中，一簇数据点的质心的横坐标就是这一簇数据点的横坐标的均值，质心的纵坐标就是这一簇数据点的纵坐标的均值。同理可推广至高维空间。</td>
</tr>
<tr>
<td align="left"><a id="more"></a></td>
</tr>
</tbody></table>
<p>K-means具体步骤如下：</p>
<ol>
<li>随机抽取K个样本作为最初的质心</li>
<li>开始循坏：<ul>
<li>将每个样本点分配到离他们最近的质心，生成K个簇</li>
<li>对于每个簇，计算所有被分到该簇的样本点的平均值作为新的质心</li>
</ul>
</li>
<li>当质心的位置不再发生变化，迭代停止，聚类完成</li>
</ol>
<p><img src="https://note.youdao.com/yws/api/personal/file/32020546C1AE4109A10AF82CB9898E86?method=download&shareKey=cd5356c9150e5202cc049f0c226a91c2" alt></p>
<p>令$x$表示簇找那个的一个样本点，$mu$表示簇中的质心，$n$表示每个样本点钟的特征数目，$i$表示成点$x$的每个特征，则该样本点到质心的距离可以由一下距离来度量</p>
<p>$$欧几里得距离：d(x,\mu)=\sqrt{\sum_{i=1}^n(x_i-\mu_i)^2}$$</p>
<p>$$欧几里得距离：d(x,\mu)=\sum_{i=1}^n(|x_i-\mu_i|)$$</p>
<p>$$余弦距离：cos\theta = \frac{\sum_1^n(x_i * \mu)}{\sqrt{\sum_1^n(x_i)^2} * \sqrt{\sum_1^n(\mu)^2}}$$</p>
<p>如果我们采用欧几里得距离，则一个簇中所有样本点到质心的距离平方和为</p>
<p>$$Cluster Sum of Square (CSS) = \sum_{j=0}^n\sum_{i=1}^n(x_i-u_i)^2$$<br>$$Total Cluster Sum of Square = \sum_{l=1}^k CSS_l$$</p>
<p>其中,$m$为一个簇中样本的个数，$j$是每个样本的编号。将整个数据集中的所有簇的簇内平方和相加，就得到了整体平方和（Total Cluster Sum of Square），KMeans追求的是能让整体平方和最小的质心</p>
<h4 id="1-2-DBSCAN"><a href="#1-2-DBSCAN" class="headerlink" title="1.2 DBSCAN"></a>1.2 DBSCAN</h4><p>DBSCAN基于“领域”参数（$\epsilon,MinPts$）来刻画样本分布的紧密程度</p>
<p>|关键概念|<br>|:–|:–|<br>|$\epsilon-$领域|样本集中$x_j$的距离不大于$\epsilon$的样本|<br>|核心对象|若$x_j$的$\epsilon-$领域至少包含MinPts个样本|<br>|密度直达|若$x_j$位于$\epsilon-$领域中，且$x_j$是核心对象，则称$x_j,x_i$密度直达|<br>|密度可达|对$x_i,x_j$存在样本序列$p_1,p_2,\dots,p_n$，其中$p_1=x_i,p_n=x_j$且$p_{i+1}$由$p_i$密度直达|<br>|密度相连|$x_i,x_j$存在$x_k$使得$x_i,x_j$由$x_k$密度可达|</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/3CFC7255AEF5494EA28847EF8F53B986?method=download&shareKey=d0ab0fa0be730535ee659da645a0ca7d" alt></p>
<p>DBSCAN具体步骤如下：</p>
<p>1.找寻核心点形成临时聚类簇</p>
<p>扫描全部样本点，如果某个样本点R半径范围内点数目大于等于MinPoints，则将其纳入核心点列表，并将其密度直达的点形成对应的临时聚类簇</p>
<p>2.合并临时聚类簇得到聚类簇</p>
<p>对于每一个临时聚类簇，检测其中的点是否为核心点，如果是，将该点对应的临时聚类簇和当前临时聚类簇合并，得到新的临时聚类簇</p>
<p>重复此操作，直到当前临时聚类簇的每一个点要么不在核心点列表，要么密度直达的点都已经在该临时聚类簇，该临时聚类簇升级成为聚类簇</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/77CEBDB3B8164208AF15C9BF40488424?method=download&shareKey=012cf4c589db2cea9df552ad9aa29fe7" alt></p>
<h4 id="1-3-层次聚类AGNES"><a href="#1-3-层次聚类AGNES" class="headerlink" title="1.3 层次聚类AGNES"></a>1.3 层次聚类AGNES</h4><p>AGNES是一种采用自底向上聚合策略的层次聚类算法，先将数据集中的每个样本看做一个初始聚类簇，然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并，该过程不断重复，直到达到预设的簇类簇个数</p>
<p>关键是如何计算簇类簇之间的距离，实际上，每个簇是一个样本集合，因此，只需采用关于集合的某种距离即可，给定聚类簇$c_i,c_j$通过下面式子来计算距离：</p>
<p>$$最小距离：d_{min}(c_i,c_j)=\min_{x\in c_i,z\in c_j}dist(x,z)$$<br>$$最大距离：d_{max}(c_i,c_j)=\max_{x\in c_i,z\in c_j}dist(x,z)$$<br>$$平均距离：d_{avg}(c_i,c_j)=\frac{1}{|c_i||c_j|}\sum_{x\in c_i}\sum_{z\in c_j}dist(x,z)$$</p>
<h3 id="2-降维算法"><a href="#2-降维算法" class="headerlink" title="2 降维算法"></a>2 降维算法</h3><h4 id="2-1-PCA所需数学原理"><a href="#2-1-PCA所需数学原理" class="headerlink" title="2.1 PCA所需数学原理"></a>2.1 PCA所需数学原理</h4><p>主成份分析，简称为PCA，是一种非监督学习算法，经常被用来进行</p>
<ul>
<li><p>数据降维</p>
</li>
<li><p>有损数据压缩</p>
</li>
<li><p>特征抽取</p>
</li>
<li><p>数据可视化</p>
</li>
</ul>
<p>通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。</p>
<p>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：</p>
<ul>
<li>基于特征值分解协方差矩阵实现PCA算法</li>
<li>基于SVD分解协方差矩阵实现PCA算法。</li>
</ul>
<h5 id="2-1-1-特征值、特征向量、特征值分解"><a href="#2-1-1-特征值、特征向量、特征值分解" class="headerlink" title="2.1.1 特征值、特征向量、特征值分解"></a>2.1.1 特征值、特征向量、特征值分解</h5><p>1.特征值、特征向量</p>
<p>如果一个向量v是矩阵A的特征向量，将一定可以表示成下面的形式：<br>$$Av=\lambda v$$<br>其中，$\lambda$是特征向量$v$对应的特征值，一个矩阵的一组特征向量是一组正交向量</p>
<p>2.特征值分解</p>
<p>对于矩阵A，有一组特征向量v，将这组向量进行正交单位化，就能得到一组正交单位向量。特征值分解，就是将矩阵A分解为如下式：<br>$$A=Q\Sigma Q^{-1}$$<br>其中，Q是矩阵A的特征向量组成的矩阵，$\Sigma$则是一个对角阵，对角线上的元素就是特征值。我们来分析一下特征值分解的式子，分解得到的$\Sigma$矩阵是一个对角阵，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变换方向（从主要的变化到次要的变化排列）</p>
<p>当矩阵是高维的情况下，那么这个矩阵就是高维空间下的一个线性变换，这个线性变换可能没法通过图片来表示，但是可以想象，这个变换也同样有很多的变化方向，我们通过特征值分解得到的钱N个特征向量，就对应了这个矩阵最重要的N个变化方向。我们利用这前N个变化方向，就可以近似这个矩阵变换，也就是之前说的：<strong>提取这个矩阵最重要的特征</strong>。</p>
<p><strong>总结</strong>：特征值分解可以得到特征值与特征向量，特征值表示的是这个特征到底有多么重要，而特征向量表示这个特征是什么，可以将每一个特征向量理解为一个线性的子空间，我们可以利用这些线性的子空间干很多事情。不过，<strong>特征值分解也有很多局限，比如说变换的矩阵必须是方阵。</strong></p>
<h5 id="2-1-2-SVD分解"><a href="#2-1-2-SVD分解" class="headerlink" title="2.1.2 SVD分解"></a>2.1.2 SVD分解</h5><p>1.特征值分解矩阵的缺点</p>
<p>我们前面讲了很多特征值、特征向量和特征值分解，而且基于我们以前学习的线性代数知识、利用特征值分解提取特征矩阵是一个容易理解并且便于实现的方法。但是为什么还存在奇异值分解呢？特征值分解最大的问题是只能针对方阵，即$n*n$的矩阵，而在实际的应用中，我们分解的大部分都不是方阵。</p>
<p><strong>举个例子：</strong><br>关系型数据库中的某一张表的数据存储结构类似于一个二维矩阵，假设这个表有m行，有n个字段，那么这个表数据矩阵规模就是$m*n$。很明显，在绝大部分情况下，m和n是不相等的。如果这个时候要对这个矩阵进行特征提取，特征值分解的方法明显就不行了。此时，就可以用SVD对非方阵进行分解。</p>
<p>2.奇异值分解</p>
<p>奇异值分解是一个能使用与任意矩阵的一种分解方式，对于任意矩阵A总是存在一个奇异值分解：</p>
<p>$$A=U\Sigma V^T$$</p>
<p>假设A是一个$m * n$的矩阵，那么得到的U是一个$m * m$的方阵，U里面的正交向量被称为左奇异向量。$\Sigma$是一个$m*n$的矩阵，<br>$\Sigma$除了对角线其他元素都为0，对角线上的元素称为奇异值。</p>
<p><strong>思考：</strong>虽说上面奇异值分解等式成立，但是如何求得左奇异值向量、右奇异值向量和奇异值呢？<br><strong>答案：</strong>由上面的奇异值分解等式，我们是不知道如何拆分矩阵A的。我们可以把奇异值和特征值联系起来。<br>首先，我们用矩阵A的转置乘以A，得到一个方阵，用这样的方阵进行特征分解，得到的特征值和特征向量满足下面的等式：<br>$$(A^TA)v_i=\lambda_iv_i$$<br>这里的$v_i$就是我们要求的右奇异向量。<br>其次，我们将A和A的转置做矩阵的乘法，得到一个方阵，用这样的方阵进行特征分解，得到的特征和特征向量满足下面的等式：<br>$$(AA^T)u_i=\lambda_iu_i$$<br>这里的$u_i$就是左奇异向量。<br><strong>思考：</strong>上面我们说$A^TA$的特征向量组成的矩阵是我们SVD中的V矩阵，而$AA^T$的特征向量组成的就是我们SVD的U矩阵，这有什么根据么？我们来证明一下，以V举证的证明为例：<br>$$A=U\Sigma V^T\Rightarrow A^T=V\Sigma^TU^T\Rightarrow A^TA=V\Sigma^TU^TU\Sigma V^T=V\Sigma^2V^T$$</p>
<p>上式证明中使用了$U^TU=I,\Sigma^T\Sigma=\Sigma^2$,可以看出，$A^TA$的特征向量组成的矩阵就是我们SVD中的V矩阵，而$AA^T$的特征向量组成的就是我们SVD中的U矩阵。</p>
<p><strong>补充定义：</strong><br>$$U\in M_n(R)满足U^TU=I，则U是实正交矩阵$$<br>此外，我们还可以得到奇异值，奇异值求法有两种：</p>
<p><strong>a)第一种：</strong><br>$$A=U\Sigma V^T\Rightarrow AV\Rightarrow U\Sigma V^TV\Rightarrow AV = U\Sigma\Rightarrow Av_i=\sigma u_i\Rightarrow \sigma_i=\frac{Av_i}{u_i}$$</p>
<p><strong>b)第二种</strong> </p>
<p>通过上面的证明，我们还可以看出，特征值举证等于奇异值矩阵的平方，也就是说特征值和奇异值满足如下关系：<br>$$\sigma_i=\sqrt{\lambda_i}$$<br>这里的$\sigma_i$就是奇异值，奇异值$\sigma_i$跟特征值类似，在矩阵$\Sigma$中也是从大到小排列。</p>
<p><strong>思考：</strong><br>我们已经知道如何用奇异值分解任何矩阵了，那么问题又来了，一个m<em>n的矩阵A，你把它分解成m</em>m的矩阵U、m<em>n的矩阵$\Sigma$和n</em>n的矩阵$V^T$</p>
<p>这三个矩阵中任何一个的维度似乎一点也不比A的维度小，而且还要做两次矩阵的乘法，这不是把简单的事情变得更加复杂了吗？</p>
<p><strong>答案：</strong><br>在奇异值分解矩阵中$\Sigma$里面的奇异值按从大到小的顺序排列，奇异值$\sigma_i$从大到小的顺序减小的特别快。<strong>在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上，也就是说，剩下的90%甚至99%的奇异值几乎没有什么作用。</strong>因此，我们可以用前面r个打的奇异值来近似描述矩阵，于是奇异值分解公式可以写成如下：</p>
<p>$$A_{m * n}\approx U_{m * n}\Sigma_{r * r}V_{r * n}^T$$</p>
<p>其中r是一个远远小于m和n的数，右边的三个举证相乘的结果会将使一个接近A的矩阵。如果r越接近于n，则相乘的结果越接近于A。如果r的取值远远小于n，从计算机内存的角度来说，右边三个矩阵的存储内存要远远小于矩阵A的。<strong>所以在奇异值分解中r的取值很重要，就是在计算精度和事件空间之间做选择。</strong></p>
<h5 id="2-1-3-协方差和散度矩阵"><a href="#2-1-3-协方差和散度矩阵" class="headerlink" title="2.1.3 协方差和散度矩阵"></a>2.1.3 协方差和散度矩阵</h5><p><strong>样本均值：</strong></p>
<p>$$\bar x = \frac{1}{n}\sum_{i=1}^Nx_i$$</p>
<p><strong>样本方差：</strong><br>$$S^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar x)^2$$</p>
<p><strong>样本X和样本Y的协方差</strong></p>
<p>$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)$$</p>
<p>由上面的公式，我们可以得到以下结论：</p>
<p>（1）方差的计算公式是针对一维特征，即针对同一特征不同样本的取值来进行计算得到；而协方差则必须要求至少满足二维特征；方差是协方差的特殊情况。</p>
<p>（2）方差和协方差的除数是n-1，这是为了得到方差和协方差的无偏估计。</p>
<p>协方差为正时，说明X和Y是正相关关系；协方差为负时，说明X和Y是负相关关系；协方差为0时，说明X和Y是相互独立。Cov(X,X)就是X的方差。当样本是n维数据时，它们的协方差实际上式协方差矩阵（对称方阵）。例如，对于3维数据（x,y,z），计算它的协方差就是：</p>
<p>$$<br>Cov(X,Y,Z)=\begin{bmatrix}<br>Cov(x,x) &amp; Cov(x,y) &amp;Cov(x,z) \\<br>Cov(y,x) &amp; Cov(y,y) &amp; Cov(y,x)\\<br>Cov(z,x) &amp; Cov(z,x) &amp; Cov(z,z)<br>\end{bmatrix}<br>$$</p>
<p><strong>散度矩阵定义为：</strong><br>$$S=\sum_{k=1}^n(x_k-m)(x_k-m)^T$$</p>
<p>$$m=\frac{1}{n}\sum_{k=1}^nx_k$$</p>
<p>对于数据X的<strong>散度矩阵为：</strong>$$XX^T$$</p>
<p>其实协方差矩阵和三都矩阵关系密切，散度矩阵就是协方差矩阵乘以（总数据量-1）。因此它们的特征值和特征向量是一样的。这里值得注意的是，散度矩阵是SVD奇异值分解的一步，因此PCA和SVD是由很大联系的。</p>
<h4 id="2-2-PCA算法两种实现方法"><a href="#2-2-PCA算法两种实现方法" class="headerlink" title="2.2 PCA算法两种实现方法"></a>2.2 PCA算法两种实现方法</h4><h5 id="2-2-1-基于特征值分解协方差矩阵实现PCA算法"><a href="#2-2-1-基于特征值分解协方差矩阵实现PCA算法" class="headerlink" title="2.2.1 基于特征值分解协方差矩阵实现PCA算法"></a>2.2.1 基于特征值分解协方差矩阵实现PCA算法</h5><p>输入数据集：<br>$$X={x_1,x_2,x_3,\dots,x_n}$$</p>
<p>需要降到K维</p>
<ol>
<li><p>去平均值（即去中心化），即每一位特征减去各自的平均值</p>
</li>
<li><p>计算协方差矩阵$$\frac{1}{n}XX^T$$</p>
<p> 注：这里除或不除n或n-1，其实对求出的特征向量没有影响。</p>
</li>
<li><p>用特征值分解方法求协方差矩阵</p>
<p> $$\frac{1}{n}XX^T$$的特征值与特征向量。</p>
</li>
<li><p>对特征值从大到小排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P。</p>
</li>
<li><p>将数据转换到k个特征向量构建的新空间中，即Y=PX。</p>
</li>
</ol>
<h5 id="2-2-2-基于SVD分解协方差矩阵实现PCA算法"><a href="#2-2-2-基于SVD分解协方差矩阵实现PCA算法" class="headerlink" title="2.2.2 基于SVD分解协方差矩阵实现PCA算法"></a>2.2.2 基于SVD分解协方差矩阵实现PCA算法</h5><p>输入数据集：<br>$$X={x_1,x_2,x_3,\dots,x_n}$$</p>
<p>需要降到K维</p>
<ol>
<li><p>去平均值（即去中心化），即每一位特征减去各自的平均值</p>
</li>
<li><p>计算协方差矩阵$$\frac{1}{n}XX^T$$</p>
<p> 注：这里除或不除n或n-1，其实对求出的特征向量没有影响。</p>
</li>
<li><p>用SVD计算协方差矩阵</p>
<p> $$\frac{1}{n}XX^T$$的特征值与特征向量。</p>
</li>
<li><p>对特征值从大到小排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P。</p>
</li>
<li><p>将数据转换到k个特征向量构建的新空间中，即Y=PX。</p>
<p> 在PCA降维中，我们需要找到样本协方差矩阵$XX^T$的最大K个特征向量，然后用这个最大的K个特征向量组成的矩阵来做低维投影降维。</p>
<p> 当样本数多、样本特征数也多的时候，这个计算还是很大的。</p>
</li>
</ol>
<p><strong>当我们用SVD分解协方差矩阵的时候SVD有两个好处：</strong></p>
<ol>
<li>有一些SVD的实现算法可以先不求出协方差矩阵$XX^T$也能求出我们的右奇异矩阵V。也就是说，我们的PCA算法可以不用做特征分解而是通过SVD来完成，这个方法在样本量很大的时候很有效。实际上，scikit-learn的PCA算法的背后真正的实现就是用的SVD，而不是特征值分解。</li>
</ol>
<ol start="2">
<li>注意到PCA仅仅使用了我们SVD的左奇异矩阵，没有使用到右奇异值矩阵，那么右奇异值矩阵有什么用呢？假设我们的样本是$m * n$的矩阵X，如果我们通过SVD找到了矩阵$X^TX$最大的k个特征向量组成的$k * n$的矩阵$V^T$,可以得到一个$m * k$的矩阵$X^{‘}$,这个矩阵和我们原来$m * n$的矩阵X相比，列数从n减到了K,可见对列数进行了压缩，也就是说，左奇异矩阵可以用于对行数的压缩；右奇异矩阵可以用于对列（即特征维度）的压缩。这就是我们用SVD分解协方差矩阵实现PCA可以得到两个方向的PCA降维（即行和列两个方向）</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/03/Bayes/" rel="prev" title="机器学习笔记（六）朴素贝叶斯">
      <i class="fa fa-chevron-left"></i> 机器学习笔记（六）朴素贝叶斯
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/09/Feat/" rel="next" title="机器学习笔记（八）数据预处理与特征工程">
      机器学习笔记（八）数据预处理与特征工程 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#无监督学习"><span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-聚类算法"><span class="nav-text">1 聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-K-means"><span class="nav-text">1.1 K-means</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-DBSCAN"><span class="nav-text">1.2 DBSCAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-层次聚类AGNES"><span class="nav-text">1.3 层次聚类AGNES</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-降维算法"><span class="nav-text">2 降维算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-PCA所需数学原理"><span class="nav-text">2.1 PCA所需数学原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-特征值、特征向量、特征值分解"><span class="nav-text">2.1.1 特征值、特征向量、特征值分解</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-SVD分解"><span class="nav-text">2.1.2 SVD分解</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-3-协方差和散度矩阵"><span class="nav-text">2.1.3 协方差和散度矩阵</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-PCA算法两种实现方法"><span class="nav-text">2.2 PCA算法两种实现方法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-1-基于特征值分解协方差矩阵实现PCA算法"><span class="nav-text">2.2.1 基于特征值分解协方差矩阵实现PCA算法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-2-基于SVD分解协方差矩阵实现PCA算法"><span class="nav-text">2.2.2 基于SVD分解协方差矩阵实现PCA算法</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiAnG"
      src="/images/timg.jpg">
  <p class="site-author-name" itemprop="name">LiAnG</p>
  <div class="site-description" itemprop="description">Stay hungry, stay foolish</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/LiAnGGGGGG" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;LiAnGGGGGG" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1318457129@qq.com" title="E-Mail → mailto:1318457129@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="rss → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>rss</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script
  async
  src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"
></script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiAnG</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">132k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:01</span>
</div>
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("05/30/2020 13:14:21");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <script src="/js/src/wobblewindow.js"></script>
  <script>
    //只在桌面版网页启用特效
    if (window.innerWidth > 768) {
      $(document).ready(function () {
        
        // 根据类名获取，而不是id
        $('.header').wobbleWindow({
          radius: 50,
          movementTop: false,
          movementLeft: false,
          movementRight: false,
          debug: false,
        });
        

        
         // 根据类名获取，而不是id
        $('.sidebar').wobbleWindow({
          radius: 50,
          movementLeft: false,
          movementTop: false,
          movementBottom: false,
          position: 'fixed',
          debug: false,
        });
        

        
         // 根据类名获取，而不是id
        $('.footer').wobbleWindow({
          radius: 50,
          movementBottom: false,
          movementLeft: false,
          movementRight: false,
          
          position: 'absolute',
          debug: false,
        });
        
      });
    }
  </script>


 
<script>
  var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });
</script>






  <script async src="/js/cursor/fireworks.js"></script>



<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rueYojQYHpaShC9b3zwCTcgt-gzGzoHsz',
      appKey     : 'SuFkJxmzL9eehU2FBrkopQlJ',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>


</body>
</html>
