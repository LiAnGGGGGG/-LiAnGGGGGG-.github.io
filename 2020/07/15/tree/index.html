<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/L.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/L.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"liangggggg.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="决策树1 决策树原理1.1 决策树是如何工作的决策树（Decision Tree）是一种非常参数的有监督学习方法，它能够从一系列有特征和标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，在解决各种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记（一）决策树">
<meta property="og:url" content="https://liangggggg.github.io/2020/07/15/tree/index.html">
<meta property="og:site_name" content="LiAnG&#39;s Blog">
<meta property="og:description" content="决策树1 决策树原理1.1 决策树是如何工作的决策树（Decision Tree）是一种非常参数的有监督学习方法，它能够从一系列有特征和标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，在解决各种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-07-15T08:04:19.000Z">
<meta property="article:modified_time" content="2020-07-22T01:50:00.743Z">
<meta property="article:author" content="LiAnG">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://liangggggg.github.io/2020/07/15/tree/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习笔记（一）决策树 | LiAnG's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="LiAnG's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">LiAnG's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay hungry, stay foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liangggggg.github.io/2020/07/15/tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/timg.jpg">
      <meta itemprop="name" content="LiAnG">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiAnG's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习笔记（一）决策树
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-15 16:04:19" itemprop="dateCreated datePublished" datetime="2020-07-15T16:04:19+08:00">2020-07-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-22 09:50:00" itemprop="dateModified" datetime="2020-07-22T09:50:00+08:00">2020-07-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/07/15/tree/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/07/15/tree/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="1-决策树原理"><a href="#1-决策树原理" class="headerlink" title="1 决策树原理"></a>1 决策树原理</h2><h3 id="1-1-决策树是如何工作的"><a href="#1-1-决策树是如何工作的" class="headerlink" title="1.1 决策树是如何工作的"></a>1.1 决策树是如何工作的</h3><p>决策树（Decision Tree）是一种非常参数的有监督学习方法，它能够从一系列有特征和标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，在解决各种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。</p>
<a id="more"></a>

<p><strong>决策树算法的核心是要解决两个问题：</strong><br>1）如何从数据表中找出最佳结点和最佳分枝<br>2）如何让决策树停止生长，防止过拟合？</p>
<p>几乎所有决策树有关的模型调整方法，都围绕这两个问题展开。</p>
<h3 id="1-2-构建决策树"><a href="#1-2-构建决策树" class="headerlink" title="1.2 构建决策树"></a>1.2 构建决策树</h3><p>原则上讲，任意一个数据集上的所有特征都可以被拿来分枝，特征上的任意结点又可以自由组合，所以一个数据集上可以发展处非常多测决策树，其数量可达指数级。但在这些树中，总有那么一棵树比其他的树分类效力都好，那样的树叫做“全局最优树”。</p>
<table>
<thead>
<tr>
<th align="left">关键概念：全局最优，局部最优</th>
</tr>
</thead>
<tbody><tr>
<td align="left">全局最优：经过组合形成的，整体来说分类效果最好的模型</td>
</tr>
<tr>
<td align="left">局部最优：每一次分枝的时候都向着更好的分类效果分枝，但无法确认如此生成的树在全局上是否是最优的</td>
</tr>
</tbody></table>
<p>要在这么多决策树中去一次性找到分类效果最佳的那一棵是不可能的，如果通过排列组合来进行筛选，计算量过于大而低效。<br>因此，机器学习研究者们开发了一些有效的算法，能够在合理的时间内构造出具有一定准确率的次最优决策树。这些算法基本都执行“贪心策略”，即通过局部最优来达到接近全局最优的结果</p>
<table>
<thead>
<tr>
<th align="left">关键概念：贪心算法</th>
</tr>
</thead>
<tbody><tr>
<td align="left">通过实现局部最优来达到接近全局最优结果的算法，所有的树模型都是这样的算法</td>
</tr>
</tbody></table>
<h3 id="1-2-1-ID3算法构建决策树"><a href="#1-2-1-ID3算法构建决策树" class="headerlink" title="1.2.1 ID3算法构建决策树"></a>1.2.1 ID3算法构建决策树</h3><p>ID3算法原型为J.R Quinlan的博士论文，是基础理论较为完善，使用较为广泛的决策树模型，并在此基础上优化退出了C4.5和C5.0决策树算法，后两者已经成为最流行的决策树算法。</p>
<p>决策树需要找出最佳节点和最佳的分枝方法，而衡量这个“最佳”的指标叫做“不纯度”。<br>不纯度基于叶子节点来计算的，所以树中的每个节点都会有一个不纯度，并且子节点的不纯度一定是低于父节点的。</p>
<table>
<thead>
<tr>
<th align="left">关键概念：不纯度</th>
</tr>
</thead>
<tbody><tr>
<td align="left">如果有某一类标签占有较大的比例，我们就说叶子节点“纯”，分枝分得好。若各类标签都很平均，则说明叶子节点“不纯”</td>
</tr>
</tbody></table>
<h4 id="怎样计算不纯度？"><a href="#怎样计算不纯度？" class="headerlink" title="怎样计算不纯度？"></a>怎样计算不纯度？</h4><p>对于节点不纯度的计算和表示方法因决策树模型而异，但不管不纯度的度量方法如何，都是由误差率衍生而来，其计算公式如下：<br>$$Classification error(t) = 1-\max_{i=1}[p(i|t)]$$</p>
<p>误差率越低，则纯度越高。由此还衍生出了其他两个常用指标，一个是ID3重的Information gain（信息增益）的计算方法可用Entropy推导，即最为人熟知的信息熵，又叫香农熵，其计算公式如下：<br>$$Entropy(t)=-\sum^{c-1}_{i=0}p(i|t)\log_2p(i|t)$$</p>
<p>其中c表示叶子节点上标签类别的个数，c-1表示标签的索引</p>
<p><strong>从第0类标签开始计算，设定$\log_20=0$</strong></p>
<p>另一个指标则是<strong>Gini（基尼）指数</strong>，主要用于CART决策树的纯度判定中，其计算公式如下：<br>$$Gini = 1-\sum_{i=0}^{c-1}[p(i|t)]^2$$</p>
<p>决策树最终的优化目标是使得叶节点的总不纯度最低。因此ID3决策树在觉得是否对某节点进性切分的时候，会尽可能选取使得该节点对应的子节点信息熵最小的特征进行切分，换而言之，就是要求父节点信息熵和子节点总信息熵之差要最大，对ID3而言，二者之差就是信息增益。</p>
<p><strong>一个父节点下可能有多个子节点，所以信息增益为父节点信息熵-所有子节点信息熵的加权平均</strong></p>
<p>$$I(child) = \sum_{j=1}^k\frac{N(v_j)}{N}I(v_j)$$</p>
<p>而父节点和子节点的不纯度下降数可由下属公式进行计算：<br>$$\Delta = I(parent)-I(child)$$</p>
<p>$I(.)$是给定节点的不纯性度量，$N$是父节点上的样本树，$k$是这一层上子节点的个数，$N(v_j)$是与子节点$v_j$相关联的子样本个数</p>
<p>决策树算法会选择最大化增益的条件，因为对任何分枝过程来说，$I(parent)$都是一个不变的值，所以最大化增益等价于最小化子节点的不纯性衡量的加权平均。</p>
<h3 id="1-2-3-ID3的局限性"><a href="#1-2-3-ID3的局限性" class="headerlink" title="1.2.3 ID3的局限性"></a>1.2.3 ID3的局限性</h3><p>ID3局限性主要源于局部最优化条件，即信息增益的计算方法，其局限性主要有以下几点：</p>
<ul>
<li>分支度越高（分类水平越多）离散变量往往子节点的总信息熵会更小，ID3是按照某一列进行切分，在极限情况下取ID作为切分字段，每个分类的纯度都是100%，因此这样的分类方式是没有效益的</li>
<li>不能直接处理连续型变量，若使用ID3处理连续型变量，则首先需要对连续型变量进行离散化</li>
<li>对缺失值比较敏感，使用ID3之前需要提前对缺失值进行处理</li>
<li>没有剪枝的设置，容易导致过拟合，即在训练集上表现很好，测试集上表现很差</li>
</ul>
<h3 id="1-3-C4-5算法-amp-CART算法"><a href="#1-3-C4-5算法-amp-CART算法" class="headerlink" title="1.3 C4.5算法 &amp; CART算法"></a>1.3 C4.5算法 &amp; CART算法</h3><h3 id="1-3-1-修改局部最优化条件"><a href="#1-3-1-修改局部最优化条件" class="headerlink" title="1.3.1 修改局部最优化条件"></a>1.3.1 修改局部最优化条件</h3><p>在C4.5中，首先通过引入分支度（IV:Information Value）概念，对信息增益的计算方法进行修正。</p>
<p>将信息熵计算公式中的$p(i|t)$（<strong>即某类别样例占总样例数</strong>）改成了$P(v_i)$，即<strong>某子节点的总样本数占父节点总样本数的比例</strong></p>
<p>$$Information Value = -\sum_{i=1}^kP(v_i)\log_2P(v_i)$$</p>
<p>其中，$i$表示父节点的第$i$个子节点，$v_i$表示第$i$个子节点样例数，$P(v_i)$表示第$i$个子节点拥有样例数占父节点总样例数的比例。</p>
<p>最终，在C4.5中，使用之前的信息增益除以分支度作为选取切分字段的参考指标，该指标被称作Gain Ratio(增益率)，计算公式如下：<br>$$Gain Ratio = \frac{Information Gain}{Information Value}$$</p>
<p>本质是信息增益最大，分支度又比较小的列（也就是纯度提升很快，但又不是靠着把类别分特别细来提升的那些特征）</p>
<h3 id="1-3-2-连续变量处理手段"><a href="#1-3-2-连续变量处理手段" class="headerlink" title="1.3.2 连续变量处理手段"></a>1.3.2 连续变量处理手段</h3><p>在C4.5中，同样还增加了针对连续变量的处理手段。如果输入特征字段是连续型变量，则有下列步骤：</p>
<ol>
<li>算法首先会对这一列数进行从小到大排序</li>
<li>选取相邻的两个数的中间数作为切分数据集的备选点，若一个连续变量有N个值，则在C4.5的处理过程中将产生N-1个备选切点，并且每个切分点都代表着一种二叉树的切分方案</li>
</ol>
<p>因此在对于包含连续变量的数据集进行树模型构建的过程中要消耗更多的运算资源。但与此同时，我们也会发现，当连续变量的某中间点参与到决策树的二分过程中，往往代表该店对于最终分类结果有较大影响，这也为我们连续变量的分箱压缩提供了指导性的意见。也是最重要的模型指导分箱方法。</p>
<p>CART树本质其实和C4.5区别不大，只不过CART树所有的层都是二叉树</p>
<ol>
<li>首先特征从小到大一次排列</li>
<li>计算两两相邻的均值</li>
<li>按均值所在的点，对连续型变量进行二分，二分得到的点交做决策树的“树桩”</li>
<li>找每种二分切分方案的获益比例，获益比例最大的切分点，就是切点</li>
<li>切完之后，计算加权信息熵，计算信息增益，引入分支度，计算增益比例</li>
</ol>
<hr>
<h2 id="2-sklearn中的决策树"><a href="#2-sklearn中的决策树" class="headerlink" title="2 sklearn中的决策树"></a>2 sklearn中的决策树</h2><ul>
<li>模块sklearn.tree</li>
</ul>
<p>模块总共包含五个类：</p>
<table>
<thead>
<tr>
<th align="left">tree.DecisionTreeClassifier</th>
<th align="left">分类树</th>
</tr>
</thead>
<tbody><tr>
<td align="left">tree.DecisionTreeRegressor</td>
<td align="left">回归树</td>
</tr>
<tr>
<td align="left">tree.export_graphviz</td>
<td align="left">将生成的决策树导出为DOT格式</td>
</tr>
<tr>
<td align="left">tree.ExtraTreeClassifier</td>
<td align="left">高随机版本的分类树</td>
</tr>
<tr>
<td align="left">tree.ExtraTreeRegressor</td>
<td align="left">高随机版本的回归树</td>
</tr>
</tbody></table>
<h3 id="2-1-重要参数"><a href="#2-1-重要参数" class="headerlink" title="2.1 重要参数"></a>2.1 重要参数</h3><h3 id="2-2-1-criterion"><a href="#2-2-1-criterion" class="headerlink" title="2.2.1 criterion"></a>2.2.1 criterion</h3><p>这个参数用来决定不纯度的计算方法</p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">criterion</th>
</tr>
</thead>
<tbody><tr>
<td align="left">如何影响模型?</td>
<td align="left">确定不纯度的计算方法，帮忙找出最佳节点和最佳分枝，不纯度越低，决策树对训练集 的拟合越好</td>
</tr>
<tr>
<td align="left">可能的输入有哪些？</td>
<td align="left">不填默认基尼系数，填写gini使用基尼系数，填写entropy使用信息增益</td>
</tr>
<tr>
<td align="left">怎样选取参数？</td>
<td align="left">通常使用基尼系数</td>
</tr>
</tbody></table>
<h3 id="2-2-2-random-state-amp-splitter"><a href="#2-2-2-random-state-amp-splitter" class="headerlink" title="2.2.2 random_state &amp; splitter"></a>2.2.2 random_state &amp; splitter</h3><ul>
<li><p>random_state 用来设置分枝中的随机模式的参数，默认None，在高维度时随机性会表现更明显，低维度的数据（比如鸢尾花数据集），随机性几乎不会显现。输入任意整数，会一直长出同一棵树，让模型稳定下来。</p>
</li>
<li><p>splitter 也是用来控制决策树中的随机选项的，有两种输入值，输入”best”，决策树在分枝时虽然随机，但是还是会优先选择更重要的特征进行分枝（重要性可以通过属性feature_importances_查看），输入“random”，决策树在分枝时会更加随机，树会因为含有更多的不必要信息而更深更大，并因这些不必要信息而降低对训练集的拟合。这也是防止过拟合的一种方式。当你预测到你的模型会过拟合，用这两个参数来帮助你降低树建成之后过拟合的可能性。当然，树一旦建成，我们依然是使用剪枝参数来防止过拟合。</p>
</li>
</ul>
<h3 id="2-2-3-剪枝参数"><a href="#2-2-3-剪枝参数" class="headerlink" title="2.2.3 剪枝参数"></a>2.2.3 剪枝参数</h3><ul>
<li><p>max_depth 限制树的最大深度，超过设定深度的树枝全部剪掉这是用得最广泛的剪枝参数，在高维度低样本量时非常有效。决策树多生长一层，对样本量的需求会增加一倍，所  以限制树深度能够有效地限制过拟合。在集成算法中也非常实用。实际使用时，建议从=3开始尝试，看看拟合的效  果再决定是否增加设定深度。</p>
</li>
<li><p>min_samples_leaf 限定，一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本，否则分  枝就不会发生，或者，分枝会朝着满足每个子节点都包含min_samples_leaf个样本的方向去发生。一般搭配max_depth使用，在回归树中有神奇的效果，可以让模型变得更加平滑。这个参数的数量设置得太小会引起过拟合，设置得太大就会阻止模型学习数据。一般来说，建议从=5开始使用。如果叶节点中含有的样本量变化很 大，建议输入浮点数作为样本量的百分比来使用。同时，这个参数可以保证每个叶子的最小尺寸，可以在回归问题  中避免低方差，过拟合的叶子节点出现。对于类别不多的分类问题，=1通常就是最佳选择。</p>
</li>
<li><p>min_samples_split 限定，一个节点必须要包含至少min_samples_split个训练样本，这个节点才允许被分枝，否则  分枝就不会发生。</p>
</li>
<li><p>max_features 限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃。和max_depth异曲同工， max_features是用来限制高维度数据的过拟合的剪枝参数，但其方法比较暴力，是直接限制可以使用的特征数量而强行使决策树停下的参数，在不知道决策树中的各个特征的重要性的情况下，强行设定这个参数可能会导致模型学习不足。如果希望通过降维的方式防止过拟合，建议使用PCA，ICA或者特征选择模块中的降维算法。</p>
</li>
<li><p>min_impurity_decrease 限制信息增益的大小，信息增益小于设定数值的分枝不会发生。这是在0.19版本中更新的    功能，在0.19版本之前时使用min_impurity_split。</p>
</li>
</ul>
<h3 id="2-2-4-目标权重参数"><a href="#2-2-4-目标权重参数" class="headerlink" title="2.2.4 目标权重参数"></a>2.2.4 目标权重参数</h3><ul>
<li><p>class_weight 完成样本标签平衡的参数。样本不平衡是指在一组数据集中，标签的一类天生占有很大的比例。因此我们要使用class_weight参数对样本标签进行一定的均衡，给少量的标签更多的权重，让模型更偏向少数类，向捕获少数类的方向建模。该参数默认None，此模式表示自动给  与数据集中的所有标签相同的权重。</p>
</li>
<li><p>min_weight_fraction_leaf 有了权重之后，样本量就不再是单纯地记录数目，而是受输入的权重影响了，因此这时候剪枝，就需要搭配min_ weight_fraction_leaf这个基于权重的剪枝参数来使用。另请注意，基于权重的剪枝参数（例如min_weight_ fraction_leaf）将比不知道样本权重的标准（比如min_samples_leaf）更少偏向主导类。如果样本是加权的，则使用基于权重的预修剪标准来更容易优化树结构，这确保叶节点至少包含样本权重的总和的一小部分。</p>
</li>
</ul>
<h2 id="3-决策树的优缺点"><a href="#3-决策树的优缺点" class="headerlink" title="3 决策树的优缺点"></a>3 决策树的优缺点</h2><h3 id="3-1-决策树优点"><a href="#3-1-决策树优点" class="headerlink" title="3.1 决策树优点"></a>3.1 决策树优点</h3><ol>
<li>易于理解和解释，因为树木可以画出来被看见</li>
<li>需要很少的数据准备。其他很多算法通常都需要数据规范化，需要创建虚拟变量并删除空值等。但请注意，sklearn中的决策树模块不支持对缺失值的处理。</li>
<li>使用树的成本（比如说，在预测数据的时候）是用于训练树的数据点的数量的对数，相比于其他算法，这是一个很低的成本。</li>
<li>能够同时处理数字和分类数据，既可以做回归又可以做分类。其他技术通常专门用于分析仅具有一种变量类型的数据集。</li>
<li>能够处理多输出问题，即含有多个标签的问题，注意与一个标签中含有多种标签分类的问题区别开</li>
<li>是一个白盒模型，结果很容易能够被解释。如果在模型中可以观察到给定的情况，则可以通过布尔逻辑轻松解释条件。相反，在黑盒模型中（例如，在人工神经网络中），结果可能更难以解释。</li>
<li>可以使用统计测试验证模型，这让我们可以考虑模型的可靠性。</li>
<li>即使其假设在某种程度上违反了生成数据的真实模型，也能够表现良好。</li>
</ol>
<h3 id="3-2-决策树的缺点"><a href="#3-2-决策树的缺点" class="headerlink" title="3.2 决策树的缺点"></a>3.2 决策树的缺点</h3><ol>
<li>决策树学习者可能创建过于复杂的树，这些树不能很好地推广数据。这称为过度拟合。修剪，设置叶节点所需的最小样本数或设置树的最大深度等机制是避免此问题所必需的，而这些参数的整合和调整对初学者来说会比较晦涩</li>
<li>决策树可能不稳定，数据中微小的变化可能导致生成完全不同的树，这个问题需要通过集成算法来解决。</li>
<li>决策树的学习是基于贪婪算法，它靠优化局部最优（每个节点的最优）来试图达到整体的最优，但这种做法不能保证返回全局最优决策树。这个问题也可以由集成算法来解决，在随机森林中，特征和样本会在分枝过程中被随机采样。</li>
<li>有些概念很难学习，因为决策树不容易表达它们，例如XOR，奇偶校验或多路复用器问题。</li>
<li>如果标签中的某些类占主导地位，决策树学习者会创建偏向主导类的树。因此，建议在拟合决策树之前平衡数据集。</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/07/15/xingce/" rel="prev" title="行测笔记：判断推理（一）图形推理">
      <i class="fa fa-chevron-left"></i> 行测笔记：判断推理（一）图形推理
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/07/16/svm/" rel="next" title="机器学习笔记（二）支持向量机（SVM）">
      机器学习笔记（二）支持向量机（SVM） <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树"><span class="nav-text">决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-决策树原理"><span class="nav-text">1 决策树原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-决策树是如何工作的"><span class="nav-text">1.1 决策树是如何工作的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-构建决策树"><span class="nav-text">1.2 构建决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-1-ID3算法构建决策树"><span class="nav-text">1.2.1 ID3算法构建决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#怎样计算不纯度？"><span class="nav-text">怎样计算不纯度？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-3-ID3的局限性"><span class="nav-text">1.2.3 ID3的局限性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-C4-5算法-amp-CART算法"><span class="nav-text">1.3 C4.5算法 &amp; CART算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-1-修改局部最优化条件"><span class="nav-text">1.3.1 修改局部最优化条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-2-连续变量处理手段"><span class="nav-text">1.3.2 连续变量处理手段</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-sklearn中的决策树"><span class="nav-text">2 sklearn中的决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-重要参数"><span class="nav-text">2.1 重要参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-criterion"><span class="nav-text">2.2.1 criterion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-random-state-amp-splitter"><span class="nav-text">2.2.2 random_state &amp; splitter</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-3-剪枝参数"><span class="nav-text">2.2.3 剪枝参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-4-目标权重参数"><span class="nav-text">2.2.4 目标权重参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-决策树的优缺点"><span class="nav-text">3 决策树的优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-决策树优点"><span class="nav-text">3.1 决策树优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-决策树的缺点"><span class="nav-text">3.2 决策树的缺点</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiAnG"
      src="/images/timg.jpg">
  <p class="site-author-name" itemprop="name">LiAnG</p>
  <div class="site-description" itemprop="description">Stay hungry, stay foolish</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/LiAnGGGGGG" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;LiAnGGGGGG" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1318457129@qq.com" title="E-Mail → mailto:1318457129@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="rss → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>rss</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script
  async
  src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"
></script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiAnG</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">132k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:01</span>
</div>
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("05/30/2020 13:14:21");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <script src="/js/src/wobblewindow.js"></script>
  <script>
    //只在桌面版网页启用特效
    if (window.innerWidth > 768) {
      $(document).ready(function () {
        
        // 根据类名获取，而不是id
        $('.header').wobbleWindow({
          radius: 50,
          movementTop: false,
          movementLeft: false,
          movementRight: false,
          debug: false,
        });
        

        
         // 根据类名获取，而不是id
        $('.sidebar').wobbleWindow({
          radius: 50,
          movementLeft: false,
          movementTop: false,
          movementBottom: false,
          position: 'fixed',
          debug: false,
        });
        

        
         // 根据类名获取，而不是id
        $('.footer').wobbleWindow({
          radius: 50,
          movementBottom: false,
          movementLeft: false,
          movementRight: false,
          
          position: 'absolute',
          debug: false,
        });
        
      });
    }
  </script>


 
<script>
  var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });
</script>






  <script async src="/js/cursor/fireworks.js"></script>



<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rueYojQYHpaShC9b3zwCTcgt-gzGzoHsz',
      appKey     : 'SuFkJxmzL9eehU2FBrkopQlJ',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>


</body>
</html>
