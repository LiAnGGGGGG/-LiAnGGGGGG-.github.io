<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LiAnG&#39;s Blog</title>
  
  <subtitle>Stay hungry, stay foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liangggggg.github.io/"/>
  <updated>2020-08-20T11:18:39.169Z</updated>
  <id>https://liangggggg.github.io/</id>
  
  <author>
    <name>LiAnG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据结构总结（六）：排序</title>
    <link href="https://liangggggg.github.io/2020/08/18/Data6/"/>
    <id>https://liangggggg.github.io/2020/08/18/Data6/</id>
    <published>2020-08-18T01:12:59.000Z</published>
    <updated>2020-08-20T11:18:39.169Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-插入排序"><a href="#1-插入排序" class="headerlink" title="1 插入排序"></a>1 插入排序</h1><h2 id="1-1-直接插入排序"><a href="#1-1-直接插入排序" class="headerlink" title="1.1 直接插入排序"></a>1.1 直接插入排序</h2><p>逐个向有序表中进行插入操作</p><p>初始关键字序列：  [7]    4    -2    19    13    6    ；<br>第一趟排序后：    [4    7]    -2    19    13    6    ；<br>第二趟排序后：    [-2    4    7]    19    13    6    ；<br>第三趟排序后：    [-2    4    7    19]    13    6    ；<br>第四趟排序后：    [-2    4    7    13    19]    6    ；<br>第五趟排序后：    [-2    4    6    7    13    19]    ；</p><a id="more"></a><p><img src="https://note.youdao.com/yws/api/personal/file/FF99682334F14D6C8BDC28A7D301BB17?method=download&shareKey=18c14c8e31ea2e76032d125fea69224f" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">void straight_insert_sort(Sqlist *L)</span><br><span class="line">&#123;int i，j ；</span><br><span class="line">for (i&#x3D;2；i&lt;&#x3D;L-&gt;length；i++)</span><br><span class="line">&#123;L-&gt;R[0]&#x3D;L-&gt;R[i]；j&#x3D;i-1；&#x2F;*设置哨兵*&#x2F; </span><br><span class="line">while(L-&gt;R[0].key&lt; L-&gt;R[j].key )</span><br><span class="line">&#123;L-&gt;R[j+1]&#x3D;L-&gt;R[j]；</span><br><span class="line">j--；</span><br><span class="line">&#125;&#x2F;*查找插入位置*&#x2F;</span><br><span class="line">L-&gt;R[j+1]&#x3D;L-&gt;R[0]；&#x2F;*插入到相应位置*&#x2F;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>python实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def insertionSort(arr):</span><br><span class="line">for i in range(len(arr)):</span><br><span class="line">preIndex &#x3D; i-1</span><br><span class="line">current &#x3D; arr[i]</span><br><span class="line">while preIndex &gt;&#x3D;0 and arr[preIndex]&gt;current:</span><br><span class="line">arr[preIndex+1] &#x3D; arr[preIndex]</span><br><span class="line">preIndex-&#x3D;1</span><br><span class="line">arr[preIndex+1] &#x3D; current</span><br><span class="line">return arr</span><br></pre></td></tr></table></figure><p>性能分析：</p><p>（1）空间效率：仅用了一个辅助单元，空间复杂度为$O(1)$</p><p>（2）时间效率：向有序表逐个插入记录操作，进行了$n-1$趟，每趟操作分为比较关键码和移动记录，直接插入最好情况为$O(n)$，平均时间复杂度$O(n^2)$</p><p>（3）稳定性：稳定</p><h2 id="1-2-折半插入排序"><a href="#1-2-折半插入排序" class="headerlink" title="1.2 折半插入排序"></a>1.2 折半插入排序</h2><p>折半插入排序是利用折半查找实现在有序表$R[1,i-1]$中查找$R[i]$的插入位置</p><p>对下列序列进行排序：{30，13，70，85，39，42，6，20}，并写出排序的过程。<br>对排序表：30，13，70，85，39，42，6，20 进行划分<br>设初始状态：</p><p>第一趟排序：    (30) 13    70    85    39    42    6 20<br>第二趟排序：    (13    30)    70    85    39    42    6 20<br>第三趟排序：    (13    30    70)    85    39    42    6 20<br>第七趟排序：    (6    13    30    39    42    70    85)    20<br>第八趟排序：    (6    13    30    39    42    70    85)    20</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">void Binary_insert_sort(Sqlist *L)</span><br><span class="line">&#123;int i，j，low，high，mid ；</span><br><span class="line">for (i&#x3D;2；i&lt;&#x3D;L-&gt;length；i++)</span><br><span class="line">&#123;L-&gt;R[0]&#x3D;L-&gt;R[i]；&#x2F;* 设置哨兵*&#x2F; </span><br><span class="line">low&#x3D;1 ；high&#x3D;i-1 ；</span><br><span class="line">while (low&lt;&#x3D;high)</span><br><span class="line">&#123;mid&#x3D;（low + high）&#x2F;2</span><br><span class="line">if ( LT(L-&gt;R[0].key，L-&gt;R[mid].key))</span><br><span class="line">high&#x3D;mid-1 ；</span><br><span class="line">else</span><br><span class="line">low&#x3D;mid+1 ；</span><br><span class="line">&#125;&#x2F;*查找插入位置*&#x2F; </span><br><span class="line">for (j&#x3D;i-1；j&gt;&#x3D;high+1；j--)</span><br><span class="line">L-&gt;R[j+1]&#x3D;L-&gt;R[j]；</span><br><span class="line">L-&gt;R[high+1]&#x3D;L-&gt;R[0]；&#x2F;* 插入到相应位置 *&#x2F;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-冒泡排序"><a href="#2-冒泡排序" class="headerlink" title="2 冒泡排序"></a>2 冒泡排序</h2><p>交换排序是通过两两比较待排序记录的关键码，若发生排序要求相逆，则交换之</p><p>对下列序列排序{23，38，22，45，23，67，31，15，41}写出冒泡排序的过程。</p><p>初始关键字序列：  23    38    22    45    23    67    31    15    41；<br>第一趟排序后：    23    22    38    33    45    31    15    41    61；<br>第二趟排序后：    22    23    23    38    31    15    41    45    67；<br>第三趟排序后：    22    23    23    31    15    38    41    45    67；<br>第四趟排序后：    22    23    23    15    31    38    41    45    67；<br>第五趟排序后：    22    23    15    23    31    38    41    45    67；<br>第六趟排序后：    22    15    23    23    31    38    41    45    67；<br>第七趟排序后：    15    22    23    23    31    38    41    45    67；</p><p><img src="https://note.youdao.com/yws/api/personal/file/7761644612D44FC58115EF304F360F80?method=download&shareKey=16637b3bb70a29545e6cd6dcae641d40" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">void Bubble_Sort(Sqlist *L)</span><br><span class="line">&#123;int j，k，flag ；</span><br><span class="line">for (j&#x3D;1；j&lt;L-&gt;length；j++)&#x2F;*共有 n-1 趟排序*&#x2F;</span><br><span class="line">&#123;flag&#x3D;TRUE ；</span><br><span class="line">for (k&#x3D;1；k&lt;&#x3D;L-&gt;length-j；k++)&#x2F;*一趟排序*&#x2F; </span><br><span class="line">if( L-&gt;R[k+1].key&lt; L-&gt;R[k].key ))</span><br><span class="line">&#123;flag&#x3D;FALSE ；L-&gt;R[0]&#x3D;L-&gt;R[k] ；</span><br><span class="line">L-&gt;R[k]&#x3D;L-&gt;R[k+1] ；</span><br><span class="line">L-&gt;R[k+1]&#x3D;L-&gt;R[0] ；&#125;</span><br><span class="line">if(flag&#x3D;&#x3D;TRUE) break ；&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Python 实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def bubbleSort(arr):</span><br><span class="line">for i in range(1,len(arr)):</span><br><span class="line">for j in range(0,len(arr)-i):</span><br><span class="line">if arr[j]&gt; arr[j+1]:</span><br><span class="line">arr[j], arr[j+1] &#x3D; arr[j+1], arr[i]</span><br><span class="line">return arr</span><br></pre></td></tr></table></figure><p>性能分析：</p><p>（1）空间效率：$O(1)$</p><p>（2）时间效率：最好情况$O(n)$，平均时间复杂度为$O(n^2)$</p><p>（3）稳定性：稳定</p><h1 id="3-简单选择排序"><a href="#3-简单选择排序" class="headerlink" title="3 简单选择排序"></a>3 简单选择排序</h1><p>从无序序列$R[i..n]$的$n-i+1$记录中选出关键字最小的记录加入有序序列</p><p>对下列序列排序{49，14，38，74，96，65，49，8，55，27}；</p><p>第 1 趟之后：8    14    38    74    96    65    49    49    55    27<br>第 2 趟之后：8    14    38    74    96    65    49    49    55    27<br>（在本位就不用交换）<br>第 3 趟之后：8    14    27    74    96    65    49    49    55    38<br>第 4 趟之后：8    14    27    49    96    65    74    49    55    38</p><p><img src="https://note.youdao.com/yws/api/personal/file/6A3A3EAE3343434E8E6699BAA353F38F?method=download&shareKey=58632ab023763519c4fb1b6d1bbd7abf" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void simple_selection_sort(Sqlist *L)</span><br><span class="line">&#123;int m，n，k；</span><br><span class="line">for (m&#x3D;1；m&lt;L-&gt;length；m++)</span><br><span class="line">&#123;k&#x3D;m ；</span><br><span class="line">for(n&#x3D;m+1；n&lt;&#x3D;L-&gt;length；n++)</span><br><span class="line">if(L-&gt;R[n].key&lt; L-&gt;R[k].key)) </span><br><span class="line">k&#x3D;n ；</span><br><span class="line">if(k!&#x3D;m)&#x2F;*记录交换*&#x2F;</span><br><span class="line">&#123;L-&gt;R[0]&#x3D;L-&gt;R[m]；</span><br><span class="line">L-&gt;R[m]&#x3D;L-&gt;R[k]； </span><br><span class="line">L-&gt;R[k]&#x3D;L-&gt;R[0]；&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>python实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def selectonSort(arr):</span><br><span class="line">for i in range(len(arr)-1):</span><br><span class="line"># 记录最小数的索引</span><br><span class="line">minIndex &#x3D; i</span><br><span class="line">for j in range(i+1, len(arr)):</span><br><span class="line">if arr[j] &lt; arr[minIndex]:</span><br><span class="line">minIndex &#x3D; j</span><br><span class="line"># i 不是最小数时，将i和最小数交换</span><br><span class="line">if i !&#x3D; MinIndex:</span><br><span class="line">arr[i], arr[minIndex] &#x3D; arr[minIndex], arr[i]</span><br><span class="line"></span><br><span class="line">return arr</span><br></pre></td></tr></table></figure><p>性能分析：</p><p>（1）空间效率：$O(1)$</p><p>（2）时间效率：最好和平均时间复杂度均为$O(n^2)$</p><p>（3）稳定性：从前往后比较稳定，从后往前比较不稳定</p><h1 id="4-希尔排序"><a href="#4-希尔排序" class="headerlink" title="4 希尔排序"></a>4 希尔排序</h1><p>直接插入排序的改进版本，希尔排序把序列按一定间隔分组，对每组使用直接插入排序；随着间隔减小，一直到1，使得整个序列有序</p><p><img src="https://note.youdao.com/yws/api/personal/file/7A971CDA8CA34300AE79B58854A8067B?method=download&shareKey=a6c84b288f98376985ad2214b2179a2f" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void shell_pass(Sqlist *L，int d)</span><br><span class="line">&#x2F;*对顺序表 L 进行一趟希尔排序，增量为 d*&#x2F;</span><br><span class="line">&#123;int j，k ；</span><br><span class="line">for (j&#x3D;d+1；j&lt;&#x3D;L-&gt;length；j++)</span><br><span class="line">&#123;L-&gt;R[0]&#x3D;L-&gt;R[j] ；&#x2F;*设置监视哨兵*&#x2F; </span><br><span class="line">k&#x3D;j-d ；</span><br><span class="line">while (k&gt;0&amp;&amp;L-&gt;R[0].key&lt; L-&gt;R[k].key))</span><br><span class="line">&#123;L-&gt;R[k+d]&#x3D;L-&gt;R[k] ；</span><br><span class="line">k&#x3D;k-d ；&#125; </span><br><span class="line">L-&gt;R[k+d]&#x3D;L-&gt;R[0] ；</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>python实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def shellSort(arr):</span><br><span class="line">import math</span><br><span class="line">gap &#x3D; 1</span><br><span class="line">while(gap&lt;len(arr)&#x2F;3):</span><br><span class="line">gap &#x3D; gap*3+1</span><br><span class="line">while gap&gt;0:</span><br><span class="line">for i in range(gap, len(arr)):</span><br><span class="line">temp &#x3D; arr[i]</span><br><span class="line">j &#x3D; i-gap</span><br><span class="line">while j&gt;&#x3D;0 and arr[j] &gt; temp:</span><br><span class="line">arr[j+gap]&#x3D;arr[j]</span><br><span class="line">j-&#x3D;gap</span><br><span class="line">arr[j+gap] &#x3D; temp</span><br><span class="line">gap &#x3D; math.floor(gap&#x2F;3)</span><br><span class="line"></span><br><span class="line">return arr</span><br></pre></td></tr></table></figure><p>性能分析：</p><p>（1）空间效率：$O(1)$</p><p>（2）时间效率：依赖于步长的选取</p><p>（3）稳定性：不稳定</p><h1 id="5-快速排序"><a href="#5-快速排序" class="headerlink" title="5 快速排序"></a>5 快速排序</h1><p>以某个记录为界（该点称为支点）,将待排序列分成两部分。其中，一部分所有记录的关键码大于等于支点记录的关键码，另一部分所有记录的关键码小于支点记录的关键码，将此过程称为一次划分，对各部分不断划分，直到整个序列按关键码有序</p><p>设置指针low,high，初始值为第一个和最后一个记录的位置，设两个变量$i,j$，令$i=low，j=high$，以$R[low].key$作为基准（将$R[low]保存在R[0]$）</p><ol><li><p>从$j$所指位置向前搜索：将$R[0].key$与$R[j].key$进行比较</p><ul><li>若$R[0].key&lt;=R[j].key$：令$j=j-1$，然后继续进行比较，直到$i=j$或$R[0].key&gt;=R[j].key$为止；</li><li>若$R[0].key&gt;R[j].key$：$R[j]=R[i]$，腾出$R[j]$的位置，且令$i=i+1$;</li></ul></li><li><p>从$i$所指位置起向后搜索：将$R[0].key$与$R[i].key$进行比较：</p><ul><li>若$R[0].key&gt;=R[i].key$:令$i=i+1$，然后进行比较，直到$i=j$或$R[0].key&lt;R[i].key$为止；</li><li>若$R[0].key&lt;R[i].key$:令$R[i]=R[j]$，腾出$R[i]$的位置，且令$j=j-1$;</li></ul></li><li><p>重复1，2直至$i=j$为止，$i$就是$R[0]$所应放置的位置</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">intquick_one_pass(Sqlist*L，int low，int high)</span><br><span class="line">&#123;int i&#x3D;low，j&#x3D;high ；</span><br><span class="line">L-&gt;R[0]&#x3D;L-&gt;R[i] ；&#x2F;* R[0]作为临时单元和哨兵 *&#x2F; do</span><br><span class="line">&#123;while (L-&gt;R[0].key&lt;&#x3D; L-&gt;R[j].key&amp;&amp;(j&gt;i))</span><br><span class="line">j-- ；</span><br><span class="line">if (j&gt;i) &#123;L-&gt;R[i]&#x3D;L-&gt;R[j]  ；i++；&#125;</span><br><span class="line">while (L-&gt;R[i].key&lt;&#x3D; L-&gt;R[0].key&amp;&amp;(j&gt;i))</span><br><span class="line">i++ ；</span><br><span class="line">if (j&gt;i) &#123;L-&gt;R[j]&#x3D;L-&gt;R[i] ；j--；&#125;</span><br><span class="line">&#125; while(i!&#x3D;j)；&#x2F;*i&#x3D;j 时退出扫描*&#x2F; </span><br><span class="line">L-&gt;R[i]&#x3D;L-&gt;R[0] ；</span><br><span class="line">return(i)；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/519327C530694B5594AF6E9DFE3077DF?method=download&shareKey=7556ec6121cdbc1262ee7d150e0de45e" alt></p><p>当进行一趟快速排序后，采用相同方法分别对两个子序列快速排序，直至子序列记录个为1为止<br><img src="https://note.youdao.com/yws/api/personal/file/4A0267871158449CBE0A83CCA16D8393?method=download&shareKey=da100567e02c7e17747e6d32b1edba56" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">voidquick_Sort(Sqlist *L，int low，int high)</span><br><span class="line">&#123;int k ；</span><br><span class="line">if(low&lt;high)</span><br><span class="line">&#123;k&#x3D;quick_one_pass(L，low，high)；</span><br><span class="line">quick_Sort(L，low，k-1)； </span><br><span class="line">quick_Sort(L，k+1，high)；</span><br><span class="line">&#125; &#x2F;* 序列分为两部分后分别对每个子序列排序*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>性能分析：</p><p>（1）空间效率：$O(nlog_2n)$</p><p>（2）时间效率：最好$O(nlog_2n)$，最坏$O(n^2)$</p><p>（3）稳定性：不稳定</p><h1 id="6-堆排序"><a href="#6-堆排序" class="headerlink" title="6 堆排序"></a>6 堆排序</h1><h2 id="6-1-堆的性质"><a href="#6-1-堆的性质" class="headerlink" title="6.1 堆的性质"></a>6.1 堆的性质</h2><ol><li>堆是一棵采用顺序存储结构的完全二叉树，$k_1$是根结点</li><li>根结点是关键字序列中最小（或最大）值，分别称为小（或大）根堆</li><li>从根结点到每一叶子结点路径上的元素组成的序列都是按元素值非递减（或非递增）</li><li>堆中的任一子树也是堆</li></ol><p>利用堆顶记录的关键字最小（或最大）性质，从当前待排序的记录中依次选取关键字最小（或最大）的记录，实现对数据记录的排序，称为堆排序</p><h2 id="6-2-堆排序思想"><a href="#6-2-堆排序思想" class="headerlink" title="6.2 堆排序思想"></a>6.2 堆排序思想</h2><ol><li>对一组待排序的记录，按堆定义建堆</li><li>将堆顶记录和最后一个记录交换位置，则前$n-1$个记录是无序的，最后一个记录有序的</li><li>堆顶记录被交换后，前$n-1$个记录不再是堆，需要重新调整为一个堆，重复2操作，直到全部记录排好序</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/548842621E8D4AACAB1CD7FD7DC5DD5A?method=download&shareKey=b859872f37b596a5ded5f420bf786943" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">（1）堆调整算法实现</span><br><span class="line">void Heap_adjust(Sqlist *H，int s，int m)</span><br><span class="line">&#x2F;*H-&gt;R[s…m]中记录关键字除 H-&gt;R[s].key 均满足堆定义*&#x2F;</span><br><span class="line">&#x2F;* 调整 H-&gt;R[s]的位置使之成为小根堆 *&#x2F;</span><br><span class="line">&#123;int j&#x3D;s，k&#x3D;2*j ；&#x2F;*计算 H-&gt;R[j]的左孩子的位置*&#x2F; </span><br><span class="line">H-&gt;R[0]&#x3D;H-&gt;R[j] ；&#x2F;*临时保存 H-&gt;R[j]*&#x2F;</span><br><span class="line">for (k&#x3D;2*j；k&lt;&#x3D;m；k&#x3D;2*k)</span><br><span class="line">&#123;if ((k&lt;m)&amp;&amp;(H-&gt;R[k+1].key&lt; H-&gt;R[k].key))</span><br><span class="line">k++ ；&#x2F;*选择左、右孩子中关键字的最小者*&#x2F; </span><br><span class="line">if(H-&gt;R[k].key&lt; H-&gt;R[0].key))</span><br><span class="line">&#123;H-&gt;R[j]&#x3D;H-&gt;R[k] ；j&#x3D;k  ；&#125;</span><br><span class="line">elsebreak ；</span><br><span class="line">&#125;</span><br><span class="line">H-&gt;R[j]&#x3D;H-&gt;R[0] ；</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">（2）堆排序</span><br><span class="line">voidHeap_Sort(Sqlist *H)</span><br><span class="line">&#123;int j ；</span><br><span class="line">for (j&#x3D;H-&gt;length&#x2F;2；j&gt;0；j--)</span><br><span class="line">Heap_adjust(H，j，H-&gt;length)；&#x2F;*初始建堆*&#x2F; for (j&#x3D;H-&gt;length；j&gt;&#x3D;1；j--)</span><br><span class="line">&#123;H-&gt;R[0]&#x3D;H-&gt;R[1] ；H-&gt;R[1]&#x3D;H-&gt;R[j] ；</span><br><span class="line">H-&gt;R[j]&#x3D;H-&gt;R[0] ；&#x2F;*堆顶与最后一个交换*&#x2F; Heap_adjust(H，1，j-1)；</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>性能分析：</p><p>（1）空间效率：$O(1)$</p><p>（2）时间效率：$O(nlog_2n)$</p><p>（3）稳定性：不稳定</p><h1 id="7-归并排序"><a href="#7-归并排序" class="headerlink" title="7 归并排序"></a>7 归并排序</h1><ol><li>将序列划分成$n$个待排的长度为1的子序列</li><li>对所有子序列进行两两归并，得到$n/2$个长度为2或1的有序子序列</li><li>重复2，直到得到长度为n的有序序列为止</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/550329FAA2224DA1909CCE2C53C7C862?method=download&shareKey=75cb313577311fe8a6540ffb19003dd3" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">(1)一趟归并排序</span><br><span class="line"></span><br><span class="line">void Merge(RecType R[]，RecType DR[]，int k，int m，int h)</span><br><span class="line">&#123;int p，q，n ；p&#x3D;n&#x3D;k，q&#x3D;m+1 ；</span><br><span class="line">while ((p&lt;&#x3D;m)&amp;&amp;(q&lt;&#x3D;h))</span><br><span class="line">&#123;if (R[p].key&lt;&#x3D; R[q].key))&#x2F;*比较两个子序列 *&#x2F;</span><br><span class="line">DR[n++]&#x3D;R[p++] ；</span><br><span class="line">elseDR[n++]&#x3D;R[q++] ；</span><br><span class="line">&#125;</span><br><span class="line">while (p&lt;&#x3D;m)&#x2F;* 将剩余子序列复制到结果序列中*&#x2F; </span><br><span class="line">DR[n++]&#x3D;R[p++] ；</span><br><span class="line">while (q&lt;&#x3D;h)DR[n++]&#x3D;R[q++] ；</span><br><span class="line">&#125;</span><br><span class="line">void Merge_pass(RecType R[]，RecType DR[]，int d，int n)</span><br><span class="line">&#123;int j&#x3D;1 ；</span><br><span class="line">while ((j+2*d-1)&lt;&#x3D;n)&#x2F;&#x2F;1+2d-1</span><br><span class="line">&#123;Merge(R，DR，j，j+d-1，j+2*d-1)； j&#x3D;j+2*d ；</span><br><span class="line"> </span><br><span class="line">&#125;&#x2F;*子序列两两归并*&#x2F;</span><br><span class="line">if (j+d-1&lt;n)&#x2F;*剩余元素个数超过一个子序列长度 d*&#x2F; </span><br><span class="line">Merge(R，DR，j，j+d-1，n)；</span><br><span class="line">else</span><br><span class="line">Merge(R，DR，j，n，n)；&#x2F;*剩余子序列复制*&#x2F;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">（2）递归调用</span><br><span class="line">void Merge_sort(Sqlist *L，RecType DR[])</span><br><span class="line">&#123;int d&#x3D;1 ；</span><br><span class="line">while(d&lt;L-&gt;length)</span><br><span class="line">&#123; Merge_pass(L-&gt;R，DR，d，L-&gt;length)； </span><br><span class="line">Merge_pass(DR，L-&gt;R，2*d，L-&gt;length)； </span><br><span class="line">d&#x3D;4*d ；&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>性能分析：<br>（1）空间复杂度：$O(n)$</p><p>（2）时间复杂度：$O(nlog_2n)$</p><p>（3）稳定性：稳定</p><h1 id="8-计数排序"><a href="#8-计数排序" class="headerlink" title="8 计数排序"></a>8 计数排序</h1><ol><li>待排序记录以指针相链，构成一个链表</li><li>分配时，按当前关键字所取值，将记录分配到不同的链队列中，每个队列中记录的关键字相同</li><li>收集时，按当前关键字位取值从小到大将各队列首尾相链成一个链表</li><li>对每个关键字位均重复2，3</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/E9DF1FF414E54E1286F6D076F1E31085?method=download&shareKey=9810a1638a78b374beff7ec84f5f424b" alt></p><p>性能分析：</p><p>（1）空间效率：$O(rd)$</p><p>（2）时间效率：$O(d(n+rd))$</p><p>（3）稳定性：稳定</p><h1 id="9-各排序算法性能总结"><a href="#9-各排序算法性能总结" class="headerlink" title="9 各排序算法性能总结"></a>9 各排序算法性能总结</h1><table><thead><tr><th align="center">排序方法</th><th align="center">平均时间性能</th><th align="center">最好时间性能</th><th align="center">最坏性能</th><th align="center">空间复杂度</th><th align="center">稳定性</th></tr></thead><tbody><tr><td align="center">直接插入</td><td align="center">$O(n^2)$</td><td align="center">$O(n)$</td><td align="center">$O(n^2)$</td><td align="center">O(1)</td><td align="center">稳定</td></tr><tr><td align="center">冒泡排序</td><td align="center">$O(n^2)$</td><td align="center">$O(n)$</td><td align="center">$O(n^2)$</td><td align="center">$O(1)$</td><td align="center">稳定</td></tr><tr><td align="center">简单选择</td><td align="center">$O(n^2)$</td><td align="center">$O(n^2)$</td><td align="center">$O(n^2)$</td><td align="center">$O(1)$</td><td align="center">不稳定</td></tr><tr><td align="center">希尔排序</td><td align="center">$O(nlog_2n)-O(n^2)$</td><td align="center">$O(n)$</td><td align="center">$O(nlog_2n)-O(n^2)$</td><td align="center">$O(1)$</td><td align="center">不稳定</td></tr><tr><td align="center">快速排序</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(n^2)$</td><td align="center">$O(nlog_2n)$</td><td align="center">不稳定</td></tr><tr><td align="center">堆排序</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(1)$</td><td align="center">不稳定</td></tr><tr><td align="center">归并排序</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(nlog_2n)$</td><td align="center">$O(n)$</td><td align="center">稳定</td></tr><tr><td align="center">基数排序</td><td align="center">$O(d(n+r))$</td><td align="center">$O(d(n+rd))$</td><td align="center">$O(d(n+r))$</td><td align="center">$O(n+rd)$</td><td align="center">稳定</td></tr></tbody></table><p>基数排序中，$r$代表关键字的基数，$d$代表长度，$n$代表关键字的个数</p><p>关于时间复杂度：</p><ol><li>平方阶（$O(n^2)$）排序，各类简单排序：直接插入、直接选择、冒泡排序</li><li>线性对数阶（$O(nlog2n)$）排序：快速排序，堆排序和归并排序</li><li>$O(n1+\epsilon)$：希尔排序</li><li>线性阶$O(n)$：计数排序</li></ol><p>关于稳定性：</p><ol><li>稳定：冒泡、插入、归并、计数</li><li>不稳定：选择、快速、希尔、堆排序</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-插入排序&quot;&gt;&lt;a href=&quot;#1-插入排序&quot; class=&quot;headerlink&quot; title=&quot;1 插入排序&quot;&gt;&lt;/a&gt;1 插入排序&lt;/h1&gt;&lt;h2 id=&quot;1-1-直接插入排序&quot;&gt;&lt;a href=&quot;#1-1-直接插入排序&quot; class=&quot;headerlink&quot; title=&quot;1.1 直接插入排序&quot;&gt;&lt;/a&gt;1.1 直接插入排序&lt;/h2&gt;&lt;p&gt;逐个向有序表中进行插入操作&lt;/p&gt;
&lt;p&gt;初始关键字序列：  [7]    4    -2    19    13    6    ；&lt;br&gt;第一趟排序后：    [4    7]    -2    19    13    6    ；&lt;br&gt;第二趟排序后：    [-2    4    7]    19    13    6    ；&lt;br&gt;第三趟排序后：    [-2    4    7    19]    13    6    ；&lt;br&gt;第四趟排序后：    [-2    4    7    13    19]    6    ；&lt;br&gt;第五趟排序后：    [-2    4    6    7    13    19]    ；&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数据结构总结（五）：查找</title>
    <link href="https://liangggggg.github.io/2020/08/17/Data5/"/>
    <id>https://liangggggg.github.io/2020/08/17/Data5/</id>
    <published>2020-08-17T00:12:59.000Z</published>
    <updated>2020-08-17T08:23:26.484Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-查找的基本概念"><a href="#1-查找的基本概念" class="headerlink" title="1 查找的基本概念"></a>1 查找的基本概念</h1><p>查找有两种基本形态：静态查找和动态查找</p><ul><li>静态查找：在查找时只对数据元素进行查询或检索，查找表称为静态查找表</li><li>动态查找：在实施查找的同时，插入查找表中不存在的记录，或从查找表中删除已存在的某个记录</li></ul><p>根据存储结构的不同，查找方法分为三大类：</p><ol><li>顺序表和链表的查找：将给定的K值与查找表中记录的关键字逐个进行比较，找到要查找的记录</li><li>散列表的查找：根据给定的K值直接访问查找表，从而找到要查找的记录</li><li>索引查找表的查找：首先根据索引确定待查找记录所在的块，然后再从块中找到要查找的记录</li></ol><a id="more"></a><p>平均查找长度</p><p>为确定数据元素在列表中的位置，需给定值进行比较的关键字个数的期望值</p><p>$$ASL = \sum_{i=1}^n p_i * C_i, \  \sum_{i=1}^n p_i = 1$$</p><p>$p_i$：查找第$i$个记录的概率<br>$C_i$：查找第$i$个记录需要进行比较的次数</p><h1 id="2-顺序查找法"><a href="#2-顺序查找法" class="headerlink" title="2. 顺序查找法"></a>2. 顺序查找法</h1><p>将查找表作为一个线性表，可以是顺序表，也可以使链表，依次进行比较</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_SIZE100 typedefstructSSTable</span><br><span class="line">&#123;RecTypeelem[MAX_SIZE]；&#x2F;*顺序表*&#x2F;</span><br><span class="line">intlength ；&#x2F;*实际元素个数*&#x2F;</span><br><span class="line">&#125;SSTable ；</span><br><span class="line">intSeq_Search(SSTableST，KeyType key)</span><br><span class="line">&#123;int p ；</span><br><span class="line">ST. elem[0].key&#x3D;key；&#x2F;*设置监视哨兵，失败返回 0 *&#x2F; </span><br><span class="line">for(p&#x3D;ST.length；ST. elem[p].key!&#x3D; key；p--)</span><br><span class="line">return(p)；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>设查找每个记录的概率相等，即$P_i = 1/n$，查找第$i$个元素成功的比较次数$C_i  = n-i+1$</p><p>查找成功时：<br>$$ASL = \sum_{i=1}^n P_i * C_i = \frac{1}{n}\sum_{i=1}^n(n-i+1)=\frac{n+1}{2}$$</p><p>查找不成功时：比较次数为$n+1$，概率为$P_1 = 1/(2n)$</p><p>$$ASL = \sum_{i=1}^n P_i * C_i = \frac{1}{2n}\sum_{i=1}^n(n-i+1)+\frac{n+1}{2}=\frac{3(n+1)}{4}$$</p><h1 id="3-分块查找法"><a href="#3-分块查找法" class="headerlink" title="3 分块查找法"></a>3 分块查找法</h1><p>分块查找的基本思想是：将表分成n块，每一块中的关键字不一定有序，但前一块中最大关键字必须小于后一块的最小关键字，即要求表示“分块有序的”。首先查找索引表，因为索引表是有序表，确定待查结点是在哪一块，然后再已确定的块中进行顺序查找</p><p>线性表中共有$n$个结点，分成大小相等的$b$块，每块有$s=n/b$个结点，假定对索引表也采用顺序查找，值考虑查找成功的情况，并假定对每个结点的查找概率是相等的</p><p>$$E_b = \sum_{i=1}^b(i* \frac{1}{b})=\frac{b+1}{2}$$</p><p>$$E_w = \sum_{i=1}^s(i*\frac{1}{s})=\frac{s+1}{2}$$</p><p>所以：</p><p>$$E(n)=E_b+E_w = \frac{b+1}{2}+\frac{s+1}{2}=\frac{n+s^2}{2s}+1$$</p><p>当$s=\sqrt{n}，E(n)取最小值$</p><p>$$E(n)=\sqrt{n}+1\approx \sqrt{n}$$</p><h1 id="4-折半查找法"><a href="#4-折半查找法" class="headerlink" title="4 折半查找法"></a>4 折半查找法</h1><p>折半查找要求查找表顺序存储结构且各数据元素按关键字有序排序，也就是说折半查找只适用于对有序顺序表进行查找</p><p>（1）查找思想<br>用Low、High和Mid表示待查找区间的下界、上届和中间位置指针，初值为Low=1,High=n</p><p>取中间位置Mid: Mid = floor[(Low+High)/2]</p><p>比较中间位置记录的关键字与给定的K值</p><ol><li>相等:查找成功</li><li>大于：待查找记录在区间的前半段，修改上界指针：High = Mid -1,转1</li><li>小于：待查记录在区间的后半段，修改下界指针：Low = Mid +1，转1</li></ol><p>直到越界(Low&gt;High)，查找失败 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">intBin_Search(SSTableST，KeyTypekey)</span><br><span class="line">&#123;intLow&#x3D;1，High&#x3D;ST.length，Mid ；</span><br><span class="line">while (Low&lt;&#x3D;High)</span><br><span class="line">&#123;Mid&#x3D;(Low+High)&#x2F;2 ；</span><br><span class="line">if(ST. elem[Mid].key&#x3D;&#x3D; key) return(Mid)；</span><br><span class="line">else if (ST. elem[Mid].key&lt; key)</span><br><span class="line">Low&#x3D;Mid+1 ；</span><br><span class="line">else</span><br><span class="line">High&#x3D;Mid-1 ；&#125;</span><br><span class="line">return(0)；&#x2F;*查找失败*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）算法分析<br>经过每一次查找，查找范围就缩小一半，该过程可用一颗二叉树表示，所得到的二叉树为判定书</p><p><img src="https://note.youdao.com/yws/api/personal/file/D88D43B8E643426EAB6B2364BFF63C6F?method=download&shareKey=3fa93bd5fbe81e5e524c115bc248e942" alt></p><p>ASL成功 = $(1+2<em>2+4</em>3+4<em>4)/11$<br>ASL不成功 = $(4</em>3 +8*4)/12$</p><p>将二叉判定书的第$\lfloor log2n \rfloor+1$层上的结点补齐就称为一颗满二叉树，深度不变，$\lfloor log2(n+1) \rfloor+1$</p><p>由满二叉树性质知，第$i$层上的结点数为$2i-1(i&lt;=h)$，设表中每个记录的查找概率相等，即$P_1 = \frac{1}{n}$，查找成功时的平均查找长度ASL：</p><p>$$ASL = \sum_{i=1}^n P_i * C_i = \frac{1}{n}\sum_{j=1}^h j* 2^{j-1}=\frac{n+1}{n}log_2(n+1)-1$$</p><p>当$n$很大$(n&gt;50)$，$ASL\approx log_2(n+1)-1$</p><h1 id="5-B树及其基本操作、B-树的基本概念"><a href="#5-B树及其基本操作、B-树的基本概念" class="headerlink" title="5 B树及其基本操作、B+树的基本概念"></a>5 B树及其基本操作、B+树的基本概念</h1><p>一颗度m的B树称为m阶的B树，是一颗平衡（平衡因子为0）的查找树（排序树）</p><h2 id="5-1-B树"><a href="#5-1-B树" class="headerlink" title="5.1 B树"></a>5.1 B树</h2><p>（1）B树的定义</p><p>一棵m阶的B树，或者为空树，或为满足下列特性的m叉树：</p><ol><li>分枝的数量$\lceil m/2 \rceil&lt;=n&lt;=m$</li><li>关键码的数量$\lceil m/2 \rceil-1&lt;=n&lt;=m-1$</li></ol><p>（2）B树的查找</p><p>类似二叉排序树的查找，所不同的是B树每个节点是多关键码的有序表，在到达某个结点时，先在有序表中查找，若找到，则查找成功；否则，按照对应的指针信息指向的子树中查找，当到达叶子节点时，则说明树中没有对应的关键码，查找失败</p><p>（3）B树的插入</p><ol><li>在B树中查找关键字$K$，若找到，表明关键字已存在，返回，否则$K$的查找操作失败于某个叶子结点，转2</li><li>将$K$插入到该叶子结点中，插入时，若：<ul><li>叶子节点的关键字数$&lt;m-1$:直接插入；</li><li>叶子节点的关键字数$=m-1$：将结点“分裂”</li></ul></li></ol><p>分裂的方法：</p><p>设待“分裂”结点包含信息为：<br>$(m,A_0,K_1,A_1,K_2,A_2,\dots,K_m,A_m)$，从其中间位置分为两个结点：</p><p>$$(\lceil m/2 \rceil -1,A_0,K_1,A_1,\dots,K_{\lceil m/2 \rceil-1},A_{\lceil m/2 \rceil-1})$$<br>$$(m-\lceil m/2 \rceil,A_{\lceil m/2 \rceil},K_{\lceil m/2 \rceil+1},A_{\lceil m/2 \rceil+1},\dots,K_{m},A_{m})$$</p><p>并将中间关键字$K_{\lceil m/2 \rceil}$插入到父节点中，以分裂后的两个结点作为其子结点</p><p><img src="https://note.youdao.com/yws/api/personal/file/E743781A41C048FBACF19AEA3B46CDE3?method=download&shareKey=fff65bef129a9f6c2e47f8fb66bd770a" alt></p><p>（4）B树的删除</p><p>在$B$树上删除一个关键字$K$，首先找到关键字所在的结点$N$，然后再$N$中进行关键字$K$的删除操作。</p><p>若$N$b不是叶子结点，设$K$是$N$的第$i$个关键字，将指针$A_{i-1}$所指子树中的最大关键字（或最小关键字）$K^{‘}$放在$(k)$的位置，然后删除$K^{‘}$，而$K^{‘}$一定在叶子结点上</p><p>从叶子结点中删除一个关键字的情况是：<br>（兄弟可借）</p><ol><li>若结点$N$中的关键字个数$&gt;\lceil m/2 \rceil-1$，在结点直接删除关键字K</li><li>若结点$N$中的关键字个数$=\lceil m/2 \rceil-1$，若结点$N$的左（右）兄弟结点中的关键字个数$&gt;\lceil m/2 \rceil-1$，则将节点$N$的左（或右）兄弟结点中的最大（或最小）关键字移到其父结点中，而父结点中大于（或小于）且紧靠上移关键字的关键字下移到结点$N$</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/2C8523525D4F45C494DF2BDD9E038DD6?method=download&shareKey=bb0f372b7208953b8ef2e463e228d3ac" alt></p><p>（兄弟不可借——合并结点）<br>3. 若结点$N$和其兄弟结点中的关键字$=\lceil m/2 \rceil-1$：删除结点$N$中的关键字，再将结点$N$中的关键字、指针域其兄弟结点以及分割二者的父结点的某个关键字$K_i$，合并为一个结点，若因此使父结点中的关键个数$&lt;=\lceil m/2 \rceil-1$，则以此类推<br>4. 若所删关键字为非终端结点中的$k_i$，则可以指针$A_i$所指子树中最小关键字$Y$替代$K_i$，然后再相应的结点中删去$Y$</p><p><img src="https://note.youdao.com/yws/api/personal/file/97818282DD604A05B09196BEAD6539F0?method=download&shareKey=c6f362679dd80a67908a2d6ca93ef7a4" alt></p><h2 id="5-2-B-树"><a href="#5-2-B-树" class="headerlink" title="5.2 $B+$树"></a>5.2 $B+$树</h2><p>$B+$树是文件系统所需要的一种$B$树的变形树，一棵$m$阶的$B+,B$树主要差异在于：</p><ol><li>有$n$棵子树的结点中含有$n$个关键码；</li><li>所有叶子结点中包含了全部关键码的信息，以及指向含有这些关键码记录的指针，且叶子结点本身依赖关键码的大小自小而大的顺序链接</li><li>所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键码</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/1814D7A4B1B64A8F8C2DE97653835F25?method=download&shareKey=5296f5cd12ff30a14d50fb00a0eaa204" alt></p><h1 id="6-哈希表"><a href="#6-哈希表" class="headerlink" title="6 哈希表"></a>6 哈希表</h1><h2 id="6-1-常用的哈希函数"><a href="#6-1-常用的哈希函数" class="headerlink" title="6.1 常用的哈希函数"></a>6.1 常用的哈希函数</h2><p>哈希函数“好坏”的主要评价因素有：散列函数的构造简单；能“均匀”地将散列表中的关键字映射到地址空间（发生冲突的可能性最少）</p><p>（1）直接定址法</p><p>$$H(key)=key, \ H(key)=a*key+b$$</p><p>此方法仅适用于：地址集合的大小等于关键字集合的大小</p><p>（2）数字分析法<br>假设关键字集合的每个关键字都是由$s$位数字组成$(k_1,k_2,\dots,k_n)$，分析关键字集中的全体，并从中提取分布均匀的若干位或他们的组合作为地址</p><p>（3）平方取中法</p><p>若关键字的每一位都有某些数字重复出现频度很高的现象，则先求关键字的平方值，以扩大差别</p><p>（4）折叠法</p><p>若关键字的位数特别多，则可将其分割成几部分，然后取他们的叠加和为散列地址</p><ol><li>位移法：将各部分的最后一位对齐相加</li><li>间界叠加法：从一端向另一端沿各个部分分界来回折叠后，最后一位对齐相加</li></ol><p>适用于关键字的数字位数特别多</p><p>（5）除留余数法</p><p>$$H(key)=key\  MOD\  p\ p&lt;=m$$</p><p>选取适合的$p$很重要，一般选取质数</p><p>（6）随机数法</p><p>$$H(key)= Random(key)$$</p><h2 id="6-2-处理冲突的方法"><a href="#6-2-处理冲突的方法" class="headerlink" title="6.2 处理冲突的方法"></a>6.2 处理冲突的方法</h2><p>（1）开放定址法</p><p>一旦产生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将数据元素存入</p><ol><li>线性探测法</li></ol><p>$$H_i = (Hash(key)+d_i)\ mod\ m\ (1&lt;=i&lt;m)$$</p><p>这种方法的特点是：发生冲突，顺序表看表中下一单元，直接找出一个空单元或查遍全表。因此，可能出现很多元素在相邻的散列地址上“堆积”起来，大大降低了查找效率。为此，可采用二次探测法改善</p><ol start="2"><li>二次探测法</li></ol><p>$$H_i = (Hash(key)\pm d_i)\ mod\ m\ (1&lt;=i&lt;m)$$</p><p>其中：$Hash(key)$为散列函数，$m$为散列表长度，$m$要求是某个$4k+3$的质数，$d_i$为增量序列$1^2,-1^2,2^2,-2^2,\dots,q^2,-q^2,\ q&lt;=m/2$</p><ol start="3"><li>拉链法</li></ol><p>将所有散列表地址为$i$的元素构成一个同义词链的单链表，并将单链表的头指针存在散列表的第$i$个单元中</p><ol start="4"><li>建立公共溢出区</li></ol><p>建立一个溢出表保存与基本表中记录冲突的所有记录</p><h2 id="6-3-散列表的查找"><a href="#6-3-散列表的查找" class="headerlink" title="6.3 散列表的查找"></a>6.3 散列表的查找</h2><p>查找过程与造表一致，假设采用开放定址处理冲突，则查找过程：</p><ol><li>对给定值$K$，计算散列地址$i=H(K)$</li><li>若$r[i]=NULL$，则查找不成功</li><li>若$r[i].key=k$，则查找成功</li><li>否则求下一地址$H_i$，直至$r[H_i]=NULL$（查找不成功），或$r[H_i].key=k$（查找成功）</li></ol><p>哈希表的填满因子<br>$$\alpha=\frac{表中填入的记录数}{哈希表长度}$$</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-查找的基本概念&quot;&gt;&lt;a href=&quot;#1-查找的基本概念&quot; class=&quot;headerlink&quot; title=&quot;1 查找的基本概念&quot;&gt;&lt;/a&gt;1 查找的基本概念&lt;/h1&gt;&lt;p&gt;查找有两种基本形态：静态查找和动态查找&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;静态查找：在查找时只对数据元素进行查询或检索，查找表称为静态查找表&lt;/li&gt;
&lt;li&gt;动态查找：在实施查找的同时，插入查找表中不存在的记录，或从查找表中删除已存在的某个记录&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据存储结构的不同，查找方法分为三大类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;顺序表和链表的查找：将给定的K值与查找表中记录的关键字逐个进行比较，找到要查找的记录&lt;/li&gt;
&lt;li&gt;散列表的查找：根据给定的K值直接访问查找表，从而找到要查找的记录&lt;/li&gt;
&lt;li&gt;索引查找表的查找：首先根据索引确定待查找记录所在的块，然后再从块中找到要查找的记录&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数据结构总结（四）：图</title>
    <link href="https://liangggggg.github.io/2020/08/15/Data4/"/>
    <id>https://liangggggg.github.io/2020/08/15/Data4/</id>
    <published>2020-08-15T01:12:59.000Z</published>
    <updated>2020-08-16T07:18:27.623Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-图的存储及基本操作"><a href="#1-图的存储及基本操作" class="headerlink" title="1 图的存储及基本操作"></a>1 图的存储及基本操作</h1><h2 id="1-1-邻接矩阵"><a href="#1-1-邻接矩阵" class="headerlink" title="1.1 邻接矩阵"></a>1.1 邻接矩阵</h2><p>用一维数组存储图中顶点信息，用矩阵表示图中各顶点之间的邻接关系</p><p>假设图$G=(V,E)$有$n$个确定的顶点，即$V=\lbrace v_0,v_1,\dots,v_{n-1}\rbrace$,$A[n][n]$存储顶点之间关系的信息</p><p>以顶点在vexs数组中的下标代表顶点</p><a id="more"></a><p>（1）无向图的邻接矩阵一定是一个对称矩阵，只需存放上（或下）三角矩阵的元素即可</p><p>（2）对于无向图，邻接矩阵第i行（或第i列）非零元素（或非$\infty$元素）的个数正好是第i个顶点的度$TD(v_i)$</p><p>（3）对于有向图，邻接矩阵第i行（或第i列）非零元素（或非$\infty$元素）的个数正好是第i个顶点的出度$OD(v_i)$（或入度$ID(v_i)$）</p><p>（4）邻接矩阵要确定图中有多少条边，则必须按行、列对每个元素进行检测，时间代价大，是邻接矩阵存储图的局限性</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#define INFINITYMAX_VAL&#x2F;* 最大值∞ *&#x2F;</span><br><span class="line">&#x2F;*根据图的权值类型，定义为最大整数或实数 *&#x2F; </span><br><span class="line">#define MAX_VEX30&#x2F;*最大顶点数目 *&#x2F; </span><br><span class="line">typedef enum &#123;DG，AG，WDG，WAG&#125; GraphKind ；</span><br><span class="line">&#x2F;*&#123;有向图，无向图，带权有向图，带权无向图&#125;*&#x2F; </span><br><span class="line">typedef struct AdjType</span><br><span class="line">&#123;</span><br><span class="line">ArcValType    ArcVal；&#x2F;*弧或边的权值*&#x2F; </span><br><span class="line">ArcInfoType ArcInfo；&#x2F;*弧或边的其它信息*&#x2F;</span><br><span class="line">&#125; AdjType ；&#x2F;*弧或边的结构定义*&#x2F; </span><br><span class="line">typedef struct ArcType</span><br><span class="line">&#123;VexTypevex1，vex2 ；&#x2F;*弧或边所依附的两个顶点 *&#x2F; </span><br><span class="line">ArcValType    ArcVal  ；&#x2F;*弧或边的权值*&#x2F;</span><br><span class="line">ArcInfoType   ArcInfo ；&#x2F;*弧或边的其它信息*&#x2F;</span><br><span class="line">&#125;ArcType ；&#x2F;*弧或边的结构定义*&#x2F; typedef struct</span><br><span class="line">&#123;GraphKindkind ； &#x2F;*图的种类标志*&#x2F;</span><br><span class="line">intvexnum，arcnum ；&#x2F;* 图的当前顶点数和弧数*&#x2F; </span><br><span class="line">VexTypevexs[MAX_VEX] ；&#x2F;*顶点向量*&#x2F; </span><br><span class="line">AdjTypeadj[MAX_VEX][MAX_VEX]；</span><br><span class="line">&#125;MGraph ；&#x2F;*图的结构定义*&#x2F;</span><br></pre></td></tr></table></figure><h2 id="1-2-邻接表"><a href="#1-2-邻接表" class="headerlink" title="1.2 邻接表"></a>1.2 邻接表</h2><p>邻接表示图的一种顺序存储与链式存储结合的存储方式。对图G中的每个顶点$v_i$，将所有邻接与$v_i$的顶点$v_j$链成一个单链表，这个单恋表就称为顶点$v_i$的邻接表，再将所有点的邻接表表头放到数组中，构成了图的邻接表。</p><p>（1）若无向图中有n个顶点，e条边，则它的邻接表需n个头结点和2e个表结点</p><p>（2）在无向图的邻接表中，顶点$v_i$的度恰为第i个链表中的结点数</p><p>（3）在有向图中，第i个链表中的结点个数是顶点$v_i$的入度</p><p>（4）在邻接表上容易找到任一顶点的第一个邻接点和下一个邻接点，但要判定任意两个顶点$v_i,v_j$之间是否有边，则需要搜索第i个或第J个链表，不及邻接矩阵方便</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_VEX30&#x2F;*最大顶点数*&#x2F; </span><br><span class="line">typedef intInfoType；</span><br><span class="line">typedef enum &#123;DG，AG，WDG，WAG&#125; GraphKind ；</span><br><span class="line">typedef struct LinkNode</span><br><span class="line">&#123;intadjvex ；&#x2F;&#x2F;邻接点在头结点数组中的位置(下标) </span><br><span class="line">InfoTypeinfo；&#x2F;&#x2F; 与边或弧相关的信息，如权值</span><br><span class="line">struct LinkNode*nextarc  ；&#x2F;&#x2F;指向下一个表结点</span><br><span class="line">&#125;LinkNode ；&#x2F;*表结点类型定义*&#x2F; </span><br><span class="line">typedef struct VexNode</span><br><span class="line">&#123;VexTypedata；&#x2F;&#x2F; 顶点信息</span><br><span class="line">int indegree；&#x2F;&#x2F;顶点的度，有向图是入度或出度或没有</span><br><span class="line">LinkNode*firstarc ；&#x2F;&#x2F; 指向第一个表结点</span><br><span class="line">&#125;VexNode  ；&#x2F;*顶点结点类型定义*&#x2F; typedef struct ArcType</span><br><span class="line">&#123;VexTypevex1，vex2 ；&#x2F;* 弧或边所依附的两个顶点 *&#x2F; </span><br><span class="line">InfoTypeinfo；&#x2F;&#x2F; 与边或弧相关的信息，如权值</span><br><span class="line">&#125;ArcType ；&#x2F;*弧或边的结构定义*&#x2F; typedef struct</span><br><span class="line">&#123;GraphKindkind ；&#x2F;*图的种类标志*&#x2F;</span><br><span class="line"> int vexnum ；</span><br><span class="line">VexNodeAdjList[MAX_VEX] ；</span><br><span class="line">&#125;ALGraph ；&#x2F;*图的结构定义*&#x2F;</span><br></pre></td></tr></table></figure><h1 id="2-图的遍历"><a href="#2-图的遍历" class="headerlink" title="2 图的遍历"></a>2 图的遍历</h1><h2 id="2-1-深度优先搜索"><a href="#2-1-深度优先搜索" class="headerlink" title="2.1 深度优先搜索"></a>2.1 深度优先搜索</h2><p>DFS类似于树的先根遍历，是树的先根遍历的推广。</p><p>其耗费的时间则取决于所采用的存储结构。当用二维数组表示邻接矩阵图的存储结构时，查找每个顶点的邻接点所需时间为$O(n^2)$，其中$n$为图中顶点数。而当以邻接表作图的存储结构时，找邻接点所需时间为$O(e)$，其中$e$为无向图中边的数或有向图中弧的数。由此，当以邻接表作存储结构时，深度优先搜索遍历图的时间复杂度为$O(n+e)$。</p><h2 id="2-2-广度优先搜索"><a href="#2-2-广度优先搜索" class="headerlink" title="2.2 广度优先搜索"></a>2.2 广度优先搜索</h2><p>BFS类似于树的按层次遍历的过程。</p><p>如果使用邻接表表示图，总时间代价为$O(n+e)$，如果用邻接矩阵，总的时间代价为$O(n^2)$</p><h1 id="3-图的应用"><a href="#3-图的应用" class="headerlink" title="3 图的应用"></a>3 图的应用</h1><h2 id="3-1-最小生成树"><a href="#3-1-最小生成树" class="headerlink" title="3.1 最小生成树"></a>3.1 最小生成树</h2><p>（1）Prim算法</p><p>假设$G=(V,E)$为一网图，其中$V$为网图中所有顶点的集合，$E$为网图中所有带权边的集合。设置两个新的结合$U$和$T$，集合$U$用于存放$G$的最小生成树的顶点，集合$T$存放$G$的最小生成树的边。令集合$U$的初值为$u=\lbrace u_1 \rbrace$</p><ol><li>从所有$u\in U , v\in V-U$的边中，选取具有最小权值的边$(u,v)$</li><li>将顶点$v$加入集合$U$中，将边$(u,v)$加入集合$T$中，不断重复</li><li>直到$U=V$时，最小生成树构造完毕</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/B0434A610F8B457C8FE7C374B1E9C6B2?method=download&shareKey=9d6342c361f13787d7d0bdb6cc2d561f" alt></p><p>Prim算法的时间复杂度为$O(n^2)$，与网中的边数无关，适用于求边稠密的网的最小生成树</p><p>（2）Kruskal算法</p><p>按照网中的权值递增顺序构造最小生成树的方法，需对$e$条边按权值进行排序，时间复杂度为$O(eloge)$（$e$为网中边的数目），因此适用于求边稀疏的网的最小生成树</p><p><img src="https://note.youdao.com/yws/api/personal/file/90EF181691074DBCB7EF3CE9D25FD795?method=download&shareKey=e18b362fdc112a35adf5f8e7a9cc78fe" alt></p><h2 id="3-2-最短路径"><a href="#3-2-最短路径" class="headerlink" title="3.2 最短路径"></a>3.2 最短路径</h2><p>（1）单源点最短路径</p><p>前提：非负权值的图</p><p>设给定源点为$V_s$，$S$为已求得最短路径的终点集，开始时令$S=\lbrace V_s \rbrace$，当求得第一条最短路径$(V_s,V_i)$后，S为$\lbrace V_s,V_i \rbrace$</p><ol><li>令$S=\lbrace V_s \rbrace$，用带权的邻接矩阵表示有向图，对图中每个顶点$V_i$按以下原则设置初值</li></ol><p>$$<br>dist[i]=<br>\begin{cases}<br>0 &amp; i=s\\<br>W_{si} &amp;i \ne s 且&lt;V_s,V_i&gt; \in E，W_{si}为弧上的权值\\<br>\infty &amp; i\ne s且&lt;V_s,V_i&gt;不属于E<br>\end{cases}<br>$$</p><ol start="2"><li>选择一个顶点$V_j$，使得：<br>$$dist[j]=Min{dist[k]|V_k\in V-S}$$</li></ol><p>$V_j$就是求得下一条最短路径重点，将$V_j$并入到$S$中，即$S=S\cup \lbrace V_j \rbrace$</p><ol start="3"><li>对$V-S$中的每个顶点$V_k$，修改$dist[k]$，方法是：</li></ol><p>若$dist[j]+W_{jk}&lt;dist[k]$，则修改为：$dist[k]=dist[j]+W_{jk} (\forall V_k \in V-S)$</p><ol start="4"><li>重复2，3，知道S=V为止</li></ol><p>时间复杂度$O(n^2)$</p><p><img src="https://note.youdao.com/yws/api/personal/file/CA666348EB3F47E38C99A46E2797F5EE?method=download&shareKey=8be271a12c0ec4ed3d00b3aeea6907ae" alt></p><p><img src="https://note.youdao.com/yws/api/personal/file/0EC47118409644B89304F162CC011C3A?method=download&shareKey=277330d42d8968178b86457f8c17f636" alt></p><p>（3）每一对顶点之间的最短路径</p><p>设顶点集$S$（初值为空），用数组$A$的每个元素$A[i][j]$保存$V_i$值经过$S$中的顶点到达$V_j$的最短路径长度，其思想是：</p><ol><li>设初始时令$S=\lbrace  \rbrace$,$A[i][j]$的赋初值方式是：</li></ol><p>$$<br>A[i][j]=<br>\begin{cases}<br>0 &amp; i=j\\<br>W_{ii} &amp;i \ne j 且&lt;V_i,V_j&gt; \in E，W_{ij}为弧上的权值\\<br>\infty &amp; i\ne j且&lt;V_i,V_i&gt;不属于E<br>\end{cases}<br>$$</p><ol start="2"><li>将图中一个顶点$V_k$加入到$S$中，修改$A[i][j]$的值，修改方式：</li></ol><p>$$A[i][j]=Min\lbrace A[i][j],(A[i][k]+A[k][j]) \rbrace$$</p><ol start="3"><li>重复2，直到$G$的所有顶点都 加入到$S$中为止</li></ol><p>时间复杂度为$O(n^3)$</p><p><img src="http://note.youdao.com/noteshare?id=d714a4e0dcbe51a82c7c2fe3047db2db&sub=4977D64EAF3A46D3AF7730228E2A555A" alt></p><p><img src="https://note.youdao.com/yws/api/personal/file/6A15DA39F38946F4907806B14FA49471?method=download&shareKey=b17f11c2ac0784dfec9a9c9d44183577" alt></p><h2 id="3-3-拓扑排序"><a href="#3-3-拓扑排序" class="headerlink" title="3.3 拓扑排序"></a>3.3 拓扑排序</h2><p>有向无环图</p><p>主要用于研究工程项目的工序问题</p><ol><li>从AVO网中选择一个没有前驱的顶点（入度为0），并且输出它</li><li>从网中删除该顶点，并且删除从该顶点发出的全部有向边</li><li>重复上述步骤，知道剩余网中不再存在没有前驱的顶点为止</li></ol><h2 id="3-4-关键路径"><a href="#3-4-关键路径" class="headerlink" title="3.4 关键路径"></a>3.4 关键路径</h2><ol><li>利用拓扑排序求出AOE网的一个拓扑序列</li><li>从拓扑排序的序列的第一个顶点开始，按拓扑顺序依次计算每个时间的最早发生时间（选择最大的）</li><li>从拓扑排序的序列的最后一个顶点开始，按拟拓扑顺序依次计算每个时间的最晚发生时间（选择最小的）</li></ol><p>最早发生时间等于最晚发生时间的事件为关键事件</p><p><img src="https://note.youdao.com/yws/api/personal/file/DDBFB4920153461085F4183EC16B2B8C?method=download&shareKey=eaf12c4b3ff1ea75085c551154dcedc2" alt></p><p>其拓扑排序序列为$&lt;V_0,V_1,V_2,V_3,V_4,V_5,V_6,V_7,V_8&gt;$</p><p>计算各事件的$ve(i),vl(i)$值</p><p><img src="https://note.youdao.com/yws/api/personal/file/AC8580E97E5E4B5E90D6F48EE738DFF4?method=download&shareKey=27d90648fa2b48f6c99e1ed8a4f4638d" alt></p><p>其次计算$e,l$</p><p><img src="https://note.youdao.com/yws/api/personal/file/83E7282B9C5048C48BBF903E663EDFE2?method=download&shareKey=67ceb99e4d35e5bdf5a4670216a959c2" alt></p><p>$e,l$相等的事件为关键事件，其构成的路径为关键路径</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-图的存储及基本操作&quot;&gt;&lt;a href=&quot;#1-图的存储及基本操作&quot; class=&quot;headerlink&quot; title=&quot;1 图的存储及基本操作&quot;&gt;&lt;/a&gt;1 图的存储及基本操作&lt;/h1&gt;&lt;h2 id=&quot;1-1-邻接矩阵&quot;&gt;&lt;a href=&quot;#1-1-邻接矩阵&quot; class=&quot;headerlink&quot; title=&quot;1.1 邻接矩阵&quot;&gt;&lt;/a&gt;1.1 邻接矩阵&lt;/h2&gt;&lt;p&gt;用一维数组存储图中顶点信息，用矩阵表示图中各顶点之间的邻接关系&lt;/p&gt;
&lt;p&gt;假设图$G=(V,E)$有$n$个确定的顶点，即$V=\lbrace v_0,v_1,\dots,v_{n-1}\rbrace$,$A[n][n]$存储顶点之间关系的信息&lt;/p&gt;
&lt;p&gt;以顶点在vexs数组中的下标代表顶点&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数据结构总结（三）：树与二叉树</title>
    <link href="https://liangggggg.github.io/2020/08/14/Data3/"/>
    <id>https://liangggggg.github.io/2020/08/14/Data3/</id>
    <published>2020-08-14T00:12:59.000Z</published>
    <updated>2020-08-21T03:33:07.637Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-二叉树"><a href="#1-二叉树" class="headerlink" title="1 二叉树"></a>1 二叉树</h1><h2 id="1-1-二叉树的定义及其主要特性"><a href="#1-1-二叉树的定义及其主要特性" class="headerlink" title="1.1 二叉树的定义及其主要特性"></a>1.1 二叉树的定义及其主要特性</h2><p>二叉树是有序的，即使树中节点只有一颗子树，也要区分它是左子树还是右子树</p><p>二叉树具有的性质：</p><ol><li>一颗非空二叉树的第$i$层上最多有$2^{i-1}$个结点$（i&gt;=1）$</li><li>一颗深度为$k$的二叉树中，最多具有$2^k-1$个结点</li><li>对于一颗非空的二叉树，如果叶子节点数为$n_0$，度数为2的结点数为$n_2$，则有$n_0=n_2+1$</li></ol><a id="more"></a><ol start="4"><li>具有$n$个结点的完全二叉树的深度为$\lfloor log_2n \rfloor+1$</li><li>对于一个有$n$个结点的全完二叉树（深度为$\lfloor log_2n \rfloor+1$），按照从根结点起，自上而下，从左到右的约定对所有结点从1到n进行编号，则对任意的编号为i的结点$(1&lt;=i&lt;=n)$有以下性质<ul><li>如果$i=1$，则结点$i$是二叉树的根，无双亲</li><li>如果$i&gt;1$，则双亲结点编号$\lfloor i/2 \rfloor$</li><li>如果$2i&gt;n$，则结点$i$无左孩子（结点$i$为叶子结点），否则其左孩子结点是$2i$</li><li>如果$2i+1&gt;n$，则结点$i$无右孩子，否则其右孩子结点$2i+1$</li></ul></li></ol><h2 id="1-2-二叉树的顺序存储结构和链式存储结构"><a href="#1-2-二叉树的顺序存储结构和链式存储结构" class="headerlink" title="1.2 二叉树的顺序存储结构和链式存储结构"></a>1.2 二叉树的顺序存储结构和链式存储结构</h2><p>（1）顺序存储结构</p><p>用一组连续的存储单元存放二叉树中的结点，一般按照二叉树结点从上至下、从左到右的顺序存储，依据二叉树的性质，完全二叉树和满二叉树采用顺序存储比较合适，树中结点的序号可以唯一地反映出结点之间的逻辑关系</p><p>对于一般的二叉树，只有添加一些并不存在的空结点，使之成为一颗完全二叉树的形式，然后再用一维数组顺序存储</p><p><img src="https://note.youdao.com/yws/api/personal/file/FFBEBB8C44AB4B52B84F5D6BE7F80AC9?method=download&shareKey=59baeb75b97d01169c42ae3332c597ed" alt></p><p>（2）链式存储结构</p><ol><li>二叉链表：包括三个域，数据域和左、右指针域，分别指向该结点的左孩子和右孩子</li><li>三叉链表：为了方便检索结点的双亲或祖先结点，在结构中增加一个指向其双亲结点的指针域</li></ol><h2 id="1-3-二叉树的遍历"><a href="#1-3-二叉树的遍历" class="headerlink" title="1.3 二叉树的遍历"></a>1.3 二叉树的遍历</h2><p>（1）先序遍历 </p><ol><li>访问根结点</li><li>先序遍历结点的左子树</li><li>先序遍历结点的右子树</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void PreOrder(BiTree b)</span><br><span class="line">&#123;</span><br><span class="line">if(b!&#x3D;NULL)</span><br><span class="line">&#123;</span><br><span class="line">Visit(b-&gt;data); &#x2F;&#x2F;访问结点的数据域</span><br><span class="line">PreOrder(b-&gt;lchild); &#x2F;&#x2F;先序遍历b的左子树</span><br><span class="line">PreOrder(b-&gt;rchild); &#x2F;&#x2F;先序遍历b的右子树</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure><p>（2）中序遍历</p><ol><li>中序遍历根结点的左子树</li><li>访问根结点</li><li>中序遍历根结点的右子树</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void InOrder(BiTree b)</span><br><span class="line">&#123;</span><br><span class="line">if(b!&#x3D;NULL)&#123;</span><br><span class="line">InOrder(b-&gt;lchild); &#x2F;&#x2F;中序递归遍历b的左子树</span><br><span class="line">Vist(b-&gt;data); &#x2F;&#x2F; 访问结点的数据域</span><br><span class="line">InOrder(b-&gt;rchild); &#x2F;&#x2F;中序递归遍历b的右子树</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）后序遍历</p><ol><li>后序遍历根结点的左子树</li><li>后序遍历根结点的右子树</li><li>访问根结点</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void PostOrder(BiTree b)</span><br><span class="line">&#123;</span><br><span class="line">if(b!&#x3D;NULL)&#123;</span><br><span class="line">PostOrder(b-&gt;lchild); &#x2F;&#x2F;后续遍历b的左子树</span><br><span class="line">PostOrder(b-&gt;rchild); &#x2F;&#x2F;后续遍历b的右子树</span><br><span class="line">Vist(b-&gt;data); &#x2F;&#x2F;访问结点的数据域</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（4）层次遍历<br>在进行层次遍历时，可设置一个队列结构，遍历从二叉树的根结点开始，首先将根结点指针入队列，然后从头取出一个元素，每取一个元素，执行下面两个操作：</p><ol><li>访问该元素所指结点</li><li>若该元素所指结点的左、右孩子结点非空，则将该元素所指结点的左孩子指针和右孩子指针顺序入队</li></ol><p>此过程不断进行，当队列为空时，二叉树的层次遍历结束</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_NODE 50</span><br><span class="line">void LevelorderTraverse(BTNode *T)</span><br><span class="line">&#123;</span><br><span class="line">BTNode *Queue[MAX_NODE], *p &#x3D; T</span><br><span class="line">int front&#x3D;0, rear&#x3D;0;</span><br><span class="line">if(p!&#x3D;NULL)</span><br><span class="line">&#123;</span><br><span class="line">Queue[++rear]&#x3D;p; # 根结点入队</span><br><span class="line"></span><br><span class="line">while(front&lt;rear)</span><br><span class="line">&#123;</span><br><span class="line">p &#x3D; Queue[++front]</span><br><span class="line">visit(p-&gt;dta);</span><br><span class="line">if(p-&gt;Lchild!&#x3D;NULL) Queue[++rear]&#x3D;p; # 左结点入队</span><br><span class="line">if(p-&gt;Rchild!&#x3D;NULL) Queue[++rear]&#x3D;p; # 右结点入队</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（5）遍历与恢复</p><p>已知结点的先序遍历和中序遍历，可以唯一确定这颗二叉树</p><p>已知二叉树的后续序列和中序序列也可以唯一地确定一颗二叉树</p><p>（6）遍历的应用</p><ol><li>按满二叉树方式建立链式二叉树，在建立过程中借助一个一维数组$S[n]$，编号为$i$的结点指针保存在$S[i]$中</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_NODE 50</span><br><span class="line">typedef struct BTNode</span><br><span class="line">&#123;</span><br><span class="line">char data;</span><br><span class="line">struct BTNode *Lchild, *Child;</span><br><span class="line">&#125;BTNode;</span><br><span class="line"></span><br><span class="line">BTNode *Create_BTree(void)</span><br><span class="line">&#123;</span><br><span class="line">BTNode *T, *p, *s[MAX_NODE];</span><br><span class="line">char ch;</span><br><span class="line">int i,j;</span><br><span class="line">while(1)</span><br><span class="line">&#123;</span><br><span class="line">scanf(&quot;%d&quot;, &amp;i);</span><br><span class="line">if(i&#x3D;&#x3D;0) break; # 输入0结束</span><br><span class="line">else&#123;</span><br><span class="line">ch&#x3D;getchar();</span><br><span class="line">p&#x3D;(BTNode *)malloc(sizeof(BTNode));</span><br><span class="line">p-&gt;data&#x3D;ch;</span><br><span class="line">p-&gt;Lchild&#x3D;p-&gt;Rchild&#x3D;NULL;</span><br><span class="line">s[i]&#x3D;p;</span><br><span class="line">if(i&#x3D;&#x3D;1) T&#x3D;p;</span><br><span class="line">&#125;</span><br><span class="line">else&#123;</span><br><span class="line">j &#x3D; i&#x2F;2 # j是i的双亲结点编号</span><br><span class="line">if(i%2&#x3D;&#x3D;0) s[j]-&gt;Lchild&#x3D;p;</span><br><span class="line">else s[j]-Rchild&#x3D;p;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return T;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>按先序遍历对一颗二叉树进行扩充</li></ol><p>读入一棵二叉树对应的扩充二叉树的前序遍历的结点值序列。每读入一个结点值就进行分析：</p><ul><li>若是扩充结点值：令根指针为 NULL；</li><li>若是(正常)结点值：动态地为根指针分配一个结点，将该值赋给根结点，然后递归地  创建根的左子树和右子树。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#define NULLKY &#39;?&#39;</span><br><span class="line">#define MAX_NODE 50</span><br><span class="line">typedef struct BTNode</span><br><span class="line">&#123;</span><br><span class="line">char data;</span><br><span class="line">struct BTNode *Lchild, *Rchild;</span><br><span class="line">&#125;BTNode;</span><br><span class="line"></span><br><span class="line">BTNode *Preorder_Create_BTree(BTNode *T)</span><br><span class="line">&#123;</span><br><span class="line">char ch;</span><br><span class="line">ch &#x3D; getchar(); getchar();</span><br><span class="line">if(ch&#x3D;&#x3D;NULLKY)</span><br><span class="line">&#123;</span><br><span class="line">T&#x3D;NULL;</span><br><span class="line">return T;</span><br><span class="line">&#125;</span><br><span class="line">else&#123;</span><br><span class="line">T&#x3D;(BTNode *)malloc(sizeof(BTNode));</span><br><span class="line">T-&gt;data&#x3D;ch;</span><br><span class="line">Preorder_Creat_BTree(T-&gt;Lchild);</span><br><span class="line">Preorder_Creat_BTree(T-&gt;Rchild);</span><br><span class="line">return T;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>求二叉树的深度</li></ol><p>利用层次遍历可以直接求得二叉树的深度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_NODE 50</span><br><span class="line">int search_depth(BTNode *T)</span><br><span class="line">&#123;</span><br><span class="line">BTNode *Queue[MAX_NODE], *p&#x3D;T;</span><br><span class="line">int front&#x3D;0,rear&#x3D;0,depth&#x3D;0,level; # level总是指向访问层的最后一个结点在队列的位置</span><br><span class="line">if(T!&#x3D;NULL)</span><br><span class="line">&#123;</span><br><span class="line">Queue[++rear]&#x3D;p; # 根结点入队</span><br><span class="line">level &#x3D; rear; # 根是第一层的最后一个结点</span><br><span class="line">while(front&lt;rear)</span><br><span class="line">&#123;</span><br><span class="line">p&#x3D;Queue[++front];</span><br><span class="line">if(p-&gt;Lchild!&#x3D;NULL) Queue[++rear]&#x3D;p; # 左结点入队</span><br><span class="line">if(p-&gt;Rchild!&#x3D;NULL) Queue[++rear]&#x3D;p; # 右结点入队</span><br><span class="line"># 正好访问的是当前层的最后一个结点</span><br><span class="line">if(front&#x3D;&#x3D;level)&#123;</span><br><span class="line">depth++;</span><br><span class="line">level&#x3D;rear;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-4-线索二叉树的基本概念和构造"><a href="#1-4-线索二叉树的基本概念和构造" class="headerlink" title="1.4 线索二叉树的基本概念和构造"></a>1.4 线索二叉树的基本概念和构造</h2><p>（1）线索二叉树的定义</p><p>为了保留结点在某种遍历序列中直接前驱和直接后继的位置信息，可以利用具有$n$个结点的二叉树中的叶子节点和一度节点的$n+1$的空指针域来表示。线索二叉树便利时可不需要栈，也不需要递归了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef struct BiThrNode</span><br><span class="line">&#123;</span><br><span class="line">ElemType data;</span><br><span class="line">struct BiTreeNode *Lchild, *Rchild;</span><br><span class="line">int Ltag, Rtag;</span><br><span class="line">&#125;BiThrNode;</span><br></pre></td></tr></table></figure><p>（2）线索二叉树的结构</p><table><thead><tr><th align="center">lchild</th><th align="center">LTag</th><th align="center">data</th><th align="center">RTag</th><th align="center">rchild</th></tr></thead></table><p>若节点有左子树，则左指针lchild指示其左孩子（LTag=0）；否则，令指针指示其前驱（LTag=1）<br>若节点有右子树，则右指针rchild指示其右孩子（RTag=0）；否则，令指针指示其后继（RTag=1）</p><p>由于序列可由不同的遍历方法得到，因此线索树有先序线索二叉树、中序线索二叉树和后续线索二叉树</p><h1 id="2-树和森林"><a href="#2-树和森林" class="headerlink" title="2 树和森林"></a>2 树和森林</h1><h2 id="2-1-树的存储结构"><a href="#2-1-树的存储结构" class="headerlink" title="2.1 树的存储结构"></a>2.1 树的存储结构</h2><p>树的存储有多种方式，既可以是顺序存储也可以使链式存储，但是无论采用何种存储方式，都要求存储结构不但能够存储各结点本身的数据信息，还要能唯一地反映树中各结点之间的逻辑关系。</p><p>（1）双亲表示法</p><p>每个结点都有唯一的一个双亲结点，根据这一特性，可用有一组连续的存储空间（一维数组）存储树中的各个结点，数组中的一个元素表示树中的一个结点，数组元素为结构体类型，其中包含结点本身的信息以及结点的双亲结点在数组中的序号</p><p><img src="https://note.youdao.com/yws/api/personal/file/75607BFFC3A8450EA03EE96468E42F6D?method=download&shareKey=5539f5c0d7c04ef62aca513e038e96d0" alt></p><p>（2）孩子链表示法</p><p>主体是一个与结点个数一样大小的一维数组，数组的每一个元素有两个域组成，一个域用来存放结点信息，另一个用来存放指针，该指针指向由该节点孩子组成的单链表的首位置。单链表的结构也由两个域组成，一个存放孩子结点在一维数组中的序号，另一个是指针域，指向下一个孩子。</p><p><img src="https://note.youdao.com/yws/api/personal/file/8A42544EBBA44326BBA5666F33BE24A1?method=download&shareKey=4c688f9694b88b0728ab777026686f16" alt></p><p>（3）孩子兄弟表示法</p><p>在树中，每个结点除信息域外，再增加两个分别指向该节点的第一个孩子结点和下一个兄弟结点的指针</p><p><img src="https://note.youdao.com/yws/api/personal/file/FA250D1719794C3C9882EF5BCF3D863F?method=download&shareKey=91bbd9735987030fe5179f337c18e88a" alt></p><h2 id="2-2-森林和二叉树的转换"><a href="#2-2-森林和二叉树的转换" class="headerlink" title="2.2 森林和二叉树的转换"></a>2.2 森林和二叉树的转换</h2><p>（1）树转换为二叉树</p><ol><li>树中所有相邻兄弟之间加一条连线</li><li>对树中的每个结点，只保留它与第一个孩子结点之间的连线，删除它与其他孩子结点之间的连线</li><li>以树的根结点为轴心，将整棵树顺时针转动一定的角度，使之结构层次分明</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/EE4E54CB8140417F94E0F1FBD4E8935E?method=download&shareKey=178b6538a41ec660e9715ef1be1eb972" alt></p><p>（2）二叉树转为树</p><ol><li>加虚线，若某结点$i$是其父结点的左子树的根结点，则将该结点$i$的右子结点以及沿右子链不断地搜索所有的右子结点，将所有这些右子结点与$i$结点的父结点之间加虚线相连</li><li>去连线，去掉二叉树所有父结点与其右子结点之间的连线</li><li>规整化，将各结点按层次排列且将所有的虚线变为实线</li></ol><p>（3）森林转为二叉树</p><ol><li>将森林中的每棵树转化成相应的二叉树</li><li>第一课二叉树不动，从第二棵二叉树开始，依次把后一棵二叉树的根结点作为前一棵二叉树根结点的右孩子，当所有二叉树连起来后，此时得到的二叉树就是由森林转换得到的二叉树</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/1396EA2DA83C47B99970805C171BF8FA?method=download&shareKey=dd8d3b3b3470844848c0236d36c194eb" alt></p><p>（4）二叉树转为森林</p><ol><li>去连线，将二叉树B的根结点与其右子结点以及沿右子结点链方向的所有右子结点的连线全部去掉，得到若干棵孤立的二叉树，每一颗就是原来森林F中的树一次对应的二叉树</li><li>二叉树的还原，将各棵孤立的二叉树按二叉树还原为树的方法还原成一般的树</li></ol><h2 id="2-3-树和森林的遍历"><a href="#2-3-树和森林的遍历" class="headerlink" title="2.3 树和森林的遍历"></a>2.3 树和森林的遍历</h2><h3 id="2-3-1-树的遍历"><a href="#2-3-1-树的遍历" class="headerlink" title="2.3.1 树的遍历"></a>2.3.1 树的遍历</h3><p>（1）先根遍历</p><ol><li>访问根结点</li><li>按照从左到右的顺序先根遍历根结点的每一颗子树</li></ol><p>（2）后根遍历</p><ol><li>按照从左到右的顺序后根遍历结点的每一颗子树</li><li>访问根结点</li></ol><p>树的先根遍历与其转换的相应二叉树的先序遍历的结果序列相同；</p><p>树的后根遍历与其转换的相应二叉树的中序遍历结果序列相同</p><h3 id="2-3-2-森林的遍历"><a href="#2-3-2-森林的遍历" class="headerlink" title="2.3.2 森林的遍历"></a>2.3.2 森林的遍历</h3><p>（1）前序遍历</p><ol><li>访问森林中第一棵树的根结点</li><li>前序遍历第一课树的根结点的子树</li><li>前序遍历去掉地棵树后的子森林</li></ol><p>（2）中序遍历</p><ol><li>中序遍历第一课树的根结点的子树</li><li>访问森林中第一棵树的根结点</li><li>中序遍历去掉第一棵树后的子森林</li></ol><p>森林的前序遍历和中序遍历与所转换的二叉树的先序遍历和中序遍历的结果序列相同</p><h1 id="3-树的应用"><a href="#3-树的应用" class="headerlink" title="3 树的应用"></a>3 树的应用</h1><h2 id="3-1-二叉排序树"><a href="#3-1-二叉排序树" class="headerlink" title="3.1 二叉排序树"></a>3.1 二叉排序树</h2><p>（1）二叉排序树的性质</p><ol><li>若左子树不空，则左子树上所有结点的值均小于根节点的恶值；若右子树不空，则右子树所有结点的值均大于根结点的值</li><li>左右子树也都是二叉排序树</li></ol><p>若按中序遍历一颗二叉排序树，所得到的结点序列是一个递增序列，通常取二叉链表作为二叉排序树的存储结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef struct Node</span><br><span class="line">&#123;</span><br><span class="line">KeyType key; # 关键字</span><br><span class="line">...# 其他数据域</span><br><span class="line">struct Node *Lchild, *Rchild;</span><br><span class="line">&#125;BSTNode;</span><br></pre></td></tr></table></figure><p>（2）二叉排序树查找过程</p><ol><li>若查找树为空，查找失败</li><li>查找树非空，将给定值key与查找树的根结点关键码比较</li><li>若相等，查找成功，结束查找过程，否则<ul><li>当key小于根结点关键码，查找将在以左孩子为根的子树上继续进行，转1</li><li>当给key大于根结点关键码，查找将在以右孩子为根的子树上继续进行，转1</li></ul></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">（1）递归算法</span><br><span class="line">BSNode *BST_Search(BSTNode *T, KeyType key)</span><br><span class="line">&#123;</span><br><span class="line">if(T&#x3D;&#x3D;NULL) return NULL;</span><br><span class="line">else&#123;</span><br><span class="line">if(T-&gt;key&#x3D;&#x3D;key) return T;</span><br><span class="line">else if(key&lt; T-&gt;key) return BST_Search(T-&gt;Lchild,key);</span><br><span class="line">else return BST_Search(T-&gt;Rchild,key);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">(2) 非递归算法</span><br><span class="line">BSTNode *BST_Search(BSTNode *T, keyType key)</span><br><span class="line">&#123;</span><br><span class="line">BSTNode p&#x3D;T;</span><br><span class="line">while(p!&#x3D;NULL &amp;&amp; p-&gt;key!&#x3D;key)</span><br><span class="line">&#123;</span><br><span class="line">if(key&lt; p-key) p&#x3D;p-&gt;Lchild;</span><br><span class="line">else p&#x3D;p-&gt;Rchild;</span><br><span class="line">&#125;</span><br><span class="line">if(p!&#x3D;NULL-&gt;key&#x3D;&#x3D;key) return p;</span><br><span class="line">else return NULL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）二叉排序树插入操作和构造一棵二叉排序树</p><p>设待插入节点的关键码为key，为将其插入，先要在二叉排序树中进行查找，若查找成功，不用插入；若查找不成功，则插入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">（1）递归算法</span><br><span class="line">void Insert_BST(BSTNode *T, keyType key)</span><br><span class="line">&#123;</span><br><span class="line">BSTNode *x;</span><br><span class="line">x &#x3D; (BSTNode *)malloc(sizeof(BSTNode));</span><br><span class="line">x-&gt;key &#x3D; key; x-&gt;Lchild&#x3D;x-&gt;Rchild&#x3D;NULL;</span><br><span class="line">if(T&#x3D;&#x3D;NULL) T&#x3D;x;</span><br><span class="line">else&#123;</span><br><span class="line">if(T-&gt;key&#x3D;&#x3D; x-&gt;key) return; # 已有结点</span><br><span class="line">else if(x-&gt;key &lt; T-&gt;key)&#123;</span><br><span class="line">Inser_BST(T-&gt;Lchild,key);</span><br><span class="line">&#125;</span><br><span class="line">else Insert_BST(T-&gt;Rchild, key);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">（2）非递归写法</span><br></pre></td></tr></table></figure><p>（4）二叉排序树删除操作<br>从BST树上删除一个节点，仍然要保证删除后满足BST的性质，设被删除结点为p，其父结点为f</p><ol><li>若 p 是叶子结点： 直接删除 p。</li><li>若 p 只有一棵子树(左子树或右子树)：直接用 p 的左子树(或右子树)取代 p 的位置而成为 f 的一棵子树。原来 p 是 f 的左子树，则 p 的子树为 f 的左子树；原来 p 是 f 的右子树，则 p 的子树为 f 的右子树。</li><li>若 p 既有左子树又有右子树 ：<ul><li>a、用 p 的直接前驱结点代替 p。即从 p 的左子树中选择值最大的结点 s 放在 p 的位置(用结点 s 的内容替换结点 p 内容)，然后删除结点 s。s 是 p 的左子树中的最右边的结点且没有右子树，对 s 的删除同 2</li><li>b、用 p 的直接后继结点代替p。即从 p 的右子树中选择值最小的结点 s 放在 p 的位置(用结点 s 的内容替换结点 p 内容)，然后删除结点 s。s 是 p 的右子树中的最左边的结点且没有左子树，对 s 的删除同 2</li></ul></li></ol><h2 id="3-2-平衡二叉树"><a href="#3-2-平衡二叉树" class="headerlink" title="3.2 平衡二叉树"></a>3.2 平衡二叉树</h2><p>具有下列性质的二叉排序树：左子树和右子树都是平衡二叉树，且左子树和右子树的高度之差的绝对值不超过一</p><p>结点类型定义</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedefstructBNode</span><br><span class="line">&#123;KeyTypekey ； &#x2F;*关键字域*&#x2F;</span><br><span class="line"> intBfactor ；&#x2F;*平衡因子域*&#x2F;</span><br><span class="line">…&#x2F;*其它数据域*&#x2F;</span><br><span class="line">structBNode*Lchild，*Rchild ；</span><br><span class="line">&#125;BSTNode ；</span><br></pre></td></tr></table></figure><p>（1）LL旋转</p><p>插入x使结点a失去平衡，通过顺时针旋转调整</p><ol><li>用b取代a的位置</li><li>a成为b的右子树的根结点</li><li>b原来的右子树作为a的左子树<br><img src="https://note.youdao.com/yws/api/personal/file/A8C880E9070E4BCC80D88E2C693BA16A?method=download&shareKey=a1fb1ffd7ee5d74e98528ca8bebe6d57" alt></li></ol><p>（2）LR旋转</p><p>插入x使结点a失去平衡，通过LR旋转</p><ol><li>先以b进行一次逆时针旋转（将以b为根的子树旋转为以c为根）</li><li>以a进行一次顺时针旋转，将整棵子树旋转以c为根</li><li>c的右子树移到a的左子树位置，c的左子树移到b的右子树位置</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/F6D908CCFFB6491F8511CF4CC0C3B1AB?method=download&shareKey=ee74a5e0fd169044915253fc53c2e363" alt></p><p>（3）RL旋转</p><p>插入x使结点a失去平衡，通过RL旋转</p><ol><li>先以b进行一次顺时针旋转</li><li>再以a进行一次逆时针旋转，将整棵子树（以a为根）旋转为以c为根</li><li>c的右子树移到b的左子树，c的左子树移到a的右子树</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/10E450C657424D2DA03FBD2C10AE1EE5?method=download&shareKey=e078245da33388048e5785f4c9fbaef0" alt></p><p>（4）RR旋转</p><p>插入x使结点a失去平衡，通过RR旋转</p><ol><li>用b取代a的位置</li><li>a作为b的左子树的根结点</li><li>b原来的左子树作为a的右子树</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/EAD2CBB56809414793546497AD6114FC?method=download&shareKey=d48eb4d2a65c980204ed747905b4ef89" alt></p><h2 id="3-3-哈夫曼树和哈夫曼编码"><a href="#3-3-哈夫曼树和哈夫曼编码" class="headerlink" title="3.3 哈夫曼树和哈夫曼编码"></a>3.3 哈夫曼树和哈夫曼编码</h2><p>（1）Huffman树的构造</p><ol><li>根据n个权值，构造哈夫曼树</li><li>选取两棵根结点权值最小的树作为左、右子树构造一棵新的二叉树，且新的二叉树根结点权值为其左、右子树根结点的权值之和</li><li>重复2操作，知道所有权值都使用上</li></ol><p>（2）Huffman编码</p><p>规定左分支代表“0”，右分支代表“1”。从根结点到每个叶子结点所经历的路径上的字符串，为该节点所对应的编码</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-二叉树&quot;&gt;&lt;a href=&quot;#1-二叉树&quot; class=&quot;headerlink&quot; title=&quot;1 二叉树&quot;&gt;&lt;/a&gt;1 二叉树&lt;/h1&gt;&lt;h2 id=&quot;1-1-二叉树的定义及其主要特性&quot;&gt;&lt;a href=&quot;#1-1-二叉树的定义及其主要特性&quot; class=&quot;headerlink&quot; title=&quot;1.1 二叉树的定义及其主要特性&quot;&gt;&lt;/a&gt;1.1 二叉树的定义及其主要特性&lt;/h2&gt;&lt;p&gt;二叉树是有序的，即使树中节点只有一颗子树，也要区分它是左子树还是右子树&lt;/p&gt;
&lt;p&gt;二叉树具有的性质：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一颗非空二叉树的第$i$层上最多有$2^{i-1}$个结点$（i&amp;gt;=1）$&lt;/li&gt;
&lt;li&gt;一颗深度为$k$的二叉树中，最多具有$2^k-1$个结点&lt;/li&gt;
&lt;li&gt;对于一颗非空的二叉树，如果叶子节点数为$n_0$，度数为2的结点数为$n_2$，则有$n_0=n_2+1$&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数据结构总结（二）：栈、队列和数组</title>
    <link href="https://liangggggg.github.io/2020/08/13/Data2/"/>
    <id>https://liangggggg.github.io/2020/08/13/Data2/</id>
    <published>2020-08-13T00:33:42.000Z</published>
    <updated>2020-08-21T01:31:04.186Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-栈"><a href="#1-栈" class="headerlink" title="1 栈"></a>1 栈</h1><p>限定仅在表尾进行插入或删除操作的线性表</p><p><img src="https://note.youdao.com/yws/api/personal/file/E759729F50D449788BC9B52C9C1611E9?method=download&shareKey=4708c48d5e45c8fd0af3e6ec588b1381" alt></p><h2 id="1-1-栈的顺序存储结构"><a href="#1-1-栈的顺序存储结构" class="headerlink" title="1.1 栈的顺序存储结构"></a>1.1 栈的顺序存储结构</h2><p>栈的顺序存储结构简称为顺序栈，用一维数组来存储栈。根据数组是否可以根据需要增大，又可分为静态顺序栈和动态顺序栈</p><a id="more"></a><p>（1）动态顺序栈</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">基本操作实现</span><br><span class="line">1 栈的定义</span><br><span class="line"># define STACK_SIZE 100;</span><br><span class="line"># define STACKINCREMENT 10;</span><br><span class="line"># typedef int ElemType;</span><br><span class="line"></span><br><span class="line">typedef struct sqstack</span><br><span class="line">&#123;</span><br><span class="line">ElemType *bottem; # 栈不存在时为NULL</span><br><span class="line">ElemType *top; # 栈顶指针</span><br><span class="line">int stacksize; # 当前已分空间，以元素为单位</span><br><span class="line">&#125;SqStack;</span><br><span class="line"></span><br><span class="line">2 栈的初始化</span><br><span class="line">SqStack Init_Stack(void)</span><br><span class="line">&#123;</span><br><span class="line">SqStack S;</span><br><span class="line">S.bottom &#x3D; (ElemType *)malloc(STACK_SIZE * sizeof(ElemType));</span><br><span class="line">if (!S.bottom) return ERROR;</span><br><span class="line">S.top &#x3D; S.bottom; # 栈空时栈顶和栈底指针相同</span><br><span class="line">S.stacksize &#x3D; STACK_SIZE;</span><br><span class="line">return S;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">3 压栈</span><br><span class="line">Status push(SqStack &amp;S, ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">if(S.top-S.bottom&gt;&#x3D;S.sstacksize-1)</span><br><span class="line">&#123;# 栈满，追加空间</span><br><span class="line">S.bottom&#x3D;(ElemType *)realloc(S.bottom, (S.STACKINCRMENT+STACK_SIEZE)*sizeof(ElemType));</span><br><span class="line">if(!S.bottom) return ERROR;</span><br><span class="line">S.top &#x3D; S.bottom+S.stacksize-1;</span><br><span class="line">S.stacksize+&#x3D;STACKINCREMENT;</span><br><span class="line">&#125;</span><br><span class="line">S.top &#x3D; e; S.top++; # 栈顶指针+1，e称为新的栈顶</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">4 弹栈</span><br><span class="line">Status pop(SqStack &amp;S, ElemType *e)</span><br><span class="line">&#123;</span><br><span class="line">if(S.top&#x3D;&#x3D;S.bottom) return ERROR;</span><br><span class="line">S.top--; *e &#x3D; S.top;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）静态顺序栈</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">基本操作的实现</span><br><span class="line">1 栈的类型定义</span><br><span class="line"># define MAX_STACK_SIZE 100</span><br><span class="line">typedef int ElemTypde;</span><br><span class="line">typedef struct Sqstack</span><br><span class="line">&#123;</span><br><span class="line">ElemType stack_array[MAX_STACK_SIZE];</span><br><span class="line">int top;</span><br><span class="line">&#125;SqStack;</span><br><span class="line"></span><br><span class="line">2 栈的初始化</span><br><span class="line">SqStack Init_Stack(void)</span><br><span class="line">&#123;</span><br><span class="line">SqStack S;</span><br><span class="line">S.top &#x3D; 0;</span><br><span class="line">return S;</span><br><span class="line">&#125;</span><br><span class="line">3 压栈</span><br><span class="line">Status push(SqStack &amp;S, ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">if(S.top&#x3D;&#x3D;MAX_STACK_SIZE-1) return ERROR;</span><br><span class="line">S.top++;</span><br><span class="line">S.stack_array[S.top]&#x3D;e</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line">4 弹栈</span><br><span class="line">Status pop(SqStack &amp;S, ElemType *e)</span><br><span class="line">&#123;</span><br><span class="line">if(S.top&#x3D;&#x3D;0) return ERROR;</span><br><span class="line">*e &#x3D; S.stack_array[S.top];</span><br><span class="line">S.top--;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）栈的链式存储结构</p><p>链栈，是运算受限的单链表，其插入和删除操作只能在表头位置上进行，栈顶指针top就是链表的头指针</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">1 栈的定义</span><br><span class="line">typedef struct Stack_Node</span><br><span class="line">&#123;</span><br><span class="line">ElemType data;</span><br><span class="line">Struct Stack_Node *next;</span><br><span class="line">&#125;Stack_Node;</span><br><span class="line"></span><br><span class="line">2 栈的初始化</span><br><span class="line">Stack_Node *Init_Link_Stack(void)</span><br><span class="line">&#123;</span><br><span class="line">Stack_Node *top;</span><br><span class="line">top &#x3D; (Stack_Node *)malloc(sizeof(Stack_Node));</span><br><span class="line">top-&gt;next&#x3D;NULL;</span><br><span class="line">return top;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">3 压栈</span><br><span class="line">Status push(Stack_Node *top, ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">Stack_Node *p;</span><br><span class="line">p &#x3D; (Stack_Node *)malloc(sizeof(Stack_Node));</span><br><span class="line">if(!p) return ERROR;</span><br><span class="line">p-&gt;data &#x3D; e;</span><br><span class="line">p-&gt;next &#x3D; top-&gt;next;</span><br><span class="line">top-&gt;next &#x3D; p;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">4 出栈</span><br><span class="line">Status pop(Stack_Node *top, ElemType *e)</span><br><span class="line">&#123;</span><br><span class="line">Stack_Node *p;</span><br><span class="line">if(top-&gt;next&#x3D;NULL) return ERROR;</span><br><span class="line">p &#x3D; top-&gt;next; *e&#x3D;p-&gt;data;</span><br><span class="line">top-&gt;next&#x3D;p-&gt;next;</span><br><span class="line">free(p)</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/179D6F1B2AA8401183DAD94F42E83FE9?method=download&shareKey=2b508c9cf73a4e6f8d5eb58630dc5f0c" alt></p><p><img src="https://note.youdao.com/yws/api/personal/file/8ABC92C47E6C482CBEB192D618EF06B8?method=download&shareKey=4d35165ff818a4551ec522a880c9c59a" alt></p><h2 id="1-2-栈的应用"><a href="#1-2-栈的应用" class="headerlink" title="1.2 栈的应用"></a>1.2 栈的应用</h2><p>（1）数制转换<br>十进制数N和其他d进制数的转换是计算机实现计算的基本问题，最简单算法基于：$N=(N\ div\ d)* d + N\ mod\ d$</p><p>采用静态顺序栈方法实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">将十进制数N转化为d进制数</span><br><span class="line">void conversion(int n, int d)</span><br><span class="line">&#123;</span><br><span class="line">SqStack S; int k, *e;</span><br><span class="line">S&#x3D;Init_Stack();</span><br><span class="line"># 求所有的余数，进栈</span><br><span class="line">while(n&gt;0)</span><br><span class="line">&#123;</span><br><span class="line">k &#x3D; n%d;</span><br><span class="line">push(S,k);</span><br><span class="line">n&#x3D;n&#x2F;d;</span><br><span class="line">&#125;</span><br><span class="line"># 栈不空时，输出</span><br><span class="line">while(S.top!&#x3D;0)</span><br><span class="line">&#123;</span><br><span class="line">pop(S,e);</span><br><span class="line">printf(&quot;%1d&quot;, *e);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）括号匹配</p><p>设置一个栈，当读到左括号时，左括号进栈，当读到右括号时，则从栈中弹出一个元素，与读到的左括号进行匹配，若匹配成功则继续读入；否则匹配失败</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">#define TRUE 0</span><br><span class="line">#define FALSE -1</span><br><span class="line">SqStack S;</span><br><span class="line">S &#x3D; Init_Stack();</span><br><span class="line">int Match_Brackets()</span><br><span class="line">&#123;</span><br><span class="line">char ch, x;</span><br><span class="line">scanf(&quot;%c&quot;, &amp;ch);</span><br><span class="line">while(asc(ch)!&#x3D;13)</span><br><span class="line">&#123;</span><br><span class="line">if((ch&#x3D;&#x3D;&#39;(&#39;)||(ch&#x3D;&#x3D;&#39;[&#39;)) push(S,ch);</span><br><span class="line">else if(ch&#x3D;&#x3D;&#39;]&#39;)</span><br><span class="line">&#123;</span><br><span class="line">x&#x3D;pop(S);</span><br><span class="line">if(x!&#x3D;&#39;[&#39;)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;&#39;]&#39;括号不匹配&quot;);</span><br><span class="line">return FALSE;&#125;&#125;</span><br><span class="line">else if(ch&#x3D;&#x3D;&#39;)&#39;)</span><br><span class="line">&#123;</span><br><span class="line">x&#x3D;pop(S);</span><br><span class="line">if(x!&#x3D;&#39;(&#39;)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;&#39;(&#39;括号不匹配&quot;)，</span><br><span class="line">return FALSE;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">if(S.top!&#x3D;0)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;括号数量不匹配&quot;);</span><br><span class="line">return FALSE;&#125;</span><br><span class="line">else return TRUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）递归</p><p>为保证递归调用正确执行，系统设立一个“递归工作栈”，作为整个递归调用过程期间使用的数据存储区。每一层包含的信息如：参数，局部变量、上一层的返回地址构建一个“工作记录”。每进入一层递归栈，就产生一个新的工作记录压入栈顶；每退出一层递归，就从栈顶弹出一个工作记录。</p><h1 id="2-队列"><a href="#2-队列" class="headerlink" title="2 队列"></a>2 队列</h1><p>插入在表一端进行，而删除在表的另一端进行，把允许插入的一端叫队尾，允许删除的一端叫队头</p><h2 id="2-1-队列的顺序存储结构"><a href="#2-1-队列的顺序存储结构" class="headerlink" title="2.1 队列的顺序存储结构"></a>2.1 队列的顺序存储结构</h2><p><img src="https://note.youdao.com/yws/api/personal/file/6E8BB975C5E840FA836368D66975CA58?method=download&shareKey=dff56d5e9e448f78b30951418edd884a" alt></p><p>当尾指针移动到最后，再有元素入队就会溢出，但是此时队列并未真正的“满员”，这种现象称为“假溢出”，为了解决假溢出，可以将队列的数据区看成首尾相接的循环结构，头尾指针的关系不变，将其称为“循环队列”</p><p>约定以“队列头指针在队列尾指针的下一位置（指换装的下一位置）”上作为队列满的标志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">队空特征：front&#x3D;rear;</span><br><span class="line">队满特征：front&#x3D;(rear+1)%MAX_QUEUE_SIZE;</span><br><span class="line">队列长度：L&#x3D;(MAX_QUEUE_SIZE+rear-front)%MAX_QUEUE_SIZE；</span><br><span class="line"></span><br><span class="line">静态顺序队列，其类型定义如下：</span><br><span class="line"># define MAX_QUEUE_SIZE 100</span><br><span class="line">typedef struct queue</span><br><span class="line">&#123;</span><br><span class="line">ElemType Queue_array[MAX_QUEUE_SIZE];</span><br><span class="line">int front;</span><br><span class="line">int rear;</span><br><span class="line">&#125;SqQueue;</span><br><span class="line"></span><br><span class="line">循环队列的基本操作</span><br><span class="line">1 循环队列的初始化</span><br><span class="line">Status Init_CirQueue(* &amp;Q)</span><br><span class="line">&#123;</span><br><span class="line">Q &#x3D; (SqQueue *)malloc(sizeof(SqQueue));</span><br><span class="line">if(Q&#x3D;&#x3D;NULL) return ERROR;</span><br><span class="line">Q-&gt;front&#x3D; Q-&gt;rear&#x3D;0;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">2 入队操作</span><br><span class="line">Status Insert_CirQueue(SqQueue *&amp;Q, ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">if((Q-&gt;rear+1)%MAX_QUEUE_SIZE&#x3D;&#x3D;Q-&gt;front) return ERROR;</span><br><span class="line">Q-&gt;Queue_array[Q-&gt;rear] &#x3D;e;</span><br><span class="line">Q-&gt;rear&#x3D;(Q-&gt;rear+1)%MAX_QUEUE_SIZE;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">3 出队操作</span><br><span class="line">Status Delete_CireQueue(SqQueue *&amp;Q, ElemType *x)</span><br><span class="line">&#123;</span><br><span class="line">if(Q-&gt;front&#x3D;&#x3D;Q-&gt;rear) return ERROR;</span><br><span class="line">*x &#x3D; Q-&gt;Queue_array[Q-&gt;front];</span><br><span class="line">Q-&gt;front &#x3D; (Q-&gt;front+1)% MAX_QUEUE_SIZE;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-2-队列的链式存储结构"><a href="#2-2-队列的链式存储结构" class="headerlink" title="2.2 队列的链式存储结构"></a>2.2 队列的链式存储结构</h2><p>队列的链式存储结构简称为链队列，是限制仅在表头进行删除操作和表尾进行插入操作的单链表，需要两类不同的结点：数据元素结点，队列的队首指针和队尾指针的结点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">元素结点的定义</span><br><span class="line">typedef struct Qnode</span><br><span class="line">&#123;</span><br><span class="line">ElemType data;</span><br><span class="line">Struct Qnode *next;</span><br><span class="line">&#125;QNode;</span><br><span class="line">指针结点类型定义：</span><br><span class="line">typedef struct link_queue</span><br><span class="line">&#123;</span><br><span class="line">QNode *front, *rear;</span><br><span class="line">&#125;Link_Queue;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/3B00BB79D4854E1FAD7625888C9A5550?method=download&shareKey=b324c8b770023286850dac1c9c3e30fb" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">1 链队列初始化</span><br><span class="line">LinkQueue *Init_Link_Queue(void)</span><br><span class="line">&#123;</span><br><span class="line">Link_Queue *Q; </span><br><span class="line">QNode *p;</span><br><span class="line">p &#x3D; (QNode *)malloc(sizeof(QNode)) # 开辟头结点</span><br><span class="line">p-&gt;next &#x3D; NULL;</span><br><span class="line">Q &#x3D; (Link_Queue *)malloc(sizeof(Link_Queue)); # 开辟链队的指针结点</span><br><span class="line">Q.front &#x3D; Q.rear&#x3D;p;</span><br><span class="line">return Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">2 链队列的入队</span><br><span class="line">在已知队列的队尾插入一个元素e,即修改队尾指针Q.rear</span><br><span class="line">Status Insert_LinkQueue(Link_Queue *Q, ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">QNode *p;</span><br><span class="line">p &#x3D; (QNode *)malloc(sizeof(QNode)); if(!p) return ERROR;</span><br><span class="line">p-&gt;data&#x3D;e; p-&gt;next&#x3D;NULL;</span><br><span class="line">Q-&gt;rear-&gt;next&#x3D;p;</span><br><span class="line">Q-&gt;rear&#x3D;p;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">3 链队列的出队</span><br><span class="line">Status Delete_LinkQueue(LinkQueue *Q, ElemType *x)</span><br><span class="line">&#123;</span><br><span class="line">QNode *p;</span><br><span class="line">if(Q-&gt;front &#x3D; Q-&gt;rear) return ERROR;</span><br><span class="line">p&#x3D;Q-&gt;front-&gt;next;</span><br><span class="line">*x &#x3D; p-&gt;data;</span><br><span class="line">Q-&gt;front-&gt;next &#x3D; p-&gt;next;</span><br><span class="line">if(p&#x3D;&#x3D;Q-&gt;rear) Q-&gt;rear&#x3D;Q-&gt;front; # 当队列只有一个结点时应防止丢失队尾指针</span><br><span class="line">free(p);</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-特殊矩阵的压缩存储"><a href="#3-特殊矩阵的压缩存储" class="headerlink" title="3 特殊矩阵的压缩存储"></a>3 特殊矩阵的压缩存储</h1><h2 id="3-1-数组"><a href="#3-1-数组" class="headerlink" title="3.1 数组"></a>3.1 数组</h2><p>数组是一组对偶（下标值，数据元素值）的集合，并且该序列必须存储在一块地址连续的存储单元中</p><ul><li>数组中的元素数据具有相同数据类型</li><li>数组是一种随机存取结构，给定一组下标，就可以访问与其对应的数据元素</li><li>数组中的数据元素个数是固定的</li></ul><p>二维数组是最简单的多维数组，通常有两种顺序存储方式</p><p>（1）行优先顺序：将数组元素按行排列，第$i+1$个行向量紧接在第$i$个行向量后面</p><p>设有二维数组$A=(a_{ij})m * n$，若每个元素占有的存储单元为1个，$LOC[a_{11}]$表示数组的首地址</p><p>二维数组中，任意元素$a_{ij}$的地址是：<br>$$LOC[a_{ij}]=LOC[a_{11}]+[(i-1) * n+(j-1)] * 1$$</p><p>（2）列优先顺序：将数组元素按列排列，第$j+1$个列向量紧接在第$j$个列向量后面</p><p>二维数组中，任意元素$a_{ij}$的地址是：<br>$$LOC[a_{ij}]=LOC[a_{11}]+[(j-1) * m+(i-1)] * 1$$</p><h2 id="3-2-特殊矩阵"><a href="#3-2-特殊矩阵" class="headerlink" title="3.2 特殊矩阵"></a>3.2 特殊矩阵</h2><p>特殊矩阵（对称矩阵，对角矩阵，三角矩阵）压缩矩阵：若多个数据元素的值都相同，则只分配一个元素值的存储空间，且零元素不占存储空间</p><p>（1）对称矩阵</p><p>关于主对角线对称，因此只需存储上三角或下三角即可</p><p>以一维数组$sa[n(n+1)/2]$作为n阶对称矩阵A的存储结构，则$sa[k]$和矩阵元$a_{ij}$之间存在着一一对应的关系：</p><p>$$<br>k=<br>\begin{cases}<br>\frac{i(i-1)}{2}+j-1, \  i&gt;=j\\<br>\frac{j(j-1)}{2}+i-1,\ i&lt;j<br>\end{cases}<br>$$</p><p>（2）三角矩阵</p><ul><li>下三角矩阵</li></ul><p>在下三角矩阵，主对角线以上的元素是一个常量，存完下三角中的元素之后，紧接着储存对角线上方的常量，因为是同一个常数，所以存一个即可</p><p>共存储了$n(n+1)/2$个元素，设存入向量$sa=[k]$中，$k$与$i，j$的对应关系为:</p><p>$$<br>k=<br>\begin{cases}<br>\frac{i(i-1)}{2}+j-1, \  i&gt;=j\\<br>\frac{n(n-1)}{2},\ i&lt;j<br>\end{cases}<br>$$</p><ul><li>上三角矩阵<br>和下三角矩阵类似，其对应关系如下：<br>$$<br>k=<br>\begin{cases}<br>\frac{(2n-i+2)(i-1)}{2}+j-1, \  i&gt;=j\\<br>\frac{n(n-1)}{2},\ i&lt;j<br>\end{cases}<br>$$</li></ul><p>（3）对角矩阵</p><p>所有非零元素都集中在以主对角线为中心的对角区域，即除了主对角线和它的上下方若干条对角线的元素外，所有其他元素都为零（或同一个常数C）</p><h2 id="3-3-稀疏矩阵"><a href="#3-3-稀疏矩阵" class="headerlink" title="3.3 稀疏矩阵"></a>3.3 稀疏矩阵</h2><p>稀疏矩阵：设矩阵 A 是一个 $n * m$ 的矩阵中有 $s$ 个非零元素，设 $\delta=s/(n * m)$，称$\delta$为稀疏因子，如果某一矩阵的稀疏因子$\delta$满足$\delta&lt;=0.05$ 时称为稀疏矩阵。对于稀疏矩阵，采用压缩存储方法时，只存储非 0 元素。必须存储非 0 元素的行下标值、列下标值、元素值。</p><p><img src="https://note.youdao.com/yws/api/personal/file/60254E2717D14DB39AF9A804B447F040?method=download&shareKey=cc6925679ea8792332ab7da244769187" alt></p><p>（1）三元组顺序表</p><p>若以行序为主序，稀疏矩阵中所有非 0 元素的三元组，就可以得构成该稀疏矩阵的一个三元组顺序表。相应的数据结构定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">（1） 三元组结点定义</span><br><span class="line">#define MAX_SIZE 101 </span><br><span class="line">typedef int elemtype;</span><br><span class="line">typedef struct</span><br><span class="line">&#123;int row; &#x2F;*行下标*&#x2F; </span><br><span class="line">int col; &#x2F;*列下标*&#x2F; </span><br><span class="line">elemtype value; &#x2F;*元素值*&#x2F;</span><br><span class="line">&#125;Triple;</span><br><span class="line">（2） 三元组顺序表定义</span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">int rn;# 行数</span><br><span class="line">int cn; # 列数</span><br><span class="line">int tn; # 非零元素个数</span><br><span class="line">Triple data[MAX_SIZE];</span><br><span class="line">&#125;TMatrix;</span><br></pre></td></tr></table></figure><p>（2）十字链表</p><p>对于稀疏矩阵，当非 0 元素的个数和位置在操作过程中变化较大时，采用链式存储结构表示比三元组的线性表更方便。<br>矩阵中非 0 元素的结点所含的域有：行、列、值、行指针(指向同一行的下一个非 0 元)、<br>列指针(指向同一列的下一个非 0 元)。其次，十字交叉链表还有一个头结点，结点的结构如图所示。</p><p><img src="https://note.youdao.com/yws/api/personal/file/9CBAA88EAE7344A29B1EE9251565FE35?method=download&shareKey=9a5a57e9724f4a833bbf4016fc97ce24" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">typedef struct Clnode</span><br><span class="line">&#123;</span><br><span class="line">int row, col;</span><br><span class="line">elemtype value;</span><br><span class="line">struct Clnode *down, *right;</span><br><span class="line">&#125;QLNode;</span><br><span class="line"></span><br><span class="line">typdef struct Clonde</span><br><span class="line">&#123;</span><br><span class="line">int rn; # 行数</span><br><span class="line">int cn; # 列数</span><br><span class="line">int tn; # 非0元素总数</span><br><span class="line">QLNode *rhead;</span><br><span class="line">QLNode *chead;</span><br><span class="line">&#125;CrossList;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/CF1C494E17F841DB90012A6139364334?method=download&shareKey=42bca25aac0ad5118ff7ee86eefe94ea" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-栈&quot;&gt;&lt;a href=&quot;#1-栈&quot; class=&quot;headerlink&quot; title=&quot;1 栈&quot;&gt;&lt;/a&gt;1 栈&lt;/h1&gt;&lt;p&gt;限定仅在表尾进行插入或删除操作的线性表&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://note.youdao.com/yws/api/personal/file/E759729F50D449788BC9B52C9C1611E9?method=download&amp;shareKey=4708c48d5e45c8fd0af3e6ec588b1381&quot; alt&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-1-栈的顺序存储结构&quot;&gt;&lt;a href=&quot;#1-1-栈的顺序存储结构&quot; class=&quot;headerlink&quot; title=&quot;1.1 栈的顺序存储结构&quot;&gt;&lt;/a&gt;1.1 栈的顺序存储结构&lt;/h2&gt;&lt;p&gt;栈的顺序存储结构简称为顺序栈，用一维数组来存储栈。根据数组是否可以根据需要增大，又可分为静态顺序栈和动态顺序栈&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode学习笔记</title>
    <link href="https://liangggggg.github.io/2020/08/11/leetcode/"/>
    <id>https://liangggggg.github.io/2020/08/11/leetcode/</id>
    <published>2020-08-11T07:47:42.000Z</published>
    <updated>2020-08-21T07:23:47.340Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-数组与矩阵"><a href="#1-数组与矩阵" class="headerlink" title="1 数组与矩阵"></a>1 数组与矩阵</h1><h2 id="Problem-1-数组中重复的数字"><a href="#Problem-1-数组中重复的数字" class="headerlink" title="Problem 1 数组中重复的数字"></a>Problem 1 数组中重复的数字</h2><p>找出数组中重复的数字。</p><p>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">示例 1：</span><br><span class="line"></span><br><span class="line">输入：</span><br><span class="line">[2, 3, 1, 0, 2, 5, 3]</span><br><span class="line">输出：2 或 3</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="方法一：-先排序，然后看相邻元素是否有相同的，直接return-时间O-nlogn-，空间O-1"><a href="#方法一：-先排序，然后看相邻元素是否有相同的，直接return-时间O-nlogn-，空间O-1" class="headerlink" title="方法一： 先排序，然后看相邻元素是否有相同的，直接return,时间O(nlogn)，空间O(1)"></a>方法一： 先排序，然后看相邻元素是否有相同的，直接return,时间O(nlogn)，空间O(1)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findRepeatNumber(self, nums: List[int]) -&gt; int:</span><br><span class="line">        nums.sort()</span><br><span class="line">        pre &#x3D; nums[0]</span><br><span class="line">        n &#x3D; len(nums)</span><br><span class="line">        for index in range(1,n):</span><br><span class="line">            if pre &#x3D;&#x3D; nums[index]:</span><br><span class="line">                return pre</span><br><span class="line">            pre &#x3D; nums[index]</span><br></pre></td></tr></table></figure><h3 id="方法二：使用哈希表，时间O-n-，空间O-n"><a href="#方法二：使用哈希表，时间O-n-，空间O-n" class="headerlink" title="方法二：使用哈希表，时间O(n)，空间O(n)"></a>方法二：使用哈希表，时间O(n)，空间O(n)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findRepeatNumber(self, nums: List[int]) -&gt; int:</span><br><span class="line">        repeatDict &#x3D; &#123;&#125;</span><br><span class="line">        for num in nums:</span><br><span class="line">            if num not in repeatDict:</span><br><span class="line">                repeatDict[num] &#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                return num</span><br></pre></td></tr></table></figure><h2 id="Problem-2-二维数组中的查找"><a href="#Problem-2-二维数组中的查找" class="headerlink" title="Problem 2 二维数组中的查找"></a>Problem 2 二维数组中的查找</h2><p>在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">示例:</span><br><span class="line"></span><br><span class="line">现有矩阵 matrix 如下：</span><br><span class="line">[</span><br><span class="line">  [1,   4,  7, 11, 15],</span><br><span class="line">  [2,   5,  8, 12, 19],</span><br><span class="line">  [3,   6,  9, 16, 22],</span><br><span class="line">  [10, 13, 14, 17, 24],</span><br><span class="line">  [18, 21, 23, 26, 30]</span><br><span class="line">]</span><br><span class="line">给定 target &#x3D; 5，返回 true。</span><br><span class="line"></span><br><span class="line">给定 target &#x3D; 20，返回 false</span><br></pre></td></tr></table></figure><h3 id="方法一：-利用矩阵特点引入标志数"><a href="#方法一：-利用矩阵特点引入标志数" class="headerlink" title="方法一： 利用矩阵特点引入标志数"></a>方法一： 利用矩阵特点引入标志数</h3><ol><li>若flag&gt;target，则target一定在flag所在行的上方，即flag所在行可被消除</li><li>若flag&lt;target, 则target一定在flag所在列的右方，即flag所在列可被消除</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -&gt; bool:</span><br><span class="line">        i, j &#x3D; len(matrix) - 1, 0</span><br><span class="line">        while i &gt;&#x3D; 0 and j &lt; len(matrix[0]):</span><br><span class="line">            if matrix[i][j] &gt; target: i -&#x3D; 1</span><br><span class="line">            elif matrix[i][j] &lt; target: j +&#x3D; 1</span><br><span class="line">            else: return True</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure><h2 id="Problem-3-删除排序数组中的重复项"><a href="#Problem-3-删除排序数组中的重复项" class="headerlink" title="Problem 3 删除排序数组中的重复项"></a>Problem 3 删除排序数组中的重复项</h2><p>给定一个排序数组，你需要在 原地 删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。</p><p>不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">给定 nums &#x3D; [0,0,1,1,1,2,2,3,3,4],</span><br><span class="line"></span><br><span class="line">函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。</span><br><span class="line"></span><br><span class="line">你不需要考虑数组中超出新长度后面的元素</span><br></pre></td></tr></table></figure><h3 id="方法一：使用双指针"><a href="#方法一：使用双指针" class="headerlink" title="方法一：使用双指针"></a>方法一：使用双指针</h3><ol><li>慢指针i从0开始,快指针j从1开始，两个指针每次移动一步</li><li>当指针i与j所指数字不同时，i后移一步，把j的值复制给i，j后移一步</li><li>当i与j所指数字相同，i不动，j后移一步</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def removeDuplicates(self, nums: List[int]) -&gt; int:</span><br><span class="line">        i &#x3D; 0</span><br><span class="line">        j &#x3D; 1</span><br><span class="line">        while j &lt; len(nums):</span><br><span class="line">            if nums[i] &#x3D;&#x3D; nums[j]:</span><br><span class="line">                j+&#x3D;1</span><br><span class="line">            else:</span><br><span class="line">                i+&#x3D;1</span><br><span class="line">                nums[i]&#x3D;nums[j]</span><br><span class="line">        return i+1</span><br></pre></td></tr></table></figure><h2 id="Problem-4"><a href="#Problem-4" class="headerlink" title="Problem 4"></a>Problem 4</h2><h3 id="方法一：每一天做一次清算"><a href="#方法一：每一天做一次清算" class="headerlink" title="方法一：每一天做一次清算"></a>方法一：每一天做一次清算</h3><ol><li>设 tmp 为第 i-1 日买入与第 i 日卖出赚取的利润，即 tmp = prices[i] - prices[i - 1] ；</li><li>当该天利润为正 tmp &gt; 0，则将利润加入总利润 profit；当利润为 00 或为负，则直接跳过；</li><li>遍历完成后，返回总利润 profit。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxProfit(self, prices: List[int]) -&gt; int:</span><br><span class="line">        profit &#x3D; 0</span><br><span class="line">        for i in range(1,len(prices)):</span><br><span class="line">            if prices[i] &gt; prices[i-1]:</span><br><span class="line">                profit +&#x3D; prices[i] - prices[i-1]</span><br><span class="line">        return profit</span><br></pre></td></tr></table></figure><h2 id="Problem-5"><a href="#Problem-5" class="headerlink" title="Problem 5"></a>Problem 5</h2><p>给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入: [1,2,3,4,5,6,7] 和 k &#x3D; 3</span><br><span class="line">输出: [5,6,7,1,2,3,4]</span><br><span class="line">解释:</span><br><span class="line">向右旋转 1 步: [7,1,2,3,4,5,6]</span><br><span class="line">向右旋转 2 步: [6,7,1,2,3,4,5]</span><br><span class="line">向右旋转 3 步: [5,6,7,1,2,3,4]</span><br></pre></td></tr></table></figure><h3 id="方法一：-数组移动使用三次反转"><a href="#方法一：-数组移动使用三次反转" class="headerlink" title="方法一： 数组移动使用三次反转"></a>方法一： 数组移动使用三次反转</h3><p>三次反转</p><p>对于[1,2,3,4,5,6,7]，根据k = k%n，数组分为两段：</p><ul><li>第一段，对应数组下标[0,n-k-1],即[1,2,3,4]</li><li>第二段，对应数组下标[n-k, n-1],即[5,6,7]</li></ul><p>分为三步:</p><ol><li>反转第一段[4,3,2,1,5,6,7]</li><li>反转第二段[4,3,2,1,7,6,5]</li><li>反转整体[5,6,7,1,2,3,4]</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def rotate(self, nums: List[int], k: int) -&gt; None:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Do not return anything, modify nums in-place instead.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        n&#x3D;len(nums)</span><br><span class="line">        k&#x3D;k%n</span><br><span class="line">        def swap(l,r):</span><br><span class="line">            while(l&lt;r):</span><br><span class="line">                nums[l],nums[r]&#x3D;nums[r],nums[l]</span><br><span class="line">                l&#x3D;l+1</span><br><span class="line">                r&#x3D;r-1</span><br><span class="line">        swap(0,n-k-1)</span><br><span class="line">        swap(n-k,n-1)</span><br><span class="line">        swap(0,n-1)</span><br></pre></td></tr></table></figure><h2 id="Problem-6-只出现一次的数字"><a href="#Problem-6-只出现一次的数字" class="headerlink" title="Problem 6 只出现一次的数字"></a>Problem 6 只出现一次的数字</h2><p>给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [2,2,1]</span><br><span class="line">输出: 1</span><br></pre></td></tr></table></figure><h3 id="方法一：位运算"><a href="#方法一：位运算" class="headerlink" title="方法一：位运算"></a>方法一：位运算</h3><p>使用异或的性质</p><ol><li>任何数和本身异或则为0</li><li>任何数和0异或是本身</li><li>异或运算满足交换律</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def singleNumber(self, nums: List[int]) -&gt; int:</span><br><span class="line">        single_number &#x3D; 0</span><br><span class="line">        for num in nums:</span><br><span class="line">            single_number ^&#x3D; num</span><br><span class="line">        return single_number</span><br></pre></td></tr></table></figure><h2 id="Problem-7-两个数组的交集-II"><a href="#Problem-7-两个数组的交集-II" class="headerlink" title="Problem 7 两个数组的交集 II"></a>Problem 7 两个数组的交集 II</h2><p>给定两个数组，编写一个函数来计算它们的交集。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：nums1 &#x3D; [1,2,2,1], nums2 &#x3D; [2,2]</span><br><span class="line">输出：[2,2]</span><br></pre></td></tr></table></figure><h3 id="方法一：-哈希表"><a href="#方法一：-哈希表" class="headerlink" title="方法一： 哈希表"></a>方法一： 哈希表</h3><ul><li>collections.Counter()利用哈希表对元素进行计数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def intersect(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        num1 &#x3D; collections.Counter(nums1)</span><br><span class="line">        num2 &#x3D; collections.Counter(nums2)</span><br><span class="line"># 取与计算交集，返还哈希表字典元素</span><br><span class="line">        num &#x3D; num1 &amp; num2</span><br><span class="line">        return num.elements()</span><br></pre></td></tr></table></figure></li></ul><h3 id="方法二：排序"><a href="#方法二：排序" class="headerlink" title="方法二：排序"></a>方法二：排序</h3><p>如果两个数组是有序的，则可以便捷地计算两个数组的交集。</p><p>首先对两个数组进行排序，然后使用两个指针遍历两个数组。</p><p>初始时，两个指针分别指向两个数组的头部。每次比较两个指针指向的两个数组中的数字，如果两个数字不相等，则将指向较小数字的指针右移一位，如果两个数字相等，将该数字添加到答案，并将两个指针都右移一位。当至少有一个指针超出数组范围时，遍历结束。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def intersect(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        nums1.sort()</span><br><span class="line">        nums2.sort()</span><br><span class="line"></span><br><span class="line">        length1, length2 &#x3D; len(nums1), len(nums2)</span><br><span class="line">        intersection &#x3D; list()</span><br><span class="line">        index1 &#x3D; index2 &#x3D; 0</span><br><span class="line">        while index1 &lt; length1 and index2 &lt; length2:</span><br><span class="line">            if nums1[index1] &lt; nums2[index2]:</span><br><span class="line">                index1 +&#x3D; 1</span><br><span class="line">            elif nums1[index1] &gt; nums2[index2]:</span><br><span class="line">                index2 +&#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                intersection.append(nums1[index1])</span><br><span class="line">                index1 +&#x3D; 1</span><br><span class="line">                index2 +&#x3D; 1</span><br><span class="line">        </span><br><span class="line">        return intersection</span><br></pre></td></tr></table></figure><h2 id="Problem-8-加一"><a href="#Problem-8-加一" class="headerlink" title="Problem 8 加一"></a>Problem 8 加一</h2><p>给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。</p><p>最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。</p><p>你可以假设除了整数 0 之外，这个整数不会以零开头。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [1,2,3]</span><br><span class="line">输出: [1,2,4]</span><br><span class="line">解释: 输入数组表示数字 123。</span><br></pre></td></tr></table></figure><h3 id="方法一：从后往前依次判断末尾是否为9-如果是-则去除："><a href="#方法一：从后往前依次判断末尾是否为9-如果是-则去除：" class="headerlink" title="方法一：从后往前依次判断末尾是否为9 如果是 则去除："></a>方法一：从后往前依次判断末尾是否为9 如果是 则去除：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def plusOne(self, digits: List[int]) -&gt; List[int]:</span><br><span class="line">        newlst &#x3D; []</span><br><span class="line">        while digits and digits[-1] &#x3D;&#x3D; 9:</span><br><span class="line">            digits.pop()</span><br><span class="line">            newlst.append(0)</span><br><span class="line">        if not digits:</span><br><span class="line">            return [1] + newlst</span><br><span class="line">        else:</span><br><span class="line">            digits[-1] +&#x3D; 1</span><br><span class="line">            return digits + newlst</span><br></pre></td></tr></table></figure><h3 id="方法二：先将数字列表转化为数字，然后-1-再转化为数组"><a href="#方法二：先将数字列表转化为数字，然后-1-再转化为数组" class="headerlink" title="方法二：先将数字列表转化为数字，然后+1,再转化为数组"></a>方法二：先将数字列表转化为数字，然后+1,再转化为数组</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def plusOne(self, digits: List[int]) -&gt; List[int]:</span><br><span class="line">        a &#x3D; [i *10**index for index,i in enumerate(digits[::-1])]</span><br><span class="line">        num &#x3D; sum(a) + 1</span><br><span class="line">        return [int(x) for x in str(num)]</span><br></pre></td></tr></table></figure><hr><h2 id="Problem-9-移动零"><a href="#Problem-9-移动零" class="headerlink" title="Problem 9 移动零"></a>Problem 9 移动零</h2><h3 id="方法一：一次遍历"><a href="#方法一：一次遍历" class="headerlink" title="方法一：一次遍历"></a>方法一：一次遍历</h3><p>参照快速排序的思想，用0当做中间点，把不等于0的放到中间点的左边，等于零0的放到其右边</p><p>使用两个指针$i,j$，只要$nums[i]!=0$就交换$nums[i]$和$nums[j]$</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def moveZeroes(self, nums: List[int]) -&gt; None:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Do not return anything, modify nums in-place instead.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 找到第一个0</span><br><span class="line">        for i in range(0,len(nums)):</span><br><span class="line">            if nums[i] &#x3D;&#x3D; 0:</span><br><span class="line">                break</span><br><span class="line">        for j in range(i+1,len(nums)):</span><br><span class="line">            if nums[j] !&#x3D; 0:</span><br><span class="line">                temp &#x3D; nums[i]</span><br><span class="line">                nums[i] &#x3D; nums[j]</span><br><span class="line">                nums[j] &#x3D; temp</span><br><span class="line">                i+&#x3D;1</span><br><span class="line">        return nums</span><br></pre></td></tr></table></figure><h2 id="Problem-10-有效的数独"><a href="#Problem-10-有效的数独" class="headerlink" title="Problem 10 有效的数独"></a>Problem 10 有效的数独</h2><h3 id="方法一：哈希表一次迭代完成"><a href="#方法一：哈希表一次迭代完成" class="headerlink" title="方法一：哈希表一次迭代完成"></a>方法一：哈希表一次迭代完成</h3><p>通过三个哈希表映射记录 行/列/子数独出现的次数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def isValidSudoku(self, board):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type board: List[List[str]]</span><br><span class="line">        :rtype: bool</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # init data</span><br><span class="line">        rows &#x3D; [&#123;&#125; for i in range(9)]</span><br><span class="line">        columns &#x3D; [&#123;&#125; for i in range(9)]</span><br><span class="line">        boxes &#x3D; [&#123;&#125; for i in range(9)]</span><br><span class="line"></span><br><span class="line">        # validate a board</span><br><span class="line">        for i in range(9):</span><br><span class="line">            for j in range(9):</span><br><span class="line">                num &#x3D; board[i][j]</span><br><span class="line">                if num !&#x3D; &#39;.&#39;:</span><br><span class="line">                    num &#x3D; int(num)</span><br><span class="line">                    box_index &#x3D; (i &#x2F;&#x2F; 3 ) * 3 + j &#x2F;&#x2F; 3</span><br><span class="line">                    </span><br><span class="line">                    # keep the current cell value</span><br><span class="line">                    rows[i][num] &#x3D; rows[i].get(num, 0) + 1</span><br><span class="line">                    columns[j][num] &#x3D; columns[j].get(num, 0) + 1</span><br><span class="line">                    boxes[box_index][num] &#x3D; boxes[box_index].get(num, 0) + 1</span><br><span class="line">                    </span><br><span class="line">                    # check if this value has been already seen before</span><br><span class="line">                    if rows[i][num] &gt; 1 or columns[j][num] &gt; 1 or boxes[box_index][num] &gt; 1:</span><br><span class="line">                        return False         </span><br><span class="line">        return True</span><br></pre></td></tr></table></figure><h2 id="Problem-11"><a href="#Problem-11" class="headerlink" title="Problem 11"></a>Problem 11</h2><p>给定一个 n × n 的二维矩阵表示一个图像。</p><p>将图像顺时针旋转 90 度。</p><p>说明：</p><p>你必须在原地旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要使用另一个矩阵来旋转图像。</p><p>示例 1:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">给定 matrix &#x3D; </span><br><span class="line">[</span><br><span class="line">  [1,2,3],</span><br><span class="line">  [4,5,6],</span><br><span class="line">  [7,8,9]</span><br><span class="line">],</span><br><span class="line"></span><br><span class="line">原地旋转输入矩阵，使其变为:</span><br><span class="line">[</span><br><span class="line">  [7,4,1],</span><br><span class="line">  [8,5,2],</span><br><span class="line">  [9,6,3]</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h3 id="方法一：-转置加翻转"><a href="#方法一：-转置加翻转" class="headerlink" title="方法一： 转置加翻转"></a>方法一： 转置加翻转</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def rotate(self, matrix):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type matrix: List[List[int]]</span><br><span class="line">        :rtype: void Do not return anything, modify matrix in-place instead.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        n &#x3D; len(matrix[0])        </span><br><span class="line">        # transpose matrix</span><br><span class="line">        for i in range(n):</span><br><span class="line">            for j in range(i, n):</span><br><span class="line">                matrix[j][i], matrix[i][j] &#x3D; matrix[i][j], matrix[j][i] </span><br><span class="line">        </span><br><span class="line">        # reverse each row</span><br><span class="line">        for i in range(n):</span><br><span class="line">            matrix[i].reverse()</span><br></pre></td></tr></table></figure><hr><h1 id="2-字符串"><a href="#2-字符串" class="headerlink" title="2 字符串"></a>2 字符串</h1><h2 id="Problem-1-字符串转换整数-atoi"><a href="#Problem-1-字符串转换整数-atoi" class="headerlink" title="Problem 1 字符串转换整数 (atoi)"></a>Problem 1 字符串转换整数 (atoi)</h2><p>请你来实现一个 atoi 函数，使其能将字符串转换成整数。</p><p>首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。接下来的转化规则如下：</p><ul><li>如果第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字字符组合起来，形成一个有符号整数。</li><li>假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成一个整数。</li><li>该字符串在有效的整数部分之后也可能会存在多余的字符，那么这些字符可以被忽略，它们对函数不应该造成影响。<br>注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换，即无法进行有效转换。</li></ul><p>在任何情况下，若函数不能进行有效的转换时，请返回 0 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: &quot;4193 with words&quot;</span><br><span class="line">输出: 4193</span><br><span class="line">解释: 转换截止于数字 &#39;3&#39; ，因为它的下一个字符不为数字。</span><br></pre></td></tr></table></figure><h3 id="方法一：普通使用字符串转换写法"><a href="#方法一：普通使用字符串转换写法" class="headerlink" title="方法一：普通使用字符串转换写法"></a>方法一：普通使用字符串转换写法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def myAtoi(self, s: str) -&gt; int:</span><br><span class="line">        s &#x3D; s.strip(&#39; &#39;)</span><br><span class="line">        string &#x3D; &#39;0&#39;</span><br><span class="line">        if len(s) &gt; 0:</span><br><span class="line">            if s[0] &#x3D;&#x3D; &#39;-&#39; or s[0].isdigit() or s[0] &#x3D;&#x3D; &#39;+&#39;:</span><br><span class="line">                string &#x3D; s[0]</span><br><span class="line">                if s[0] &#x3D;&#x3D; &#39;+&#39; or s[0] &#x3D;&#x3D; &#39;-&#39;:</span><br><span class="line">                    string +&#x3D; &#39;0&#39;</span><br><span class="line">                for c in range(1,len(s)):</span><br><span class="line">                    if s[c].isdigit():</span><br><span class="line">                        string +&#x3D; s[c]</span><br><span class="line">                    else:</span><br><span class="line">                        break</span><br><span class="line">        num &#x3D; int(string)</span><br><span class="line">        if num &lt; -2**31:</span><br><span class="line">            return -2**31</span><br><span class="line">        elif num &gt; 2**31-1:</span><br><span class="line">            return 2**31-1</span><br><span class="line">        return num</span><br></pre></td></tr></table></figure><h3 id="方法二：利用Python正则化"><a href="#方法二：利用Python正则化" class="headerlink" title="方法二：利用Python正则化"></a>方法二：利用Python正则化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def myAtoi(self, s: str) -&gt; int:</span><br><span class="line">        return max(min(int(*re.findall(&#39;^[\+\-]?\d+&#39;, s.lstrip())), 2**31 - 1), -2**31)</span><br></pre></td></tr></table></figure><p>^：匹配字符串开头<br>[+-]：代表一个+字符或-字符<br>?：前面一个字符可有可无<br>\d：一个数字<br>+：前面一个字符的一个或多个<br>\D：一个非数字字符<br>*：前面一个字符的0个或多个</p><hr><h1 id="3-链表"><a href="#3-链表" class="headerlink" title="3 链表"></a>3 链表</h1><h2 id="Problem-1-删除链表的倒数第N个节点"><a href="#Problem-1-删除链表的倒数第N个节点" class="headerlink" title="Problem  1 删除链表的倒数第N个节点"></a>Problem  1 删除链表的倒数第N个节点</h2><p>给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n &#x3D; 2.</span><br><span class="line"></span><br><span class="line">当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.</span><br></pre></td></tr></table></figure><p>对于链表类题目，对某一个特定索引的元素进行操作往往会成为增加运算时间的瓶颈，因此如何通过尽可能少的遍历次数寻找到所要操作的元素就成为关键。</p><h3 id="方法一：-双指针"><a href="#方法一：-双指针" class="headerlink" title="方法一： 双指针"></a>方法一： 双指针</h3><p>为了方便，我们在原有链表前面设置一个哑结点，哑结点的好处在于，因为这里我们是要删除一个结点，所以我们可以定位到被删除结点的前置结点，然后将前置结点的后续指针指向被删除结点的后续结点，则可完成删除。</p><p>我们设置两个指针，两个指针初始状态都指向哑结点，指针fast 先走n步，然后指针fast和指针slow同步往前继续遍历链表，直至fast的后续结点为空，此时指针slow到达被删除结点的前置结点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Definition for singly-linked list.</span><br><span class="line">class ListNode:</span><br><span class="line">def __init__(self, x):</span><br><span class="line">self.val &#x3D; x</span><br><span class="line">self.next &#x3D; None</span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">def removeNthFromEnd(self, head: ListNode, n: int) -&gt; ListNode:</span><br><span class="line">if not head:</span><br><span class="line">return head</span><br><span class="line">slownode &#x3D; ListNode(None)</span><br><span class="line">slownode.next &#x3D; head</span><br><span class="line">fastnode &#x3D; slownode</span><br><span class="line">for i in range(n):</span><br><span class="line">fastnode &#x3D; fastnode.next</span><br><span class="line">while(fastnode.next!&#x3D;None):</span><br><span class="line">slownode &#x3D; slownode.next</span><br><span class="line">fastnode &#x3D; fastnode.next</span><br><span class="line">if slownode.next &#x3D;&#x3D; head:</span><br><span class="line">head &#x3D; head.next</span><br><span class="line">else:</span><br><span class="line">slownode.next &#x3D; slownode.next.next</span><br><span class="line">return head</span><br></pre></td></tr></table></figure><h3 id="方法二：递归"><a href="#方法二：递归" class="headerlink" title="方法二：递归"></a>方法二：递归</h3><p>先通过head.next = self.removeNthFromEnd(head.next,n)，找到base case也就是if head is None时，设i=0.<br>然后通过递归慢慢向前并每次加一，找到倒数第n个节点，并且返回这个要删除节点的next。<br>如果i!=n，也就是这个节点要保留，返回这个节点（通过.next也包括了他后面的那些节点）。<br>返回节点时会通过head.next = self.removeNthFromEnd(head.next,n)把每次返回的节点接到head.next上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def removeNthFromEnd(self, head, n):</span><br><span class="line">        global i </span><br><span class="line">        if head is None:</span><br><span class="line">            i&#x3D;0</span><br><span class="line">            return None</span><br><span class="line">        head.next &#x3D; self.removeNthFromEnd(head.next,n)</span><br><span class="line">        i+&#x3D;1</span><br><span class="line">        return head.next if i&#x3D;&#x3D;n else head</span><br></pre></td></tr></table></figure><h2 id="Problem-2-翻转链表"><a href="#Problem-2-翻转链表" class="headerlink" title="Problem 2  翻转链表"></a>Problem 2  翻转链表</h2><p>输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL<br>输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL</p><h3 id="方法一：双指针法"><a href="#方法一：双指针法" class="headerlink" title="方法一：双指针法"></a>方法一：双指针法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def reverseList(self, head: ListNode) -&gt; ListNode:</span><br><span class="line">        pre &#x3D; None</span><br><span class="line">        cur &#x3D; head</span><br><span class="line">        while cur:</span><br><span class="line">            temp &#x3D; cur.next   # 先把原来cur.next位置存起来</span><br><span class="line">            cur.next &#x3D; pre</span><br><span class="line">            pre &#x3D; cur</span><br><span class="line">            cur &#x3D; temp</span><br><span class="line">        return pre</span><br></pre></td></tr></table></figure><h3 id="方法二：递归-1"><a href="#方法二：递归-1" class="headerlink" title="方法二：递归"></a>方法二：递归</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Definition for singly-linked list.</span><br><span class="line"># class ListNode:</span><br><span class="line">#     def __init__(self, x):</span><br><span class="line">#         self.val &#x3D; x</span><br><span class="line">#         self.next &#x3D; None</span><br><span class="line">class Solution:</span><br><span class="line">    def reverseList(self, head: ListNode) -&gt; ListNode:</span><br><span class="line">        ## 递归</span><br><span class="line">        if not (head and head.next):</span><br><span class="line">            return head</span><br><span class="line">        </span><br><span class="line">        newHead &#x3D; self.reverseList(head.next)</span><br><span class="line">        </span><br><span class="line">        head.next.next &#x3D; head</span><br><span class="line">        head.next &#x3D; None</span><br><span class="line">        return newHead</span><br></pre></td></tr></table></figure><h2 id="Problem-3-合并两个有序链表"><a href="#Problem-3-合并两个有序链表" class="headerlink" title="Problem 3 合并两个有序链表"></a>Problem 3 合并两个有序链表</h2><p>将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4</span><br><span class="line">输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4</span><br></pre></td></tr></table></figure><h3 id="方法一：-递归"><a href="#方法一：-递归" class="headerlink" title="方法一： 递归"></a>方法一： 递归</h3><p>当我们使用递归方法解题时，主要思考两个关键</p><ul><li>递归的中值条件</li><li>递归不断调用自身，直到遇到终止条件后进行回溯，最终返回答案</li></ul><p>所以根据以上考虑本题</p><ul><li>终止条件： 当两个链表都为空时，表示我们对链表已合并完成</li><li>如何递归： 判断l1,l2头结点哪个更小，然后较小结点next指针指向其余结点的合并结果（调用递归）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def mergeTwoLists(self, l1: ListNode, l2: ListNode) -&gt; ListNode:</span><br><span class="line">        if not l1: return l2  # 终止条件，直到两个链表都空</span><br><span class="line">        if not l2: return l1</span><br><span class="line">        if l1.val &lt;&#x3D; l2.val:  # 递归调用</span><br><span class="line">            l1.next &#x3D; self.mergeTwoLists(l1.next,l2)</span><br><span class="line">            return l1</span><br><span class="line">        else:</span><br><span class="line">            l2.next &#x3D; self.mergeTwoLists(l1,l2.next)</span><br><span class="line">            return l2</span><br></pre></td></tr></table></figure><h3 id="方法二：-双指针"><a href="#方法二：-双指针" class="headerlink" title="方法二： 双指针"></a>方法二： 双指针</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def mergeTwoLists(self, l1: ListNode, l2: ListNode) -&gt; ListNode:</span><br><span class="line">        phead &#x3D; ListNode(0)</span><br><span class="line">        dummy &#x3D; phead</span><br><span class="line">        while l1 and l2:</span><br><span class="line">            if l1.val &lt;&#x3D; l2.val:</span><br><span class="line">                dummy.next &#x3D; l1</span><br><span class="line">                dummy &#x3D; dummy.next</span><br><span class="line">                l1 &#x3D; l1.next</span><br><span class="line">            else:</span><br><span class="line">                dummy.next &#x3D; l2</span><br><span class="line">                dummy &#x3D; dummy.next</span><br><span class="line">                l2 &#x3D; l2.next</span><br><span class="line">        if l1:</span><br><span class="line">            dummy.next &#x3D; l1</span><br><span class="line">        if l2:</span><br><span class="line">            dummy.next &#x3D; l2</span><br><span class="line">        return phead.next</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-数组与矩阵&quot;&gt;&lt;a href=&quot;#1-数组与矩阵&quot; class=&quot;headerlink&quot; title=&quot;1 数组与矩阵&quot;&gt;&lt;/a&gt;1 数组与矩阵&lt;/h1&gt;&lt;h2 id=&quot;Problem-1-数组中重复的数字&quot;&gt;&lt;a href=&quot;#Problem-1-数组中重复的数字&quot; class=&quot;headerlink&quot; title=&quot;Problem 1 数组中重复的数字&quot;&gt;&lt;/a&gt;Problem 1 数组中重复的数字&lt;/h2&gt;&lt;p&gt;找出数组中重复的数字。&lt;/p&gt;
&lt;p&gt;在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;示例 1：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;输入：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[2, 3, 1, 0, 2, 5, 3]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;输出：2 或 3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="编程" scheme="https://liangggggg.github.io/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="编程" scheme="https://liangggggg.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>数据结构总结（一）：线性表</title>
    <link href="https://liangggggg.github.io/2020/08/11/Data/"/>
    <id>https://liangggggg.github.io/2020/08/11/Data/</id>
    <published>2020-08-11T01:47:42.000Z</published>
    <updated>2020-08-20T08:26:22.640Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-线性表"><a href="#1-线性表" class="headerlink" title="1 线性表"></a>1 线性表</h1><h2 id="1-1-线性表的定义和基本操作"><a href="#1-1-线性表的定义和基本操作" class="headerlink" title="1.1 线性表的定义和基本操作"></a>1.1 线性表的定义和基本操作</h2><p>1.线性结构的特点是：在数据元素的非空有限集中</p><ul><li>存在唯一的一个被称作“第一个”的数据元素</li><li>存在唯一一个被称作“最后一个”的数据元素</li><li>除第一个之外，集合中的每个元素均只有一个前驱</li><li>除最后一个之外，集合中每个元素均只有一个后继</li></ul><p>2.线性表示一种线性结构，在一个线性表中数据元素的类型是相同的，长度可以根据需要增长或缩短</p><a id="more"></a><h2 id="1-2-线性表的实现"><a href="#1-2-线性表的实现" class="headerlink" title="1.2 线性表的实现"></a>1.2 线性表的实现</h2><h3 id="1-2-1-顺序存储"><a href="#1-2-1-顺序存储" class="headerlink" title="1.2.1 顺序存储"></a>1.2.1 顺序存储</h3><p>1.顺序表的定义<br>线性表的顺序存储是指在内存中用地址连续的一块存储空间顺序存放线性表的各元素</p><p><img src="https://note.youdao.com/yws/api/personal/file/96E6535559A647A3B6F63C3AE1535948?method=download&shareKey=7b053e18c9fb7504affa8b8851745fd7" alt></p><p>2.顺序表上基本运算的实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; - -一一一线性表的动态分配顺序存储结构一一</span><br><span class="line">define LIST_INIT_SIZE 100 &#x2F;&#x2F;线性表存储空间的初始分量</span><br><span class="line"></span><br><span class="line">define LISTINCREMNT 10 &#x2F;&#x2F;线性表存储空间的分配增量</span><br><span class="line"></span><br><span class="line">1）静态结构：表一旦装满，不能扩充</span><br><span class="line">define MAX_SIZE 100</span><br><span class="line">typdef int Status;</span><br><span class="line">typdef int ElemType;</span><br><span class="line">typdef struct sqlist</span><br><span class="line">&#123;</span><br><span class="line">ElemType Elem_array[Max_SIZE];</span><br><span class="line">int length;</span><br><span class="line">&#125;SqList;</span><br><span class="line"></span><br><span class="line">2) 动态结构，可以扩充，新的大小计入数据成员maxSize中</span><br><span class="line">typedef struct sqlist&#123;</span><br><span class="line">ElempType *elem; &#x2F;&#x2F;存储数组int length</span><br><span class="line">int length &#x2F;&#x2F;当前表元素个数</span><br><span class="line">int maxSize; &#x2F;&#x2F;表的最大长度</span><br><span class="line">&#125;SqList;</span><br></pre></td></tr></table></figure><p>(1)顺序表的初始化</p><p>将L设为引用参数，首先动态分配存储空间，然后将length置为0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status Init_SqList(SqList *L)</span><br><span class="line">&#123;</span><br><span class="line">L-&gt;elem &#x3D; (ElemType *)malloc(MAX_SIZE*sizeof(ElemType));</span><br><span class="line">if (!L-&gt;elem)</span><br><span class="line">return ERROR;</span><br><span class="line">else&#123;</span><br><span class="line">L-&gt;length &#x3D; 0;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>(2)插入运算</p><p>在第i个位置上插入x，从$a_i-a_n$都要向下移动一个位置，共需要移动$n-i+1$个元素</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Status Insert_SqList(Sqlist *L, int i, ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">int j;</span><br><span class="line">if (i&lt;0 || i-&gt;L-&gt;length+1) return ERROR;</span><br><span class="line">if (L-&gt;length&gt;&#x3D;MAX_SIZE)</span><br><span class="line">&#123;</span><br><span class="line">printf(“溢出！\n”);</span><br><span class="line">return ERROR;</span><br><span class="line">&#125;</span><br><span class="line">for (j&#x3D;L-&gt;length-1; j&gt;&#x3D;i-1; --j)</span><br><span class="line">&#123;</span><br><span class="line">&#x2F;* i-1位置以后的所有结点往后移 *&#x2F;</span><br><span class="line">L-&gt;Elem_array[j+1]&#x3D;L-&gt;Elem_array[j];&#125;</span><br><span class="line">L-&gt;Elem_array[i-1] &#x3D; e;</span><br><span class="line">&#x2F;* 在i-1个位置插入*&#x2F;</span><br><span class="line">L-&gt;length++;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>(3)删除运算</p><p>删除第i个元素，其后面的元素$a_{i+1}-a_n$都要向上移动，共移动了$n-i$个元素</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">ElemType Delete_SqList(Sqlist *L, int i)</span><br><span class="line">&#123;</span><br><span class="line">int k;</span><br><span class="line">ElemTpye x;</span><br><span class="line">if (L-&gt;length&#x3D;&#x3D;0)</span><br><span class="line">&#123;</span><br><span class="line">printf(“要删除的数据元素不存在!\n”);</span><br><span class="line">return ERROR;</span><br><span class="line">&#125;</span><br><span class="line">else&#123;</span><br><span class="line">x&#x3D;L-&gt;Elem_array[i-1]; # 保存结点的值</span><br><span class="line">for(k&#x3D;i; k &lt; L-&gt;length; k++)</span><br><span class="line">&#123;</span><br><span class="line">L-&gt;Elem_array[k-1]&#x3D;L-&gt;Elem_array[k]; # i位置以后的所有结点前移</span><br><span class="line">&#125;</span><br><span class="line">L-&gt;length--;</span><br><span class="line">reutrn x;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/A5E9B6356BA5483D8C339A5E599C9D35?method=download&shareKey=ffe88d5b4391046d95eebfc796a71a70" alt></p><p>3.顺序线性表的查找定位删除</p><p>在线性表$L=(a_1,a_2,\dots,a_n)$删除值为$x$的第一个节点</p><p>(1)在线性表L查找值为x的第一个数据元素</p><p>(2)将从找到的位置至最后一个结点依次向前移动一个位置</p><p>(3)线性表长度减1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Status Locate_Delete_SqList(Sqlist *L, ElemType x)</span><br><span class="line">&#123;</span><br><span class="line">int i&#x3D;0,k;</span><br><span class="line">while(i&lt; L-&gt;length) # 查找值为x的第一个结点</span><br><span class="line">&#123;</span><br><span class="line">if(L-&gt;Elem_array[i]!&#x3D;x) i++;&#125;</span><br><span class="line">else&#123;</span><br><span class="line">for(k &#x3D; i+1; k&lt; L-&gt;length; k++) </span><br><span class="line">L-&gt;Elem_array[k-1]&#x3D;L-&gt;Elem_array[k];</span><br><span class="line">L-&gt;length--;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">if (i&gt;L-&gt;length)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;要删除的数据元素不存在！\n&quot;);</span><br><span class="line">return ERROR;</span><br><span class="line">&#125;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4.顺序表的合并问题</p><p>对于有序顺序表$L_a,L_b$</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int MergeList(SqList La, SqList Lb, SqList *Lc)</span><br><span class="line">&#123;</span><br><span class="line">Lc-&gt;listsize &#x3D; Lc.length &#x3D; La.lenth + Lb.length;</span><br><span class="line">Pc &#x3D; Lc-&gt;elem &#x3D; (ElemType *)malloc(Lc.listsize * sizeof(ElemType));</span><br><span class="line">if(!Lc.elem) exit(overflow);</span><br><span class="line">pa_last &#x3D; La.elem + La.length-1;</span><br><span class="line">pb_last &#x3D; Lb.elem + Lb.length-1;</span><br><span class="line">while(pa&lt;&#x3D;pa_last &amp;&amp; pb &lt;&#x3D; pb_last)&#123;</span><br><span class="line">if(*pa&lt;&#x3D;*pb)</span><br><span class="line">*pc++&#x3D;*pa++;</span><br><span class="line">else</span><br><span class="line">*pc++&#x3D;*pb++;</span><br><span class="line">&#125;</span><br><span class="line">while(pa&lt;pa_last) *pc++&#x3D;*pa++;</span><br><span class="line">while(pb&lt;&#x3D;pb_last) *pc++&#x3D;*pb++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-2-2-链式存储"><a href="#1-2-2-链式存储" class="headerlink" title="1.2.2 链式存储"></a>1.2.2 链式存储</h3><p>1.单链表</p><p>线性表的链式存储结构特点是用一组任意的存储单元存储线性表的数据元素（存储单元可以是连续的，也可以使不连续的）</p><p>定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct LNode&#123;</span><br><span class="line">ElemType data;</span><br><span class="line">struct LNode* next;</span><br><span class="line">&#125;LNode, *LinkList;</span><br></pre></td></tr></table></figure><p>2.单链表基本运算实现</p><p>（1）建立单链表</p><ul><li>头插法————在链表的头部插入节点建立单链表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">LNode *create_LinkList(void) # 头插法创建单链表，头结点head作为返回值</span><br><span class="line">&#123;</span><br><span class="line">int data;</span><br><span class="line">LNode *head, *p;</span><br><span class="line">head &#x3D; (LNode *)malloc(sizeof(LNode));</span><br><span class="line">head-&gt;next &#x3D; NULL # 创建链表的头结点head</span><br><span class="line">while(1)</span><br><span class="line">&#123;</span><br><span class="line">scanf(&quot;%d&quot;, &amp;data);</span><br><span class="line">if(data&#x3D;&#x3D;327667) break;</span><br><span class="line">p&#x3D;(LNode *)malloc(sizeof(LNode));</span><br><span class="line">p-&gt;data &#x3D; data; # 数据域赋值</span><br><span class="line">p-&gt;next &#x3D; head-&gt;next;</span><br><span class="line">head-&gt;next &#x3D; p; # 钩链，新创建的结点总是作为第一个结点</span><br><span class="line">&#125;</span><br><span class="line">return head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/8849B8BB9FE946FC8CC970D8022939A1?method=download&shareKey=e854f232f11469e6c244f77d5f73ab42" alt></p><ul><li>尾插法————头插法虽然简单但是读入的数据元素顺序与生成的链表中元素是相反的，为了次序一致，可以使用尾插法</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">LNode *create_LinkList(void) # 尾插法创建单链表，头结点head作为返回值</span><br><span class="line">&#123;</span><br><span class="line">int data;</span><br><span class="line">LNode *head, *last, *q;</span><br><span class="line">head &#x3D; p &#x3D; (LNode *)malloc(sizeof(LNode))</span><br><span class="line">p-&gt;next&#x3D;NULL # 创建单链表的头结点head</span><br><span class="line">while(1)</span><br><span class="line">&#123;</span><br><span class="line">scanf(&quot;%d&quot;, &amp;data);</span><br><span class="line">if(data&#x3D;&#x3D;32767) break;</span><br><span class="line">q &#x3D; (LNode *)malloc(sizeof(LNode));</span><br><span class="line">q-&gt;data&#x3D;data # 数据域赋值</span><br><span class="line">q-&gt;next &#x3D; last-&gt;next;</span><br><span class="line">last-&gt;next&#x3D;q;</span><br><span class="line">last&#x3D;q; # 钩链，新创建的结点总是作为最后一个结点</span><br><span class="line">&#125;</span><br><span class="line">return head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://note.youdao.com/yws/api/personal/file/A17A2DAD6A0B44F8B383E21B37DFBC81?method=download&shareKey=6b0d21c3a6ea6e2ed2387497e28ee6a0" alt></p><p>(2)查找操作</p><ul><li>按序号查找</li></ul><p>子单链表中，取得第1个数据元素必须从头指针出发寻找，因此单链表是非随机存取的存储结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ElemType Get_Elem(LNode *L, int i)</span><br><span class="line">&#123;</span><br><span class="line">int j;</span><br><span class="line">LNode *p;</span><br><span class="line">if(i&lt;1)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;i太小\n&quot;);</span><br><span class="line">return;&#125;</span><br><span class="line">P&#x3D;L-&gt;next; j&#x3D;1 # 使P指向第一个结点</span><br><span class="line">while(P!&#x3D;NULL &amp;&amp; j&lt;i)</span><br><span class="line">&#123;</span><br><span class="line">p&#x3D;p-&gt;next;</span><br><span class="line">j++;&#125; # 移动指针p，j计数</span><br><span class="line">if(p&#x3D;&#x3D;NULL)</span><br><span class="line">return -32768</span><br><span class="line">else</span><br><span class="line">return p-&gt;data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>按值查找</li></ul><p>查找时从开始节点出发，沿链表逐个将节点的值和给定值key作比较</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">LNode *Locate_Note(LNode *L, int key)</span><br><span class="line">&#123;</span><br><span class="line">LNode *p&#x3D;L-&gt;next;</span><br><span class="line">while(P!&#x3D;NULL &amp;&amp; p-&gt;data!&#x3D;key) p&#x3D;p-&gt;next;</span><br><span class="line">if(p-&gt;data&#x3D;&#x3D;key) return p;</span><br><span class="line">else&#123;</span><br><span class="line">printf(&quot;所要查找的结点不存在！\n&quot;);</span><br><span class="line">return NULL;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）插入运算（后插法）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">void Insert_LNode(LNode *L, int i, ElemType e)</span><br><span class="line">&#x2F;*在以 L 为头结点的单链表的第 i 个位置插入值为 e 的结点 *&#x2F;</span><br><span class="line">&#123;</span><br><span class="line">int j&#x3D;0; LNode *p, *q;</span><br><span class="line">if(i&lt;1)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;i太小\n&quot;);</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">p&#x3D;L;</span><br><span class="line">while(P!&#x3D;NULL &amp;&amp; j&lt;i-1)</span><br><span class="line">&#123;</span><br><span class="line">p&#x3D;p-&gt;next;</span><br><span class="line">j++;</span><br><span class="line">if(P&#x3D;&#x3D;NULL) printf(&quot;i太大!\n&quot;);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">q&#x3D;(LNode *)malloc(sizeof(LNode));</span><br><span class="line">q-&gt;data&#x3D;e;</span><br><span class="line">q-&gt;next&#x3D;p-&gt;next;</span><br><span class="line">p-&gt;next&#x3D;q;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（4）删除运算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">void Delete_LinkList(LNode *L, int i)</span><br><span class="line">&#x2F;*删除以 L 为头结点的单链表中的第 i 个结点*&#x2F;</span><br><span class="line">&#123;</span><br><span class="line">int j&#x3D;1; LNode *p,*q;</span><br><span class="line">if(i&lt;1)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;i太小\n&quot;);</span><br><span class="line">return;&#125;</span><br><span class="line">p&#x3D;L; q&#x3D;L-&gt;next;</span><br><span class="line">while(q!&#x3D;NULL &amp;&amp; j&lt;i)</span><br><span class="line">&#123;</span><br><span class="line">p&#x3D;q;</span><br><span class="line">q&#x3D;q-&gt;next;</span><br><span class="line">j++;&#125;</span><br><span class="line">if(p&#x3D;&#x3D;NULL) printf(&quot;i太大!\n&quot;);</span><br><span class="line">else&#123;</span><br><span class="line">p-&gt;next&#x3D;q-&gt;next;</span><br><span class="line">free(q);&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3.单链表的合并</p><p>若La,Lb两个链表的长度分别是m,n，则链表合并的时间复杂度为O(m+n)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">LNode *Merge_LinkList(LNode *La, LNode *Lb)</span><br><span class="line">&#x2F;*合并以 La，Lb 为头结点的两个有序单链表*&#x2F;</span><br><span class="line">&#123;</span><br><span class="line">LNode *Lc, *pa, *pb, *pc, *ptr;</span><br><span class="line">Lc &#x3D; La; pc &#x3D; La;</span><br><span class="line">pa&#x3D;La-&gt;next; pb&#x3D;Lb-&gt;next;</span><br><span class="line">while(pa!&#x3D;NULL &amp;&amp; pb!&#x3D;NULL)</span><br><span class="line">&#123;</span><br><span class="line">if(pa-&gt;data &lt; pb-&gt;data)</span><br><span class="line">&#123;</span><br><span class="line">pc-&gt;next&#x3D;pa;</span><br><span class="line">pc&#x3D;pa;</span><br><span class="line">pa&#x3D;pa-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">if(pa-&gt;data &gt; pb-&gt;data)</span><br><span class="line">&#123;</span><br><span class="line">pc-&gt;next&#x3D;pb;</span><br><span class="line">pc&#x3D;pb;</span><br><span class="line">pb&#x3D;pb-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;* 如果两个值相等，将pa所指结点合并，pb所指结点删除*&#x2F;</span><br><span class="line">if(pa-&gt;data&#x3D;&#x3D;pb-&gt;data)</span><br><span class="line">&#123;</span><br><span class="line">pc-&gt;next&#x3D;pa;</span><br><span class="line">pc&#x3D;pa;</span><br><span class="line">pa&#x3D;pa-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">if(pa!&#x3D;NULL) pc-&gt;next&#x3D;pa;</span><br><span class="line">else pc-&gt;next&#x3D;pb;</span><br><span class="line">free(Lb);</span><br><span class="line">return Lc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4.循环链表</p><p>对于单链表，最后一个节点的指针域是空指针，如果将该链表投指针置入该指针域，则使得链表头尾节点相连，构成了单循环链表</p><p>对于单链表只能从头结点开始遍历整个链表，而对于单循环链表则可以从表中任意结点   开始遍历整个链表，不仅如此，有时对链表常做的操作是在表尾、表头进行，此时可以改变   一下链表的标识方法，不用头指针而用一个指向尾结点的指针 R 来标识，可以使得操作效率得以提高。</p><ol start="5"><li>双向链表</li></ol><table><thead><tr><th align="center">前驱指针域</th><th align="center">数据域</th><th align="center">后继指针域</th></tr></thead></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct Dulnode</span><br><span class="line">&#123;ElemType data;</span><br><span class="line">struct Dulnode*prior, *next;</span><br><span class="line">&#125;DulNode;</span><br></pre></td></tr></table></figure><p>(1)双向链表的插入</p><ol><li>插入时仅仅指出直接前驱节点，钩链时必须注意先后次序是：“先右后左”</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">S&#x3D;(DulNode *)malloc(sizeof(DulNode));</span><br><span class="line">S-&gt;data&#x3D;e;</span><br><span class="line">S-&gt;next&#x3D;p-&gt;next;</span><br><span class="line">p-&gt;next-&gt;prior&#x3D;S;</span><br><span class="line">p-&gt;next&#x3D;S;</span><br><span class="line">S-&gt;prior&#x3D;p; # 操作次序非常需要</span><br></pre></td></tr></table></figure><ol start="2"><li>插入时同时指出直接前驱节点p和直接后继节点q，钩链时无需注意先后次序</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">S&#x3D;(DulNode *)malloc(sizeof(DulNode));</span><br><span class="line">S-&gt;data&#x3D;e;</span><br><span class="line">p-&gt;next&#x3D;S;</span><br><span class="line">S-&gt;next&#x3D;q;</span><br><span class="line">S-&gt;prior&#x3D;p;</span><br><span class="line">q-&gt;prior&#x3D;S;</span><br></pre></td></tr></table></figure><p>(2)双向链表中节点的删除</p><p><img src="https://note.youdao.com/yws/api/personal/file/9E3F091C1048407BA19F473010DBB842?method=download&shareKey=71f41f90b3a0d26a4b185941b04bd5d9" alt></p><p>删除时可以不引入新的辅助指针变量，可以直接先断链，再释放结点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">p-&gt;prior-&gt;next&#x3D;p-&gt;next;</span><br><span class="line">p-&gt;next-&gt;prior&#x3D;p-&gt;prior; </span><br><span class="line">free(p);</span><br></pre></td></tr></table></figure><p>注意：与单链表的插入和删除操作不同的是，在双向链表中插入和删除必须同时修改两个方向上的指针域的指向。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-线性表&quot;&gt;&lt;a href=&quot;#1-线性表&quot; class=&quot;headerlink&quot; title=&quot;1 线性表&quot;&gt;&lt;/a&gt;1 线性表&lt;/h1&gt;&lt;h2 id=&quot;1-1-线性表的定义和基本操作&quot;&gt;&lt;a href=&quot;#1-1-线性表的定义和基本操作&quot; class=&quot;headerlink&quot; title=&quot;1.1 线性表的定义和基本操作&quot;&gt;&lt;/a&gt;1.1 线性表的定义和基本操作&lt;/h2&gt;&lt;p&gt;1.线性结构的特点是：在数据元素的非空有限集中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存在唯一的一个被称作“第一个”的数据元素&lt;/li&gt;
&lt;li&gt;存在唯一一个被称作“最后一个”的数据元素&lt;/li&gt;
&lt;li&gt;除第一个之外，集合中的每个元素均只有一个前驱&lt;/li&gt;
&lt;li&gt;除最后一个之外，集合中每个元素均只有一个后继&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.线性表示一种线性结构，在一个线性表中数据元素的类型是相同的，长度可以根据需要增长或缩短&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络总结</title>
    <link href="https://liangggggg.github.io/2020/08/11/network/"/>
    <id>https://liangggggg.github.io/2020/08/11/network/</id>
    <published>2020-08-11T01:47:42.000Z</published>
    <updated>2020-08-20T01:38:05.502Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-计算机网络体系结构"><a href="#1-计算机网络体系结构" class="headerlink" title="1 计算机网络体系结构"></a>1 计算机网络体系结构</h1><h2 id="1-1-计算机网络的概念、组成与功能"><a href="#1-1-计算机网络的概念、组成与功能" class="headerlink" title="1.1 计算机网络的概念、组成与功能"></a>1.1 计算机网络的概念、组成与功能</h2><p>互联网的拓扑结构虽然非常复杂，并且在地理上覆盖了全球，但从其工作方式上看，可以划分为以下两大块：<br>（1）边缘部分    由所有连接在互联网上的主机组成。这部分是用户直接使用的，用来进行通信（传送数据、音频或视频）和资源共享。<br>（2）核心部分    由大量网络和连接这些网络的路由器组成。这部分是为边缘部分提供服务的（提供连通性和交换）</p><a id="more"></a><h2 id="1-2-计算机网络的分类"><a href="#1-2-计算机网络的分类" class="headerlink" title="1.2 计算机网络的分类"></a>1.2 计算机网络的分类</h2><p>计算机网络有多种类别，下面进行简单的介绍。<br>1.按照网络的作用范围进行分类<br>（1）广域网 WAN（Wide Area Network）<br>广域网的作用范围通常为几十到几千公里。广域网是互联网的核心部分，其任务是通过长距离（例如，跨越不同的国家）运送主机所发送的数据。连接广域网各结点交换机的链路一般都是高速链路，具有较大的通信容量。<br>（2）城域网 MAN（Metropolitan Area Network）<br>城域网的作用范围一般是一个城市，可跨越几个街区甚至整个城市。城域网可以为一个或几个单位所拥有，但也可以是一种公用设施，用来将多个局域网进行互连。目前很多城域网采用的是以太网技术，因此有时也常并入局域网的范围进行讨论。<br>（3）局域网 LAN（Local Area Network）<br>局域网一般用微型计算机或工作站通过高速通信线路相连（速率通常在 10 Mbit/s 以上），但地理上则局限在较小的范围（如 1 km 左右）。<br>（4）个人区域网 PAN（Personal Area Network）<br>个人区域网就是在个人工作的地方把属于个人使用的电子设备（如便携式电脑等）用无线技术连接起来的网络，因此也常称为无线个人区域网 WPAN（WirelessPAN），其范围很小，大约在 10 m 左右。<br>2.按照网络的使用者进行分类<br>（5）公用网（publiCnetwork）这是指电信公司（国有或私有）出资建造的大型网络。”公用”的意思就是所有愿意按电信公司的规定交纳费用的人都可以使用这种网络。因此公用网也可称为公众网。<br>（6）专用网（private network）这是某个部门为满足本单位的特殊业务工作的需要而建造的网络。这种网络不向本单位以外的人提供服务。例如，军队、铁路、银行、电力等系统均有本系统的专用网。</p><p>公用网和专用网都可以提供多种服务。如传送的是计算机数据，则分别是公用计算机网络和专用计算机网络。</p><h2 id="1-3-计算机网络协议、接口、服务等概念"><a href="#1-3-计算机网络协议、接口、服务等概念" class="headerlink" title="1.3 计算机网络协议、接口、服务等概念"></a>1.3 计算机网络协议、接口、服务等概念</h2><p>1.协议<br>主要由以下三要素组成</p><ul><li>语法，即数据与控制信息的结构或格式：</li><li>语义，即需要发出何种控制信息，完成何种动作以及做出何种响应：</li><li>同步，即事件实现顺序的详细说明。</li></ul><p>2.接口（服务访问点）<br>同一系统中相邻两层的实体进行交互的地方。</p><p>3.服务（service）<br>为保证上层对等体之间能相互通信，下层向上层提供的功能。</p><h2 id="1-4-ISO-OSI参考模型和TCP-IP模型"><a href="#1-4-ISO-OSI参考模型和TCP-IP模型" class="headerlink" title="1.4 ISO/OSI参考模型和TCP/IP模型"></a>1.4 ISO/OSI参考模型和TCP/IP模型</h2><p>1.ISO/OSI参考模型</p><p><img src="https://note.youdao.com/yws/api/personal/file/9AA9B51F88884CCE88B4E887CBD0F540?method=download&shareKey=3fad92c71278a5fdcac6d459d65c99d2" alt></p><p>(1) 物理层<br>物理层是 OSI 参考模型的最低一层，也是在同级层之间直接进行信息交换的唯一一层。物理层负责传输二进制位流，也就是透明的传输比特，它的任务就是为上层（数据链路层）提供一个物理连接，以便在相邻节点之间无差错地传送二进制位流。有一点应该注意的是，传送二进制位流的传输介质，如双绞线、同轴电缆以及光纤等并不属于物理层要考虑的问题。实际上传输介质并不在 OSI的7个层次之内。<br>(2) 数据链路层<br>数据链路层负责在两个相邻节点之间，无差错地传送以 “ 帧 ” 为单位的数据。每一帧包括一定数量的数据和若干控制信息。数据链路的任务首先要负责建立、维持和释放数据链路的连接。在传送数据时，如果接收节点发现数据有错，要通知发送方重发这一帧，直到这一帧正确无误地送到为止。这样，数据链路层就把一条可能出错的链路，转变成让网络层看起来就像是一条不出错的理想链路。<br>(3) 网络层<br>网络层的主要功能是为处在不同网络系统中的两个节点设备通信提供一条逻辑通路。其基本任务包括路由选择、拥塞控制与网络互联等功能。<br>(4) 传输层<br>传输层的主要任务是向用户提供可靠的端到端（end-to-end ）服务，透明地传送报文。它向高层屏蔽了下层数据通信的细节，因而是计算机通信体系结构中最关键的一层。该层关心的主要问题包括建立、维护和中断虚电路、传输差错校验和恢复以及信息流量控制机制等。<br>(5) 会话层<br>负责通讯的双方在正式开始传输前的沟通，目的在于建立传输时所遵循的规则，使传输更顺畅、有效率。沟通的议题包括：使用全双工模式或半双式模式？如何发起传输？如何结束传输？如何设置传输参数就像两国元首在见面会晤之前，总会先派人谈好议事规则，正式谈判时就根据这套规则进行一样。<br>(6) 表示层<br>表示层处理两个应用实体之间进行数据交换的语法问题，解决数据交换中存在的数据格式不一致以及数据表示方法不同等问题。例如，IBM 系统的用户使用 EBCD 编码，而其它用户使用 ASCII 编码。表示层必须提供这两编码的转换服务。数据加密与解密、数据压缩与恢复等也都是表示层提供的服务。<br>(7) 应用层<br>应用层是 OSI 参考模型中最靠近用户的一层，它直接提供文件传输、电子邮件、网页浏览等服务给用户。</p><p>2.TCP/IP模型</p><p><img src="https://note.youdao.com/yws/api/personal/file/612A9DB2F78D400882E6E63B5039B5D7?method=download&shareKey=34d2de9a289a9eab74e01f3de190d316" alt></p><p>TCP/IP 是一个四层的体系结构，它包含应用层、传输层、网际层和网络接口层（用网际层这个名字 是强调这一层是为了解决不同网络的互连问题）。不过从实质上讲，TCP/IP 只有最上面的三层，因为最下面的网络接口层并没有什么具体内容。<br>(1) 网络接口层（network interface layeR）</p><p>在 TCP/IP 分层体系结构中，最底层是网络接口层，它 负责通过网络发送和接收 IP 数据报 。TCP/IP 体系结构并未对网络接口层使用权的协议做出强硬的规定，它允许主机连入网络时使用多种现成的和流行的协议，例如局域网协议或其他一些协议。</p><p>(2) 网络层（internet layeR）也就是网际层</p><p>网络层是 TCP/IP 体系结构的第二层，它实现的功能相当于 OSI 参考模型网络层的无连接网络服务。互联层负责将源主机的报文分组发送到目的的主机，源主机与目的主机可以在一个网上，也可以在不同的网上。</p><ol><li>处理来自传输层的分组发送请求。在收到分组发送请求之后，将分组装入 IP 数据报，填充报头，选择发送路径，然后将数据报发送到相应的网络输出线。</li><li>处理接收的数据报。在接收到其他主机发送的数据报之后，检查目的地址，如需要转发，则选择发送路径，转发出去；如目的地址为本节点 IP 地址，则除去报头，将分组送交给传输层处理。</li><li>处理互联的路径、流控与拥塞问题。</li></ol><p>(3) 传输层（transport layeR）<br>网络层之上是传输层，它的主要功能是负责应用进程之间的 端 - 端（Host-to-host ）通信。在 TCP/IP 体系结构中，设计传输层的主要目的是在互联网中源主机与目的主机的对等实体之间建立用于会话的端- 端连接 。因此，它与 OSI 参考模型的传输层功能相似。</p><p>TCP/IP 体系结构的传输层定义了 传输控制协议（TCP，transportControlProtocol ）和 用户数据报协（UDP,useRdatagramProtocol ）两种协议。<br>TCP 协议是一种可靠的面向连接的协议，它允许将一台主机的字节流（byte stream ）无差错地传送到目的主机。<br>UDP 协议是一种不可靠的无连接协议，它主要用于不要求分组顺序到达的传输中，分组传输顺序检查与排序由应用层完成。</p><p>(4) 应用层（application layeR）<br>在 TCP/IP 体系结构中，应用层是最靠近用户的一层。它包括了所有的高层协议，并且总是不断有新的协议加入。其主要协议包括：</p><ol><li>文件传输协议（FTP ,file transfeRprotocol ），用于实现互联网中交互式文件传输功能；</li><li>简单邮件传输协议（SMTP simple mail transfeRprotocol ），用于实现互联网中邮件传送功能；</li><li>域名系统（DNS, domain name system ），用于实现互联网设备名字到 IP 地址映射的网络服务；</li><li>超文本传输协议（HTTP, bypeRtext transfeRprotocol ），用于目前广泛使用的 Web 服务；</li><li>路由信息协议（RIP,Routing informationProtocol ），用于网络设备之间交换路由信息；</li></ol><p>在学习计算机网络的原理时往往采取折中的办法，即综合 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。</p><p><img src="https://note.youdao.com/yws/api/personal/file/7AF501D78232488DA7EF5B4DAD0A6487?method=download&shareKey=29133d1298976bc40cf97fb451b81b45" alt></p><h1 id="2-通信系统"><a href="#2-通信系统" class="headerlink" title="2 通信系统"></a>2 通信系统</h1><h2 id="1-1-信道、信号、宽带、码元、波特、速率、信源与信宿等基本概念"><a href="#1-1-信道、信号、宽带、码元、波特、速率、信源与信宿等基本概念" class="headerlink" title="1.1 信道、信号、宽带、码元、波特、速率、信源与信宿等基本概念"></a>1.1 信道、信号、宽带、码元、波特、速率、信源与信宿等基本概念</h2><p>（1）    信道：向某一个方向传送信息的媒体。<br>（2）    数据：信息的承载实体。<br>（3）    信号：数据的电磁或电气表现。<br>（4）    带宽：媒介中信号可使用的最高频率和最低频率之差，或者说是频带的宽度；另一个定义是信道中数据的传送速率。<br>（5）    码元：在使用时间域（简称时域）的波形表示数字信号时，代表不同离散数值的基本波形。<br>（6）    波特：单位时间内传输的码元数。<br>（7）    比特率：单位时间内传输的比特数。<br>（8）    信息传播过程简单地描述为：信源→信道→信宿。<br>（9）    速率：连接在计算机网络上的主机在数字信道上传送数据位数的速率，也称为 dataRate 或 bitRate 。单位是 b/s, kb/s, Mb/s, Gb/s.<br>（10）    吞吐量：即在单位时间内通过某个网络的数据量。单位 b/s, Mb/s 等。<br>（11）    时延：是指数据（一个报文或者分组，甚至比特）从网络（或链路）的一端传送到另一端所需   的时间。网络中的时延是由以下几个不同的部分组成。<br>（12）    传输时延=发送时延：发送数据时，数据块从结点进入到传输媒体所需要的时间。也就是从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间。<br>（13）    传播时延： 电磁波在信道中需要传播一定的距离而花费的时间。信号传输速率（即发送速率）和信号在信道上的传播速率是完全不同的概念。<br>（14）    处理时延：交换结点为存储转发而进行一些必要的处理所花费的时间。<br>（15）    排队时延：结点缓存队列中分组排队所经历的时延, 排队时延的长短往往取决于网络中当时的通信量。</p><p><img src="https://note.youdao.com/yws/api/personal/file/368712118CEA4A3BA287476C1072735D?method=download&shareKey=e98ca92aa8ce103624487ccffbac8a94" alt></p><p>（16）    时延带宽积 把以上讨论的网络性能的两个度量一一传播时延和带宽一一相乘，就得到另一个很有用的度量：传播时延带宽积，即<br>$$时延带宽积=传播时延×带宽$$<br>（17）    往返时间 RTT 在计算机网络中，往返时间 RTT（Round-Trip Time）也是一个重要的性能指标。这是因为在许多情况下，互联网上的信息不仅仅单方向传输而是双向交互的。因此，我们有时很需要知道双向交互一次所需的时间。<br>（18）    利用率 利用率有信道利用率和网络利用率两种。信道利用率指出某信道有百分之几的时间是被利用的（有数据通过）。完全空闲的信道的利用率是零。网络利用率则是全网络的信道利用率的加权平   均值。</p><h2 id="1-2-奈奎斯特定理与香农定理"><a href="#1-2-奈奎斯特定理与香农定理" class="headerlink" title="1.2 奈奎斯特定理与香农定理"></a>1.2 奈奎斯特定理与香农定理</h2><p>（1）    信道能够通过的频率范围 具体的信道所能通过的频率范围总是有限的。信号中的许多高频分量往往不能通过信道。严重的码间串扰使得本来分得很清楚的一串码元变得模糊而无法识别。早在 1924 年， 奈奎斯特（Nyquist）就推导出了著名的奈氏准则。他给出了在假定的理想条件下，为了避免码间串扰，码<br>元的传输速率的上限值。在任何信道中，码元传输的速率是有上限的，传输速率超过此上限，就会出现严   重的码间串扰的问题，使接收端对码元的判决。如果信道的频带越宽，也就是能够通过的信号高频分量越   多，那么就可以用更高的速率传送码元而不出现码间串扰。<br>（2）    信噪比 噪声存在于所有的电子设备和通信信道中。由于噪声是随机产生的，它的瞬时值有时会很大，因此噪声会使接收端对码元的判决产生错误（1 误判为 0 或 0 误判为 1）。但噪声的影响是相对的。如果信号相对较强，那么噪声的影响就相对较小。因此，信噪比就很重要。所谓信噪比就是信号的平均功率和噪声的平均功率之比，常记为 $S/N$，并用分贝（dB）作为度 量单位。即：<br>$$信噪比（dB）=10lg（S/N）（dB）$$</p><h2 id="1-3-编码与调制"><a href="#1-3-编码与调制" class="headerlink" title="1.3 编码与调制"></a>1.3 编码与调制</h2><p>（1）    常用编码方式<br>常用编码方式如图</p><p><img src="https://note.youdao.com/yws/api/personal/file/743B08B4BF3D4A29B90B9AA13704E9FF?method=download&shareKey=b5999ffaed519febec838168afaca2a9" alt></p><p>•    不归零制正电平代表 1，负电平代表 0。<br>•    归零制正脉冲代表 1，负脉冲代表 0。<br>•    曼彻斯特编码位周期中心的向上跳变代表 0，位周期中心的向下跳变代表 1。但也可反过来定义。<br>•    差分曼彻斯特编码在每一位的中心处始终都有跳变。位开始边界有跳变代表 0，而位开始边界没有跳变代表 1。<br>从信号波形中可以看出，曼彻斯特（Manchester）编码产生的信号频率比不归零制高。从自同步能力来看，不归零制不能从信号波形本身中提取信号时钟频率（这叫做没有自同步能力），而曼彻斯特编码具   有自同步能力。</p><p>（2）    基本的带通调制方法</p><p>最基本的三种调制方法</p><p><img src="https://note.youdao.com/yws/api/personal/file/06E730D52D2D42D3945C232347AD725C?method=download&shareKey=ace8561eee2a7aec1f62ae07787dd7ec" alt></p><p>•    调幅（AM）即载波的振幅随基带数字信号而变化。<br>•    调频（FM）即载波的频率随基带数字信号而变化。<br>•    调相（PM）即载波的初始相位随基带数字信号而变化。</p><h2 id="1-4-电路交换、报文交换与分组交换"><a href="#1-4-电路交换、报文交换与分组交换" class="headerlink" title="1.4    电路交换、报文交换与分组交换"></a>1.4    电路交换、报文交换与分组交换</h2><p>（1）电路交换<br>从通信资源的分配角度来看，交换（switching）就是按照某种方式动态地分配传输线路的资源。在使用电路交换通话之前，必须先拨号请求建立连接。当被叫用户听到交换机送来的振铃音并摘机后，从主叫端到被叫端就建立了一条连接，也就是一条专用的物理通路。这条连接保证了双方通话时所需的通信资源，而这些资源在双方通信时不会被其他用户占用。此后主叫和被叫双方就能互相通电话。通话完毕挂机后， 交换机释放刚才使用的这条专用的物理通路（即把刚才占用的所有通信资源归还给电信网）。这种必须经过”建立连接（占用通信资源）通话（一直占用通信资源）释放连接（归还通信资源）”三个步骤的交换方式称为电路交换。</p><p>（2）报文交换<br>报文交换方式的数据传输单位是报文，报文就是站点一次性要发送的数据块，其长度不限且可变。当一个站要发送报文时，它将一个目的地址附加到报文上，网络节点根据报文上的目的地址信息，把报文发   送到下一个节点，一直逐个节点地转送到目的节点。<br>每个节点在收到整个报文并检查无误后，就暂存这个报文，然后利用路由信息找出下一个节点的地址，再把整个报文传送给下一个节点。因此，端与端之间无需先通过呼叫建立连接。<br>（3）分组交换<br>分组交换是报文交换的一种改进，它将报文分成若干个分组，每个分组的长度有一个上限，有限长度   的分组使得每个节点所需的存储能力降低了，分组可以存储到内存中，提高了交换速度。它适用于交互式   通信，如终端与主机通信。</p><p><img src="https://note.youdao.com/yws/api/personal/file/0DC55D5A3277495289DAE9BB462B55B9?method=download&shareKey=a7506d6369a3cad7b9339b7fd5f2ed25" alt></p><h2 id="1-5-传输介质"><a href="#1-5-传输介质" class="headerlink" title="1.5    传输介质"></a>1.5    传输介质</h2><ol><li>双绞线</li><li>同轴电缆</li><li>无线通信</li></ol><h2 id="1-6-物理层设备"><a href="#1-6-物理层设备" class="headerlink" title="1.6 物理层设备"></a>1.6 物理层设备</h2><ol><li><p>中继器</p></li><li><p>集线器</p></li></ol><h1 id="3-数据链路层"><a href="#3-数据链路层" class="headerlink" title="3 数据链路层"></a>3 数据链路层</h1><p>链路层的主要功能包括链路管理、帧同步、流量控制、差错控制、数据和控制信息分开、透明传输和寻址。</p><h2 id="3-1-局域网"><a href="#3-1-局域网" class="headerlink" title="3.1 局域网"></a>3.1 局域网</h2><p>局域网具有如下一些主要优点：</p><p>（1）具有广播功能，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。<br>（2）便于系统的扩展和逐渐演变，各设备的位置可灵活调整和改变。提高了系统的可靠性（reliability）、可用性（avai1ability）和生存性（survivability）</p><p>为了使数据链路层能更好地适应多种局域网标准，IEEE 802 委员会就把局域网的数据链路层拆成两个子层，即逻辑链路控制 LLC（Logical LinkControl）子层和媒体接入控制 MAC（Medium AccessControl） 子层。与接入到传输媒体有关的内容都放在 MAC 子层，而 LLC 子层则与传输媒体无关，不管采用何种传输媒体和 MAC 子层的局域网对 LLC 子层来说都是透明的。</p><p>以太网与IEEE 802.3</p><p>（1）MAC 层的硬件地址，在局域网中，硬件地址又称为物理地址或 MAC 地址.局域网的”地址”应当是每一个站的”名字”或标识符。</p><p>（2）IEEE 802.11 这种无线局域网的功耗低、传输距离长（最长可达 1 km），很适合于物联网设备之间的通信。</p><h2 id="3-2-广域网"><a href="#3-2-广域网" class="headerlink" title="3.2 广域网"></a>3.2 广域网</h2><p>广域网（WAN，Wide Area Network）也称远程网（long haul network ）。通常跨接很大的物理范围， 所覆盖的范围从几十公里到几千公里，它能连接多个城市或国家，或横跨几个洲并能提供远距离通信，形成国际性的远程网络。</p><p>（1）PPP（Point-to-PointProtocol）协议</p><p>（2）HDLC协议，是通用的数据链路控制协议，在开始建立数据链路时，允许选用特定的操作方式。</p><h2 id="3-3-数据链路层设备"><a href="#3-3-数据链路层设备" class="headerlink" title="3.3 数据链路层设备"></a>3.3 数据链路层设备</h2><p>（1）网桥</p><p>在数据链路层扩展局域网是使用网桥。网桥工作在数据链路层，它根据 MAC 帧的目的地址对收到的帧进行转发。网桥具有过滤帧的功能。当网桥收到一个帧时，并不是向所有的接口转发此帧，而是先检查此帧的目的 MAC 地址，然后再确定将该帧转发到哪一个接口。</p><p><img src="https://note.youdao.com/yws/api/personal/file/F8488EE946054FBDB4B2BC6547FF5977?method=download&shareKey=db97cb4ba0afeb614fce19ee7ccc53bf" alt></p><p>（2）局域网交换机</p><p>以太网交换机实质上就是一个多接口的网桥，通常都有十几个或更多的接口，和工作在物理层的转发器、集线器有很大的差别。以太网交换机的每个接口都直接与一个单台主机或另一个以太网交换机相连，   并且一般都工作在全双工方式。以太网交换机还具有并行性，即能同时连通多对接口，使多对主机能同时通信（而网桥只能一次分析和转发一个帧）。相互通信的主机都是独占传输媒体，无碰撞地传输数据。</p><h1 id="4-网络层"><a href="#4-网络层" class="headerlink" title="4 网络层"></a>4 网络层</h1><h2 id="4-1-ARP协议"><a href="#4-1-ARP协议" class="headerlink" title="4.1 ARP协议"></a>4.1 ARP协议</h2><p>在实际应用中，我们经常会遇到这样的问题：已经知道了一个机器（主机或路由器）的 IP 地址，需要找出其相应的硬件地址。地址解析协议 ARP 就是用来解决这样的问题的。</p><p>（1）ARP进程在本局域网上广播发送一个 ARP  请求分组。图 4-21（a）是主机 A 广播发送 ARP 请求分组的示意图。 ARP 请求分组的主要内容是： “我的 IP 地址是 209.0.0.5 ，硬件地址是 00-00-C0-15-AD-18 。我想知道 IP 地址为 209.0.0.6 的主机的硬件地址。”</p><p>（2）在本局域网上的所有主机上运行的 ARP 进程都收到此 ARP 请求分组。</p><p>（3）主机B的 IP 地址与 ARP 请求分组中要查询的 IP 地址一致，就收下这个 ARP 请求分组， 并向主机 A 发送 ARP 响应分组，同时在这个 ARP 响应分组中写入自己的硬件地址。由于其余的所有主机的 IP 地址都与 ARP 请求分组中要查询的 IP 地址不一致，因此都不理睬这个 ARP 请求分组。ARP 响应分组的主要内容是：”我的IP  地址是 209.0.0.6，我的硬件地址是 08-00-2B-00-EE-0A。”请注意：虽然 ARP请求分组是广播发送的，但 ARP 响应分组是普通的单播，即从一个源地址发送到一个目的地址。</p><p><img src="https://note.youdao.com/yws/api/personal/file/ED89F9AB66274D0090BA4D71B1385B79?method=download&shareKey=f8d5eabfc610815c8d1faaa3b9f661de" alt></p><h2 id="4-2-DHCP协议"><a href="#4-2-DHCP协议" class="headerlink" title="4.2 DHCP协议"></a>4.2 DHCP协议</h2><p>用人工进行协议配置很不方便，而且容易出错。因此，应当采用自动协议配置的方法。互联网现在广泛使   用的是动态主机配置协议DHCP（DynamiCHostConfigurationProtocol），它提供了一种机制，称为即插即用连网（plug-and-play networking）。这种机制允许一台计算机加入新的网络和获取IP 地址而不用手工参与。</p><h2 id="4-3-ICMP协议"><a href="#4-3-ICMP协议" class="headerlink" title="4.3 ICMP协议"></a>4.3 ICMP协议</h2><p>为了更有效地转发 IP 数据报和提高交付成功的机会，在网际层使用了网际控制报文协议 ICMP<br>（InternetControl MessageProtocol）。ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。</p><p>ICMP 是互联网的标准协议。但 ICMP 不是高层协议（看起来好像是高层协议，因为 ICMP 报文是装在 IP 数据报中，作为其中的数据部分），而是 IP 层的协议。ICMP 报文作为 IP 层数据报的数据，加上数据报的首部，组成 IP 数据报发送出去。</p><h2 id="4-4-RIP路由协议"><a href="#4-4-RIP路由协议" class="headerlink" title="4.4 RIP路由协议"></a>4.4 RIP路由协议</h2><p>RIP（Routing InformationProtocol）是内部网关协议 IGP  中最先得到广泛使用的协议，它的中文名称叫做路由信息协议，但很少被使用。RIP 是一种分布式的基于距离向量的路由选择协议，是互联网的标准协议，其最大优点就是简单。</p><h2 id="4-5-OSPF路由协议"><a href="#4-5-OSPF路由协议" class="headerlink" title="4.5 OSPF路由协议"></a>4.5 OSPF路由协议</h2><p>这个协议的名字是开放最短路径优先 OSPF（Open ShortestPath First）。它是为克服 RIP  的缺点在 1989</p><p>年开发出来的。OSPF 的原理很简单，但实现起来却较复杂。”开放”表明 OSP 协议不是受某一家厂商控制， 而是公开发表的。”最短路径优先”是因为使用了 Dijkstra 提出的最短路径算法 SPF。OSPF 的第二个版本OSPF2 己成为互联网标准协议 [RFC2328]  。</p><h2 id="4-6-BGP-路由协议"><a href="#4-6-BGP-路由协议" class="headerlink" title="4.6 BGP 路由协议"></a>4.6 BGP 路由协议</h2><p>边界网关协议 BGP 只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），而井非要寻找一条最佳路由。BGP 采用了路径向量（path vector）路由选择协议，它与距离向量协议（如 RIP） 和链路状态协议（如 OSPF）都有很大的区别。</p><h2 id="4-7-网络层设备"><a href="#4-7-网络层设备" class="headerlink" title="4.7 网络层设备"></a>4.7 网络层设备</h2><p>（1）路由器</p><h1 id="5-传输层"><a href="#5-传输层" class="headerlink" title="5 传输层"></a>5 传输层</h1><h2 id="5-1-UDP协议"><a href="#5-1-UDP协议" class="headerlink" title="5.1 UDP协议"></a>5.1 UDP协议</h2><p>UDP 的主要特点是：<br>（1）UDP 是无连接的，即发送数据之前不需要建立连接（当然，发送数据结束时也没有 连接可释放），因此减少了开销和发送数据之前的时延。</p><p>（2）UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的连接状态表（这里面有许多参数）。</p><p>（3）UDP 是面向报文的。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。 UDP 对应用层交下来的报文，既不合井，也不拆分，而是保留这些报文的边界。这就是说，应用层交给 UDP 多长的报文，UDP 就照样发送，即一次发送一个报文。</p><p>（4）UDP 没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很多的实时应用（如 IP 电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP 正好适合这种要求。</p><p>（5）UDP 支持一对一、一对多、多对一和多对多的交互通信。</p><p>（6）UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短。虽然某些实时应用需要使用没有拥塞控制的 UDP，但当很多的源主机同时都向网络发送高速率的实时视频流时，网络就有可能发生拥塞，结果大家都无法正常接收。因此，不使用拥塞控制功能的 UDP 有可能会引起网络产生严重的拥塞问题。</p><p>用户数据报 UDP 有两个字段：数据字段和首部字段。首部字段很简单，只有 8 个字节，由四个字段组成，每个字段的长度都是两个字节。各字段意义如下：<br>（1）源端口 源端口号。在需要对方回信时选用。不需要时可用全 0。</p><p>（2）目的端口 目的端口号。这在终点交付报文时必须使用。</p><p>（3）长度 UDP 用户数据报的长度，其最小值是 8。</p><p>（4）检验和检测 UDP 用户数据报在传输中是否有错。有错就丢弃。</p><p><img src="https://note.youdao.com/yws/api/personal/file/81F7AD447FFF42CC8C20CA701C7FBA15?method=download&shareKey=e6b8cfe8f296aff25779319faa9cf94c" alt></p><h2 id="5-2-TCP协议"><a href="#5-2-TCP协议" class="headerlink" title="5.2 TCP协议"></a>5.2 TCP协议</h2>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-计算机网络体系结构&quot;&gt;&lt;a href=&quot;#1-计算机网络体系结构&quot; class=&quot;headerlink&quot; title=&quot;1 计算机网络体系结构&quot;&gt;&lt;/a&gt;1 计算机网络体系结构&lt;/h1&gt;&lt;h2 id=&quot;1-1-计算机网络的概念、组成与功能&quot;&gt;&lt;a href=&quot;#1-1-计算机网络的概念、组成与功能&quot; class=&quot;headerlink&quot; title=&quot;1.1 计算机网络的概念、组成与功能&quot;&gt;&lt;/a&gt;1.1 计算机网络的概念、组成与功能&lt;/h2&gt;&lt;p&gt;互联网的拓扑结构虽然非常复杂，并且在地理上覆盖了全球，但从其工作方式上看，可以划分为以下两大块：&lt;br&gt;（1）边缘部分    由所有连接在互联网上的主机组成。这部分是用户直接使用的，用来进行通信（传送数据、音频或视频）和资源共享。&lt;br&gt;（2）核心部分    由大量网络和连接这些网络的路由器组成。这部分是为边缘部分提供服务的（提供连通性和交换）&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="计算机基础知识" scheme="https://liangggggg.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（八）数据预处理与特征工程</title>
    <link href="https://liangggggg.github.io/2020/08/09/Feat/"/>
    <id>https://liangggggg.github.io/2020/08/09/Feat/</id>
    <published>2020-08-09T01:47:42.000Z</published>
    <updated>2020-08-11T07:15:18.866Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据预处理和特征工程"><a href="#数据预处理和特征工程" class="headerlink" title="数据预处理和特征工程"></a>数据预处理和特征工程</h2><h3 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1 数据预处理"></a>1 数据预处理</h3><h4 id="1-1-数据无量纲化"><a href="#1-1-数据无量纲化" class="headerlink" title="1.1 数据无量纲化"></a>1.1 数据无量纲化</h4><ul><li>preprocessing.MinMaxScaler：归一化</li></ul><p>$$x^{*} = \frac{x-min(x)}{max(x)-min(x)}$$</p><ul><li>preprocessing.StandardScaler：标准化</li></ul><p>$$x^{*}=\frac{x-\mu}{\sigma}$$</p><ul><li>StandardScaler和MinMaxScaler选哪个</li></ul><p>大多数机器选择算法会选择StandardScaler进行放缩，因为MinMaxScaler对异常值非常敏感</p><a id="more"></a><h4 id="1-2-缺失值"><a href="#1-2-缺失值" class="headerlink" title="1.2 缺失值"></a>1.2 缺失值</h4><ul><li>填充固定值</li><li>填充均值</li><li>填充中位数</li><li>填充众数</li><li>填充上下跳的数据</li><li>填充插值得到的数据</li><li>填充KNN数据</li><li>填充模型预测的值</li></ul><h4 id="1-3-处理分类型特征：编码与哑变量"><a href="#1-3-处理分类型特征：编码与哑变量" class="headerlink" title="1.3 处理分类型特征：编码与哑变量"></a>1.3 处理分类型特征：编码与哑变量</h4><ul><li><p>preprocessing.LabelEncoder：标签专用，能够将分类转换为分类数值</p></li><li><p>preprocessing.OrdinalEncoder：特征专用，能够将分类特征转化为分类数值</p></li><li><p>preprocessing.OneHotEncoder:独热编码，创建哑变量</p></li></ul><p><img src="https://note.youdao.com/yws/api/personal/file/671DF765B3D84C68A1C2E1038494B94C?method=download&shareKey=5c723470f1cc5eaed7f35061d1aac324" alt></p><p><img src="https://note.youdao.com/yws/api/personal/file/DAC20B5C378C4A4485B373870AAF5971?method=download&shareKey=8ba1b6bb9905782ae7951e742ae79fd0" alt></p><p>但是在独热编码后，增加了特征的维数。如果类别有很多种的话可能特征矩阵非常稀疏</p><h4 id="1-4-处理连续特征：二值化与分段"><a href="#1-4-处理连续特征：二值化与分段" class="headerlink" title="1.4 处理连续特征：二值化与分段"></a>1.4 处理连续特征：二值化与分段</h4><ul><li>sklearn.preprocessing.Binarizer</li></ul><p>根据阈值将数据二值化，用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈值的值射为0。二值化常用于文本计数数据</p><ul><li>preprocessing.KBinsDiscretizer</li></ul><p>将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分分箱后编码</p><table><thead><tr><th align="left">参数</th><th align="left">含义&amp;输入</th></tr></thead><tbody><tr><td align="left">n_bins</td><td align="left">每个特征中分箱的个数，默认5，一次会被运用到所有导入的特征</td></tr><tr><td align="left">encode</td><td align="left">编码的方 式，默 认 “onehot”：做哑变量，之后返回一个稀疏矩阵，每一列是一个特征中的一个类别，含有该类别的样本表示为 1， 不含的表示为0</td></tr><tr><td align="left"></td><td align="left">“ordinal”：每个特征的每个箱都被编码为一个整数，返回每一列是一个特征，每个特征下含有不同整数编码的箱的矩阵</td></tr><tr><td align="left"></td><td align="left">“onehot-dense”：做哑变量，之后返回一个密集数组。</td></tr><tr><td align="left">strategy</td><td align="left">用来定义箱宽的方式，默认”quantile”</td></tr><tr><td align="left"></td><td align="left">“uniform”：表示等宽分箱，即每个特征中的每个箱的最大值之间的差为（$特征.max()-特征.min()/n_bins$）</td></tr><tr><td align="left"></td><td align="left">“quantile”：表示等位分箱，即每个特征中的每个箱内的样本数量都相同</td></tr><tr><td align="left"></td><td align="left">“kmeans”：表示按聚类分箱，每个箱中的值到最近的一维k均值聚类的簇心得距离都相同</td></tr></tbody></table><h3 id="2-特征选择"><a href="#2-特征选择" class="headerlink" title="2 特征选择"></a>2 特征选择</h3><p>我们有四种方法可以用来选择特征：过滤法、嵌入法、包装法、降维算法</p><h4 id="2-1-Filter过滤法"><a href="#2-1-Filter过滤法" class="headerlink" title="2.1 Filter过滤法"></a>2.1 Filter过滤法</h4><p>它是根据各种统计检验中的分数以及相关性的各向指标来选择特征</p><h5 id="2-1-1-方差过滤"><a href="#2-1-1-方差过滤" class="headerlink" title="2.1.1 方差过滤"></a>2.1.1 方差过滤</h5><ul><li>VarianceThreshold</li></ul><p>通过特征本身的方差来筛选特征的类。如果一个特征本身的方差很小，就表示这个特征基本没有差异，那这个特征对于样本区分没有什么作用。</p><h5 id="2-1-2-相关性过滤"><a href="#2-1-2-相关性过滤" class="headerlink" title="2.1.2 相关性过滤"></a>2.1.2 相关性过滤</h5><p>我们希望选出与标签相关且有意义的特征，这样的特征能够为我们提供大量的信息。</p><p><img src="https://note.youdao.com/yws/api/personal/file/6A85336AB79345C18D14A5F3F3D1B4B9?method=download&shareKey=a1bc337ffcb61ce727aa8d9300b45809" alt></p><ul><li>卡方过滤</li></ul><p>卡方过滤是专门针对离散型标签的相关性过滤，通过卡方检验类feature_selection.chi2结合feature_selection.SelectKBest来选出前K个分数最高的特征类</p><ul><li>F检验</li></ul><p>用来捕捉每个特征与标签之间的线性关系的过滤方法，即可以做回归也可以做分类。</p><ul><li>互信息法</li></ul><p>互信息法是用来捕捉每个特征与标签之间的任意关系（包括线性和非线性）的过滤方法，也可以做回归和分类。</p><h4 id="2-2-Embedded嵌入法"><a href="#2-2-Embedded嵌入法" class="headerlink" title="2.2 Embedded嵌入法"></a>2.2 Embedded嵌入法</h4><p>嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。</p><p><img src="https://note.youdao.com/yws/api/personal/file/B20CE443F91E421FA086F0D7B773F940?method=download&shareKey=329d8ddf018f6e52198b696aafc99c1a" alt></p><ul><li>feature_selection.SelectFromModel</li></ul><p>SelectFromModel是一个元变换器，可以与任何在拟合后具有coef_,feature_impoortances_属性或参数中可选惩罚项的评估器一起使用</p><table><thead><tr><th align="left">参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">estimator</td><td align="left">使用的模型评估器，只要是带feature_importances_或者coef_属性，或带有$l_1$和$l_2$惩罚项的模型都可以使用</td></tr><tr><td align="left">threshold</td><td align="left">特征重要性的阈值，重要性低于这个阈值的特征都将被删除</td></tr><tr><td align="left">preﬁt</td><td align="left">默认False，判断是否将实例化后的模型直接传递给构造函数。如果为True，则必须直接调用ﬁt和transform，不能使用ﬁt_transform，并且SelectFromModel不能与cross_val_score，GridSearchCV和克隆估计器的类似实用程序一起使用。</td></tr><tr><td align="left">norm_order</td><td align="left">k可输入非零整数，正无穷，负无穷，默认值为1在评估器的coef_属性高于一维的情况下，用于过滤低于阈值的系数的向量的范数的阶数。</td></tr><tr><td align="left">max_features</td><td align="left">在阈值设定下，要选择的最大特征数。要禁用阈值并仅根据max_features选择，请设置threshold = -np.inf</td></tr></tbody></table><h4 id="3-3-Wrapper包装法"><a href="#3-3-Wrapper包装法" class="headerlink" title="3.3 Wrapper包装法"></a>3.3 Wrapper包装法</h4><p>包装法也是一个特征选择和算法训练同时记性的方法，与嵌入法十分相似，但不同的是，我们往往使用一个目标函数作为黑盒来帮助我们选取特征，而不是自己输入某个评估指标或统计量的阈值。</p><p><img src="https://note.youdao.com/yws/api/personal/file/2210DFBFBE614558A58D1F7F7C3A207F?method=download&shareKey=a4ee875d7e0cf4e62258f04f111375e1" alt></p><ul><li>feature_selection.RFE<br>最典型的目标函数是递归特征消除法（Recursive feature elimination, RFE）</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;数据预处理和特征工程&quot;&gt;&lt;a href=&quot;#数据预处理和特征工程&quot; class=&quot;headerlink&quot; title=&quot;数据预处理和特征工程&quot;&gt;&lt;/a&gt;数据预处理和特征工程&lt;/h2&gt;&lt;h3 id=&quot;1-数据预处理&quot;&gt;&lt;a href=&quot;#1-数据预处理&quot; class=&quot;headerlink&quot; title=&quot;1 数据预处理&quot;&gt;&lt;/a&gt;1 数据预处理&lt;/h3&gt;&lt;h4 id=&quot;1-1-数据无量纲化&quot;&gt;&lt;a href=&quot;#1-1-数据无量纲化&quot; class=&quot;headerlink&quot; title=&quot;1.1 数据无量纲化&quot;&gt;&lt;/a&gt;1.1 数据无量纲化&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;preprocessing.MinMaxScaler：归一化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$x^{*} = \frac{x-min(x)}{max(x)-min(x)}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;preprocessing.StandardScaler：标准化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$x^{*}=\frac{x-\mu}{\sigma}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;StandardScaler和MinMaxScaler选哪个&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大多数机器选择算法会选择StandardScaler进行放缩，因为MinMaxScaler对异常值非常敏感&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（七）无监督学习</title>
    <link href="https://liangggggg.github.io/2020/08/05/Unsupervised/"/>
    <id>https://liangggggg.github.io/2020/08/05/Unsupervised/</id>
    <published>2020-08-05T01:47:42.000Z</published>
    <updated>2020-08-11T07:28:30.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>在“无监督学习”中，训练样本的标记信息时未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础</p><h3 id="1-聚类算法"><a href="#1-聚类算法" class="headerlink" title="1 聚类算法"></a>1 聚类算法</h3><h4 id="1-1-K-means"><a href="#1-1-K-means" class="headerlink" title="1.1 K-means"></a>1.1 K-means</h4><table><thead><tr><th align="left">关键概念：簇与质心</th></tr></thead><tbody><tr><td align="left">KMeans算法将一组N个样本的特征矩阵X划分为K个无交集的簇，直观上来看是簇是一组一组聚集在一起的数据，在一个簇中的数据就认为是同一类。簇就是聚类的结果表现。簇中所有数据的均值\mu_j通常被称为这个簇的“质心”（centroids）。在一个二维平面中，一簇数据点的质心的横坐标就是这一簇数据点的横坐标的均值，质心的纵坐标就是这一簇数据点的纵坐标的均值。同理可推广至高维空间。</td></tr><tr><td align="left"><a id="more"></a></td></tr></tbody></table><p>K-means具体步骤如下：</p><ol><li>随机抽取K个样本作为最初的质心</li><li>开始循坏：<ul><li>将每个样本点分配到离他们最近的质心，生成K个簇</li><li>对于每个簇，计算所有被分到该簇的样本点的平均值作为新的质心</li></ul></li><li>当质心的位置不再发生变化，迭代停止，聚类完成</li></ol><p><img src="https://note.youdao.com/yws/api/personal/file/32020546C1AE4109A10AF82CB9898E86?method=download&shareKey=cd5356c9150e5202cc049f0c226a91c2" alt></p><p>令$x$表示簇找那个的一个样本点，$mu$表示簇中的质心，$n$表示每个样本点钟的特征数目，$i$表示成点$x$的每个特征，则该样本点到质心的距离可以由一下距离来度量</p><p>$$欧几里得距离：d(x,\mu)=\sqrt{\sum_{i=1}^n(x_i-\mu_i)^2}$$</p><p>$$欧几里得距离：d(x,\mu)=\sum_{i=1}^n(|x_i-\mu_i|)$$</p><p>$$余弦距离：cos\theta = \frac{\sum_1^n(x_i * \mu)}{\sqrt{\sum_1^n(x_i)^2} * \sqrt{\sum_1^n(\mu)^2}}$$</p><p>如果我们采用欧几里得距离，则一个簇中所有样本点到质心的距离平方和为</p><p>$$Cluster Sum of Square (CSS) = \sum_{j=0}^n\sum_{i=1}^n(x_i-u_i)^2$$<br>$$Total Cluster Sum of Square = \sum_{l=1}^k CSS_l$$</p><p>其中,$m$为一个簇中样本的个数，$j$是每个样本的编号。将整个数据集中的所有簇的簇内平方和相加，就得到了整体平方和（Total Cluster Sum of Square），KMeans追求的是能让整体平方和最小的质心</p><h4 id="1-2-DBSCAN"><a href="#1-2-DBSCAN" class="headerlink" title="1.2 DBSCAN"></a>1.2 DBSCAN</h4><p>DBSCAN基于“领域”参数（$\epsilon,MinPts$）来刻画样本分布的紧密程度</p><p>|关键概念|<br>|:–|:–|<br>|$\epsilon-$领域|样本集中$x_j$的距离不大于$\epsilon$的样本|<br>|核心对象|若$x_j$的$\epsilon-$领域至少包含MinPts个样本|<br>|密度直达|若$x_j$位于$\epsilon-$领域中，且$x_j$是核心对象，则称$x_j,x_i$密度直达|<br>|密度可达|对$x_i,x_j$存在样本序列$p_1,p_2,\dots,p_n$，其中$p_1=x_i,p_n=x_j$且$p_{i+1}$由$p_i$密度直达|<br>|密度相连|$x_i,x_j$存在$x_k$使得$x_i,x_j$由$x_k$密度可达|</p><p><img src="https://note.youdao.com/yws/api/personal/file/3CFC7255AEF5494EA28847EF8F53B986?method=download&shareKey=d0ab0fa0be730535ee659da645a0ca7d" alt></p><p>DBSCAN具体步骤如下：</p><p>1.找寻核心点形成临时聚类簇</p><p>扫描全部样本点，如果某个样本点R半径范围内点数目大于等于MinPoints，则将其纳入核心点列表，并将其密度直达的点形成对应的临时聚类簇</p><p>2.合并临时聚类簇得到聚类簇</p><p>对于每一个临时聚类簇，检测其中的点是否为核心点，如果是，将该点对应的临时聚类簇和当前临时聚类簇合并，得到新的临时聚类簇</p><p>重复此操作，直到当前临时聚类簇的每一个点要么不在核心点列表，要么密度直达的点都已经在该临时聚类簇，该临时聚类簇升级成为聚类簇</p><p><img src="https://note.youdao.com/yws/api/personal/file/77CEBDB3B8164208AF15C9BF40488424?method=download&shareKey=012cf4c589db2cea9df552ad9aa29fe7" alt></p><h4 id="1-3-层次聚类AGNES"><a href="#1-3-层次聚类AGNES" class="headerlink" title="1.3 层次聚类AGNES"></a>1.3 层次聚类AGNES</h4><p>AGNES是一种采用自底向上聚合策略的层次聚类算法，先将数据集中的每个样本看做一个初始聚类簇，然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并，该过程不断重复，直到达到预设的簇类簇个数</p><p>关键是如何计算簇类簇之间的距离，实际上，每个簇是一个样本集合，因此，只需采用关于集合的某种距离即可，给定聚类簇$c_i,c_j$通过下面式子来计算距离：</p><p>$$最小距离：d_{min}(c_i,c_j)=\min_{x\in c_i,z\in c_j}dist(x,z)$$<br>$$最大距离：d_{max}(c_i,c_j)=\max_{x\in c_i,z\in c_j}dist(x,z)$$<br>$$平均距离：d_{avg}(c_i,c_j)=\frac{1}{|c_i||c_j|}\sum_{x\in c_i}\sum_{z\in c_j}dist(x,z)$$</p><h3 id="2-降维算法"><a href="#2-降维算法" class="headerlink" title="2 降维算法"></a>2 降维算法</h3><h4 id="2-1-PCA所需数学原理"><a href="#2-1-PCA所需数学原理" class="headerlink" title="2.1 PCA所需数学原理"></a>2.1 PCA所需数学原理</h4><p>主成份分析，简称为PCA，是一种非监督学习算法，经常被用来进行</p><ul><li><p>数据降维</p></li><li><p>有损数据压缩</p></li><li><p>特征抽取</p></li><li><p>数据可视化</p></li></ul><p>通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。</p><p>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：</p><ul><li>基于特征值分解协方差矩阵实现PCA算法</li><li>基于SVD分解协方差矩阵实现PCA算法。</li></ul><h5 id="2-1-1-特征值、特征向量、特征值分解"><a href="#2-1-1-特征值、特征向量、特征值分解" class="headerlink" title="2.1.1 特征值、特征向量、特征值分解"></a>2.1.1 特征值、特征向量、特征值分解</h5><p>1.特征值、特征向量</p><p>如果一个向量v是矩阵A的特征向量，将一定可以表示成下面的形式：<br>$$Av=\lambda v$$<br>其中，$\lambda$是特征向量$v$对应的特征值，一个矩阵的一组特征向量是一组正交向量</p><p>2.特征值分解</p><p>对于矩阵A，有一组特征向量v，将这组向量进行正交单位化，就能得到一组正交单位向量。特征值分解，就是将矩阵A分解为如下式：<br>$$A=Q\Sigma Q^{-1}$$<br>其中，Q是矩阵A的特征向量组成的矩阵，$\Sigma$则是一个对角阵，对角线上的元素就是特征值。我们来分析一下特征值分解的式子，分解得到的$\Sigma$矩阵是一个对角阵，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变换方向（从主要的变化到次要的变化排列）</p><p>当矩阵是高维的情况下，那么这个矩阵就是高维空间下的一个线性变换，这个线性变换可能没法通过图片来表示，但是可以想象，这个变换也同样有很多的变化方向，我们通过特征值分解得到的钱N个特征向量，就对应了这个矩阵最重要的N个变化方向。我们利用这前N个变化方向，就可以近似这个矩阵变换，也就是之前说的：<strong>提取这个矩阵最重要的特征</strong>。</p><p><strong>总结</strong>：特征值分解可以得到特征值与特征向量，特征值表示的是这个特征到底有多么重要，而特征向量表示这个特征是什么，可以将每一个特征向量理解为一个线性的子空间，我们可以利用这些线性的子空间干很多事情。不过，<strong>特征值分解也有很多局限，比如说变换的矩阵必须是方阵。</strong></p><h5 id="2-1-2-SVD分解"><a href="#2-1-2-SVD分解" class="headerlink" title="2.1.2 SVD分解"></a>2.1.2 SVD分解</h5><p>1.特征值分解矩阵的缺点</p><p>我们前面讲了很多特征值、特征向量和特征值分解，而且基于我们以前学习的线性代数知识、利用特征值分解提取特征矩阵是一个容易理解并且便于实现的方法。但是为什么还存在奇异值分解呢？特征值分解最大的问题是只能针对方阵，即$n*n$的矩阵，而在实际的应用中，我们分解的大部分都不是方阵。</p><p><strong>举个例子：</strong><br>关系型数据库中的某一张表的数据存储结构类似于一个二维矩阵，假设这个表有m行，有n个字段，那么这个表数据矩阵规模就是$m*n$。很明显，在绝大部分情况下，m和n是不相等的。如果这个时候要对这个矩阵进行特征提取，特征值分解的方法明显就不行了。此时，就可以用SVD对非方阵进行分解。</p><p>2.奇异值分解</p><p>奇异值分解是一个能使用与任意矩阵的一种分解方式，对于任意矩阵A总是存在一个奇异值分解：</p><p>$$A=U\Sigma V^T$$</p><p>假设A是一个$m * n$的矩阵，那么得到的U是一个$m * m$的方阵，U里面的正交向量被称为左奇异向量。$\Sigma$是一个$m*n$的矩阵，<br>$\Sigma$除了对角线其他元素都为0，对角线上的元素称为奇异值。</p><p><strong>思考：</strong>虽说上面奇异值分解等式成立，但是如何求得左奇异值向量、右奇异值向量和奇异值呢？<br><strong>答案：</strong>由上面的奇异值分解等式，我们是不知道如何拆分矩阵A的。我们可以把奇异值和特征值联系起来。<br>首先，我们用矩阵A的转置乘以A，得到一个方阵，用这样的方阵进行特征分解，得到的特征值和特征向量满足下面的等式：<br>$$(A^TA)v_i=\lambda_iv_i$$<br>这里的$v_i$就是我们要求的右奇异向量。<br>其次，我们将A和A的转置做矩阵的乘法，得到一个方阵，用这样的方阵进行特征分解，得到的特征和特征向量满足下面的等式：<br>$$(AA^T)u_i=\lambda_iu_i$$<br>这里的$u_i$就是左奇异向量。<br><strong>思考：</strong>上面我们说$A^TA$的特征向量组成的矩阵是我们SVD中的V矩阵，而$AA^T$的特征向量组成的就是我们SVD的U矩阵，这有什么根据么？我们来证明一下，以V举证的证明为例：<br>$$A=U\Sigma V^T\Rightarrow A^T=V\Sigma^TU^T\Rightarrow A^TA=V\Sigma^TU^TU\Sigma V^T=V\Sigma^2V^T$$</p><p>上式证明中使用了$U^TU=I,\Sigma^T\Sigma=\Sigma^2$,可以看出，$A^TA$的特征向量组成的矩阵就是我们SVD中的V矩阵，而$AA^T$的特征向量组成的就是我们SVD中的U矩阵。</p><p><strong>补充定义：</strong><br>$$U\in M_n(R)满足U^TU=I，则U是实正交矩阵$$<br>此外，我们还可以得到奇异值，奇异值求法有两种：</p><p><strong>a)第一种：</strong><br>$$A=U\Sigma V^T\Rightarrow AV\Rightarrow U\Sigma V^TV\Rightarrow AV = U\Sigma\Rightarrow Av_i=\sigma u_i\Rightarrow \sigma_i=\frac{Av_i}{u_i}$$</p><p><strong>b)第二种</strong> </p><p>通过上面的证明，我们还可以看出，特征值举证等于奇异值矩阵的平方，也就是说特征值和奇异值满足如下关系：<br>$$\sigma_i=\sqrt{\lambda_i}$$<br>这里的$\sigma_i$就是奇异值，奇异值$\sigma_i$跟特征值类似，在矩阵$\Sigma$中也是从大到小排列。</p><p><strong>思考：</strong><br>我们已经知道如何用奇异值分解任何矩阵了，那么问题又来了，一个m<em>n的矩阵A，你把它分解成m</em>m的矩阵U、m<em>n的矩阵$\Sigma$和n</em>n的矩阵$V^T$</p><p>这三个矩阵中任何一个的维度似乎一点也不比A的维度小，而且还要做两次矩阵的乘法，这不是把简单的事情变得更加复杂了吗？</p><p><strong>答案：</strong><br>在奇异值分解矩阵中$\Sigma$里面的奇异值按从大到小的顺序排列，奇异值$\sigma_i$从大到小的顺序减小的特别快。<strong>在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上，也就是说，剩下的90%甚至99%的奇异值几乎没有什么作用。</strong>因此，我们可以用前面r个打的奇异值来近似描述矩阵，于是奇异值分解公式可以写成如下：</p><p>$$A_{m * n}\approx U_{m * n}\Sigma_{r * r}V_{r * n}^T$$</p><p>其中r是一个远远小于m和n的数，右边的三个举证相乘的结果会将使一个接近A的矩阵。如果r越接近于n，则相乘的结果越接近于A。如果r的取值远远小于n，从计算机内存的角度来说，右边三个矩阵的存储内存要远远小于矩阵A的。<strong>所以在奇异值分解中r的取值很重要，就是在计算精度和事件空间之间做选择。</strong></p><h5 id="2-1-3-协方差和散度矩阵"><a href="#2-1-3-协方差和散度矩阵" class="headerlink" title="2.1.3 协方差和散度矩阵"></a>2.1.3 协方差和散度矩阵</h5><p><strong>样本均值：</strong></p><p>$$\bar x = \frac{1}{n}\sum_{i=1}^Nx_i$$</p><p><strong>样本方差：</strong><br>$$S^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar x)^2$$</p><p><strong>样本X和样本Y的协方差</strong></p><p>$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)$$</p><p>由上面的公式，我们可以得到以下结论：</p><p>（1）方差的计算公式是针对一维特征，即针对同一特征不同样本的取值来进行计算得到；而协方差则必须要求至少满足二维特征；方差是协方差的特殊情况。</p><p>（2）方差和协方差的除数是n-1，这是为了得到方差和协方差的无偏估计。</p><p>协方差为正时，说明X和Y是正相关关系；协方差为负时，说明X和Y是负相关关系；协方差为0时，说明X和Y是相互独立。Cov(X,X)就是X的方差。当样本是n维数据时，它们的协方差实际上式协方差矩阵（对称方阵）。例如，对于3维数据（x,y,z），计算它的协方差就是：</p><p>$$<br>Cov(X,Y,Z)=\begin{bmatrix}<br>Cov(x,x) &amp; Cov(x,y) &amp;Cov(x,z) \\<br>Cov(y,x) &amp; Cov(y,y) &amp; Cov(y,x)\\<br>Cov(z,x) &amp; Cov(z,x) &amp; Cov(z,z)<br>\end{bmatrix}<br>$$</p><p><strong>散度矩阵定义为：</strong><br>$$S=\sum_{k=1}^n(x_k-m)(x_k-m)^T$$</p><p>$$m=\frac{1}{n}\sum_{k=1}^nx_k$$</p><p>对于数据X的<strong>散度矩阵为：</strong>$$XX^T$$</p><p>其实协方差矩阵和三都矩阵关系密切，散度矩阵就是协方差矩阵乘以（总数据量-1）。因此它们的特征值和特征向量是一样的。这里值得注意的是，散度矩阵是SVD奇异值分解的一步，因此PCA和SVD是由很大联系的。</p><h4 id="2-2-PCA算法两种实现方法"><a href="#2-2-PCA算法两种实现方法" class="headerlink" title="2.2 PCA算法两种实现方法"></a>2.2 PCA算法两种实现方法</h4><h5 id="2-2-1-基于特征值分解协方差矩阵实现PCA算法"><a href="#2-2-1-基于特征值分解协方差矩阵实现PCA算法" class="headerlink" title="2.2.1 基于特征值分解协方差矩阵实现PCA算法"></a>2.2.1 基于特征值分解协方差矩阵实现PCA算法</h5><p>输入数据集：<br>$$X={x_1,x_2,x_3,\dots,x_n}$$</p><p>需要降到K维</p><ol><li><p>去平均值（即去中心化），即每一位特征减去各自的平均值</p></li><li><p>计算协方差矩阵$$\frac{1}{n}XX^T$$</p><p> 注：这里除或不除n或n-1，其实对求出的特征向量没有影响。</p></li><li><p>用特征值分解方法求协方差矩阵</p><p> $$\frac{1}{n}XX^T$$的特征值与特征向量。</p></li><li><p>对特征值从大到小排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P。</p></li><li><p>将数据转换到k个特征向量构建的新空间中，即Y=PX。</p></li></ol><h5 id="2-2-2-基于SVD分解协方差矩阵实现PCA算法"><a href="#2-2-2-基于SVD分解协方差矩阵实现PCA算法" class="headerlink" title="2.2.2 基于SVD分解协方差矩阵实现PCA算法"></a>2.2.2 基于SVD分解协方差矩阵实现PCA算法</h5><p>输入数据集：<br>$$X={x_1,x_2,x_3,\dots,x_n}$$</p><p>需要降到K维</p><ol><li><p>去平均值（即去中心化），即每一位特征减去各自的平均值</p></li><li><p>计算协方差矩阵$$\frac{1}{n}XX^T$$</p><p> 注：这里除或不除n或n-1，其实对求出的特征向量没有影响。</p></li><li><p>用SVD计算协方差矩阵</p><p> $$\frac{1}{n}XX^T$$的特征值与特征向量。</p></li><li><p>对特征值从大到小排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P。</p></li><li><p>将数据转换到k个特征向量构建的新空间中，即Y=PX。</p><p> 在PCA降维中，我们需要找到样本协方差矩阵$XX^T$的最大K个特征向量，然后用这个最大的K个特征向量组成的矩阵来做低维投影降维。</p><p> 当样本数多、样本特征数也多的时候，这个计算还是很大的。</p></li></ol><p><strong>当我们用SVD分解协方差矩阵的时候SVD有两个好处：</strong></p><ol><li>有一些SVD的实现算法可以先不求出协方差矩阵$XX^T$也能求出我们的右奇异矩阵V。也就是说，我们的PCA算法可以不用做特征分解而是通过SVD来完成，这个方法在样本量很大的时候很有效。实际上，scikit-learn的PCA算法的背后真正的实现就是用的SVD，而不是特征值分解。</li></ol><ol start="2"><li>注意到PCA仅仅使用了我们SVD的左奇异矩阵，没有使用到右奇异值矩阵，那么右奇异值矩阵有什么用呢？假设我们的样本是$m * n$的矩阵X，如果我们通过SVD找到了矩阵$X^TX$最大的k个特征向量组成的$k * n$的矩阵$V^T$,可以得到一个$m * k$的矩阵$X^{‘}$,这个矩阵和我们原来$m * n$的矩阵X相比，列数从n减到了K,可见对列数进行了压缩，也就是说，左奇异矩阵可以用于对行数的压缩；右奇异矩阵可以用于对列（即特征维度）的压缩。这就是我们用SVD分解协方差矩阵实现PCA可以得到两个方向的PCA降维（即行和列两个方向）</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;无监督学习&quot;&gt;&lt;a href=&quot;#无监督学习&quot; class=&quot;headerlink&quot; title=&quot;无监督学习&quot;&gt;&lt;/a&gt;无监督学习&lt;/h2&gt;&lt;p&gt;在“无监督学习”中，训练样本的标记信息时未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础&lt;/p&gt;
&lt;h3 id=&quot;1-聚类算法&quot;&gt;&lt;a href=&quot;#1-聚类算法&quot; class=&quot;headerlink&quot; title=&quot;1 聚类算法&quot;&gt;&lt;/a&gt;1 聚类算法&lt;/h3&gt;&lt;h4 id=&quot;1-1-K-means&quot;&gt;&lt;a href=&quot;#1-1-K-means&quot; class=&quot;headerlink&quot; title=&quot;1.1 K-means&quot;&gt;&lt;/a&gt;1.1 K-means&lt;/h4&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;关键概念：簇与质心&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;KMeans算法将一组N个样本的特征矩阵X划分为K个无交集的簇，直观上来看是簇是一组一组聚集在一起的数据，在一个簇中的数据就认为是同一类。簇就是聚类的结果表现。簇中所有数据的均值\mu_j通常被称为这个簇的“质心”（centroids）。在一个二维平面中，一簇数据点的质心的横坐标就是这一簇数据点的横坐标的均值，质心的纵坐标就是这一簇数据点的纵坐标的均值。同理可推广至高维空间。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（六）朴素贝叶斯</title>
    <link href="https://liangggggg.github.io/2020/08/03/Bayes/"/>
    <id>https://liangggggg.github.io/2020/08/03/Bayes/</id>
    <published>2020-08-03T01:47:42.000Z</published>
    <updated>2020-08-11T07:12:54.897Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-朴素贝叶斯原理"><a href="#1-朴素贝叶斯原理" class="headerlink" title="1 朴素贝叶斯原理"></a>1 朴素贝叶斯原理</h2><p>朴素贝叶斯是一种直接衡量标签和特征之间的概率关系的有监督学习算法，是一种专注分类的算法</p><p>贝叶斯理论等式：</p><p>$$P(Y|X)=\frac{P(X|Y) * P(Y)}{P(X)}$$</p><p>我们可以把特征$X$当成是我们的条件事件，而我们要求解的标签Y当成是我们被满足条件后会被影响的结果，而两者之间的概率关系就是$P(Y|X)$，这个概率在机器学习中，被称为是标签的后验概率。而标签Y被写作$P(Y)$，被称为标签的先验概率</p><a id="more"></a><p>假设我们只有两个特征$X_1,X_2$，由联合概率公式</p><p>$$P(X_1,X_2|Y=1)=\frac{X_1,X_2,Y=1}{P(Y=1)}$$<br>$$=\frac{P(X_1,X_2,Y=1)}{P(X_2,Y=1)} * \frac{P(X_2,Y=1)}{P(Y=1)}$$<br>$$=P(X_1|X_2,Y=1) * P(X_2|Y=1)$$</p><p><strong>将(X_2,Y=1)看成一个条件</strong></p><p><strong>当X_1,X_2是独立时$$P(X_1|X_2,Y=1)等于P(X_1|Y=1)$$</strong><br>$$=P(X_1|Y=1) * P(X_2|Y=1)$$</p><p>推广到n个$X$，则有：</p><p>$$P(X|Y=1)=\prod_{i=1}^{n}P(X_i=x_i|Y=1)$$</p><p><strong>假设特征之间是有条件独立的，可以解决众多问题，也简化了很多计算过程，这是朴素贝叶斯被称为“朴素”的理由</strong></p><p>因此，贝叶斯在特征之间有较多相关性的数据集上表现不佳。</p><p>分母的求解可以根据全概率公式<br>$$P(X)=\sum_{i=1}^mP(y_i) * P(X|Y_i)$$</p><p>其中m代表标签的种类，对于二分类：<br>$$P(X)=P(Y=1) * P(X|Y=1)+P(Y=0) * P(X|Y=0)$$</p><h2 id="2-不同分布下的贝叶斯"><a href="#2-不同分布下的贝叶斯" class="headerlink" title="2 不同分布下的贝叶斯"></a>2 不同分布下的贝叶斯</h2><h3 id="2-1-高斯朴素贝叶斯GaussianNB"><a href="#2-1-高斯朴素贝叶斯GaussianNB" class="headerlink" title="2.1 高斯朴素贝叶斯GaussianNB"></a>2.1 高斯朴素贝叶斯GaussianNB</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.naive_bayes.GaussianNB (priors&#x3D;None, var_smoothing&#x3D;1e-09)</span><br></pre></td></tr></table></figure><p>高斯朴素贝叶斯，通过假设$P(x_i|Y)$是服从高斯分布</p><p>$$P(x_i|Y)=f(x_i;\mu,\sigma) * \epsilon$$<br>$$=\frac{1}{\sqrt{2\pi \sigma_y^2}}exp(-\frac{(x_i-\mu_y)^2}{2\sigma_y^2})$$</p><h3 id="2-2-多项式朴素贝叶斯MultinomialNB"><a href="#2-2-多项式朴素贝叶斯MultinomialNB" class="headerlink" title="2.2 多项式朴素贝叶斯MultinomialNB"></a>2.2 多项式朴素贝叶斯MultinomialNB</h3><p>假设概率分布是服从一个简单多项式分布，具体可解释为：实验包括n次重复实验，每项实验都有不同的可能结果，在任何给定的实验中，特定结果发生的概率是不变的。</p><ol><li>多项式分布擅长的是分类型变量，在其原理假设中的概率是离散的，并且不同下的相互独立，互不影响。虽然sklearn中的多项式分布也可以处理连续型变量，但现实中，如果我们真的想要处理连续型变量，使用高斯朴素贝叶斯。</li><li>多项式实验中的实验结果都很具体，它所涉及的特征往往是次数，频率，计数，出现与否这样的概念，这些概念都是离散的正整数，因此sklearn中的多项式朴素贝叶斯不接受负值的输入。</li></ol><h3 id="2-3-伯努利朴素贝叶斯BernoulliNB"><a href="#2-3-伯努利朴素贝叶斯BernoulliNB" class="headerlink" title="2.3 伯努利朴素贝叶斯BernoulliNB"></a>2.3 伯努利朴素贝叶斯BernoulliNB</h3><p>多项式朴素贝叶斯可同时处理二项分布（抛硬币）和多项分布（掷骰子），其中二项分布又叫做伯努利分布，它是一种现实中常见，并且拥有很多优越数学性质的分布。因此，既然有着多项式朴素贝叶斯，我们自然也就又专门用来处理二项分布的朴素贝叶斯：伯努利朴素贝叶斯。</p><h3 id="2-4-改进多项式朴素贝叶斯：补集朴素贝叶斯ComplementNB"><a href="#2-4-改进多项式朴素贝叶斯：补集朴素贝叶斯ComplementNB" class="headerlink" title="2.4 改进多项式朴素贝叶斯：补集朴素贝叶斯ComplementNB"></a>2.4 改进多项式朴素贝叶斯：补集朴素贝叶斯ComplementNB</h3><p>补集朴素贝叶斯（complement naive Bayes，CNB）算法是标准多项式朴素贝叶斯算法的改进。CNB的发明小组创造出CNB的初衷是为了解决贝叶斯中的“朴素”假设带来的各种问题，他们希望能够创造出数学方法以逃避朴素贝叶斯中的朴素假设，让算法能够不去关心所有特征之间是否是条件独立的。以此为基础，他们创造出了能够解决样本不平衡问题，并且能够一定程度上忽略朴素假设的补集朴素贝叶斯。在实验中，CNB的参数估计已经被证明比普通多项式朴素贝叶斯更稳定，并且它特别适合于样本不平衡的数据集。有时候，CNB在文本分类任务上的表现有时能够优于多项式朴素贝叶斯，因此现在补集朴素贝叶斯也开始逐渐流行。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-朴素贝叶斯原理&quot;&gt;&lt;a href=&quot;#1-朴素贝叶斯原理&quot; class=&quot;headerlink&quot; title=&quot;1 朴素贝叶斯原理&quot;&gt;&lt;/a&gt;1 朴素贝叶斯原理&lt;/h2&gt;&lt;p&gt;朴素贝叶斯是一种直接衡量标签和特征之间的概率关系的有监督学习算法，是一种专注分类的算法&lt;/p&gt;
&lt;p&gt;贝叶斯理论等式：&lt;/p&gt;
&lt;p&gt;$$P(Y|X)=\frac{P(X|Y) * P(Y)}{P(X)}$$&lt;/p&gt;
&lt;p&gt;我们可以把特征$X$当成是我们的条件事件，而我们要求解的标签Y当成是我们被满足条件后会被影响的结果，而两者之间的概率关系就是$P(Y|X)$，这个概率在机器学习中，被称为是标签的后验概率。而标签Y被写作$P(Y)$，被称为标签的先验概率&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（五）集成学习</title>
    <link href="https://liangggggg.github.io/2020/07/26/ensemble/"/>
    <id>https://liangggggg.github.io/2020/07/26/ensemble/</id>
    <published>2020-07-26T01:47:42.000Z</published>
    <updated>2020-08-02T03:17:17.716Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><p>多个模型集成称为的模型叫作集成评估器（ensemble estimator），组成集成评估器的每个模型都叫作基评估器(base estimator)。通常来说，有两类集成算法：装袋法（Bagging），提升法(Boosting)。要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，并且要有“多样性”</p><p><img src="https://note.youdao.com/yws/api/personal/file/ADF733049258402C8AD900FD965CB288?method=download&shareKey=18ded5ff7e25a56d46886670b21ef009" alt></p><ul><li>装袋法：多个相互独立的评估器，对其预测进行平均或多数表决原则来决定集成评估器的结果（随机森林）</li><li>提升法：基评估器是相关的，是按顺序一一构建的。其核心思想是结合弱评估器的力量一次次对难以评估的样本进行预测，从而构成一个强评估器（Adaboost，梯度提升树）<a id="more"></a></li></ul><h2 id="2-Bagging"><a href="#2-Bagging" class="headerlink" title="2 Bagging"></a>2 Bagging</h2><p>Bagging是并行式集成学习方法最著名的代表，通过自助采样法得到多个训练样本的采样集，然后基于每个采样集孙连出一个基学习器，再将这些基学习器进行结合，在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。</p><h3 id="2-1-随机森林（Random-Forest-RF）"><a href="#2-1-随机森林（Random-Forest-RF）" class="headerlink" title="2.1 随机森林（Random Forest, RF）"></a>2.1 随机森林（Random Forest, RF）</h3><p>随机森林是非常具有代表性的Bagging集成算法，RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择，传统决策树在选择划分属性时是在当前节点的属性集合（假设有d个属性）中选择一个最优属性；而在RF中，对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含$k$个属性的子集，然后再从这个子集中选择一个最优属性用于划分。</p><h3 id="2-2-重要参数"><a href="#2-2-重要参数" class="headerlink" title="2.2 重要参数"></a>2.2 重要参数</h3><h3 id="2-2-1-控制基评估器的参数"><a href="#2-2-1-控制基评估器的参数" class="headerlink" title="2.2.1 控制基评估器的参数"></a>2.2.1 控制基评估器的参数</h3><table><thead><tr><th align="left">参数</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">criterion</td><td align="left">不纯度的衡量指标，有基尼系数和信息熵两种选择</td></tr><tr><td align="left">max_depth</td><td align="left">树的最大深度，超过最大深度的树枝都会被剪掉</td></tr><tr><td align="left">min_samples_leaf</td><td align="left">一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本，否则分枝就不会发生</td></tr><tr><td align="left">min_samples_split</td><td align="left">一个节点必须要包含至少min_samples_split个训练样本，这个节点才允许被分枝，否则分枝就不会发生</td></tr><tr><td align="left">max_features</td><td align="left">max_features限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃，默认值为总特征个数开平方取整</td></tr><tr><td align="left">min_impurity_decrease</td><td align="left">限制信息增益的大小，信息增益小于设定数值的分枝不会发生</td></tr></tbody></table><h3 id="2-2-2-n-estimators"><a href="#2-2-2-n-estimators" class="headerlink" title="2.2.2 n_estimators"></a>2.2.2 n_estimators</h3><p>这是森林中树木的数量，即基评估器的数量。这个参数对随机森林模型的精确性影响是单调的，n_estimators越大，模型的效果往往越好。但是相应的，任何模型都有决策边界，n_estimators达到一定的程度之后，随机森林的精确性往往不在上升或开始波动，并且，n_estimators越大，需要的计算量和内存也越大，训练的时间也会越来越长。对于这个参数，我们是渴望在训练难度和模型效果之间取得平衡。</p><p>n_estimators的默认值在现有版本的sklearn中是10，但是在即将更新的0.22版本中，这个默认值会被修正为100。这个修正显示出了使用者的调参倾向：要更大的n_estimators。</p><h3 id="2-2-3-random-state"><a href="#2-2-3-random-state" class="headerlink" title="2.2.3 random_state"></a>2.2.3 random_state</h3><p>在决策树中，从最重要的特征中随机选择出一个特征进行分枝，这个功能由参数random_state控制，在随机森林中，用法和分类树相似，通过这个参数控制生成森林的模型，让森林中的树木具有多样性</p><h3 id="2-2-4-bootstrap-amp-oob-score"><a href="#2-2-4-bootstrap-amp-oob-score" class="headerlink" title="2.2.4 bootstrap &amp; oob_score"></a>2.2.4 bootstrap &amp; oob_score</h3><p>Bagging通过自助采样技术来形成不同的训练数据，bootstrap就是用来控制采样技术的参数</p><p>bootstrap参数默认True，代表采用这种有放回的随机抽取技术（通常不会被设置为False）</p><p><img src="https://note.youdao.com/yws/api/personal/file/4BDC11FD2EB54DFE874F6D1AB68277A0?method=download&shareKey=6ade8a6ff415a53d39ae944bccf89e54" alt></p><p>一般来说，自助集大概平均会包含63%的原始数据，每一个样本被抽取到某自助集的概率为：</p><p>$$1-(1-\frac{1}{n})^n$$</p><p>当n足够大时，这个概率收敛与$1-(1/e)$，越等于0.632，因此会约有37%的训练数据被浪费掉，没有参与建模，这些数据被称为袋外数据(out of bag data, oob)。</p><p>也就是说，在使用随机森林时，可以不划分测试集和训练集，用袋外数据来测试我们的模型</p><h2 id="3-boosting"><a href="#3-boosting" class="headerlink" title="3 boosting"></a>3 boosting</h2><p>Boosting是一族可将弱学习器提升为强学习器的算法。先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器。</p><h3 id="3-1-Adaboost"><a href="#3-1-Adaboost" class="headerlink" title="3.1 Adaboost"></a>3.1 Adaboost</h3><h4 id="3-1-1-Adaboost原理"><a href="#3-1-1-Adaboost原理" class="headerlink" title="3.1.1 Adaboost原理"></a>3.1.1 Adaboost原理</h4><p>AdaBoost算法是Adaptive Boost的简称，Boosting通过将一系列弱学习器组合起来，通过集成这些弱学习器的学习能力，得到一个强学习器。具体到AdaBoost算法，AdaBoost在之前学习器的基础上改变样本的权重，增加那些之前被分类错误的样本的比重，降低分类正确样本的比重，这样之后的学习器将重点关注那些被分类错误的样本。最后通过将这些学习器通过加权组合成一个强学习器，具体的，分类正确率高的学习器权重较高，分类正确率低的学习器权重较低。</p><p>假设：</p><p>输入：训练集$X={(x_1,y_1),(x_2,y_2),(x_3,y_3),\dots,(x_n,y_n)},\ x_i\in R^n,\ y_i\in 0,1$</p><p>输出：最终学习器$G(x)$</p><ol><li>初始化训练数据的权重分布值：（$D_m$表示第m个弱学习器的样本点的权值）<br>$$D_1=(w_{11},\dots,w_{1i},\dots,w_{1N}),\  w_{1i}=1/N,\  i=1,2,\dots,N$$</li><li>对于M个弱学习器，$m=1,2,3,\dots,M$<ul><li>使用具有权值分布$D_m$的训练数据集进行学习，得到基本分类器$G_m(x)$，其输出值为$-1,1$</li><li>计算弱分类器$G_m(x)$在训练数据集上的分类误差率$e_m$，其值越小的基分类器在最终分类器中的作用越大<br>$$e_m = P(G_m(x)\ne y_i)=\sum_{i=1}^N w_{mi}I(G_m(x_i)\ne y_i)$$<br>其中，$I(G_m(x_i)\ne y_i)$取值为0或1，取0表示分类正确，取1表示分类错误。</li><li>计算弱分类器$G_m(x)$的权重系数$\alpha_m$:<br>$$\alpha_m = \frac{1}{2}ln\frac{1-e_m}{e_m}$$<br>当$e_m$减小是时候$\alpha_m$的值增大，而我们希望得到的是分类误差率越小的弱分类器的权值越大，对最终的预测产生的影响也就越大</li><li>更新训练集的样本权值分布：<br>$$D_{m+1}=(w_{m+1,1},w_{m+1,2},\dots,w_{m+1,N})$$<br>$$w_{m+1,i}=\frac{w_{mi}}{Z_m}exp(-\alpha_m y_i G_m(x_i)),\ i=1,2,\dots,N$$<br>对于二分类，弱分类器$G_m(x)$的输出取值为$-1,1$，$y_i$的取值为$-1,1$，所以对于正确的分类$y_iG_m(x)&gt;0$，错误的分类小于0，由于样本权重值在$0-1$之间，当分类正确时的$w_{m+1,i}$取值较小，而分类错误时$w_{m+1,i}$取值较小，而分类错时取值较大，符合我们期望的权重值高的训练样本点在后面的弱学习器中会得到更多的重视。<br>其中，$Z_m$是规范化因子，主要作用是将$W_{mi}$规范到0-1之间，使得$\sum_{i=1}^Nw_{mi}=1$</li></ul></li></ol><p>$$Z_m = \sum_{i=1}^N w_{mi}exp(-\alpha_m y_i G_m(x_i))$$</p><ol start="3"><li>通过加权平均法构建基本分类器的线性组合<br>$$f(x)=\sum_{m=1}^M \alpha_mG_m(x)$$<br>得到最终的分类器<br>$$G(x)=sign(f(x))=sign(\sum_{m=1}^M\alpha_mG_m(x))$$</li></ol><h4 id="3-1-2-Adaboost优缺点"><a href="#3-1-2-Adaboost优缺点" class="headerlink" title="3.1.2 Adaboost优缺点"></a>3.1.2 Adaboost优缺点</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ol><li>不容发生过拟合</li><li>由于AdaBoost并没有限制弱学习器的种类，所以可以使用不同的学习算法来构建弱分类器</li><li>具有很高的精度</li><li>相对于Bagging算法和Random Forest算法，Adaboost充分考虑每个分类器的权重</li><li>参数较少，实际应用中不需要调节太多的参数</li></ol><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ol><li>AdaBoost迭代次数也就是弱分类器数目不太好设定，可以用交叉验证来确定</li><li>数据不平衡导致分类精度下降</li><li>训练比较耗时，每次重新选择当前分类器最好切分点</li><li>对异常样本敏感，异常样本在迭代中可能会获得比较高的权重，影响最终的枪学习器的预测准确性</li></ol><h3 id="3-2-GBDT（Gradient-Boosting-Decision-Tree，梯度提升树）"><a href="#3-2-GBDT（Gradient-Boosting-Decision-Tree，梯度提升树）" class="headerlink" title="3.2 GBDT（Gradient Boosting Decision Tree，梯度提升树）"></a>3.2 GBDT（Gradient Boosting Decision Tree，梯度提升树）</h3><h4 id="3-2-1-GBDT原理"><a href="#3-2-1-GBDT原理" class="headerlink" title="3.2.1 GBDT原理"></a>3.2.1 GBDT原理</h4><p>输入：训练数据集$T=(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)$，损失函数为$L(y,f(x))$<br>输出：回归树$F(x)$</p><ol><li>初始化：（估计使损失函数极小化的常数值，是只有一个根节点的树，一般平方损失函数为节点的均值，而绝对损失函数为节点样本的中位数）</li></ol><p>$$f_0(x)=arg\min_c\sum_{i=1}^NL(y_i,c)$$</p><ol start="2"><li><p>对$m=1,2,\dots,M$（M表示迭代次数，即生成弱学习器的个数）</p><ul><li>对于样本$i=1,2,\dots,N$，计算损失函数的负梯度在当前模型的值，将它作为残差的估计<br>$$r_{mi}=-\frac{\partial L(y_i,f(x))}{\partial f(x_i)}f(x)=f_{m-1}(x)$$</li><li>对$(x_1,r_{m1}),\dots,(x_N,r_{mN})$拟合一个回归树，得到第$m$棵树的叶结点区域$R_{mj}，\ j=1,2,\dots,J$（$J$表示每棵树的叶结点个数）</li><li>对$j=1,2,\dots,J$，利用线性所搜，估计叶结点区域的值，使损失函数最小化，计算<br>$$c_{mj}=arg\min_c\sum_{x\in R_{mj}}L(y_i,f_{m-1}(x_i+c))$$</li><li>更新<br>$$f_m(x)=f_{m-1}(x)+\sum_{J}^{j=1}c_{mj}I(x\in R_{mj})$$</li></ul></li><li><p>得到最终的回归树<br>$$F(x)=\sum_{m=1}^M\sum_{j=1}^Jc_{mj}I(x\in R_{mj})$$</p></li></ol><h3 id="3-3-XGboost"><a href="#3-3-XGboost" class="headerlink" title="3.3 XGboost"></a>3.3 XGboost</h3><h4 id="3-3-1-目标函数"><a href="#3-3-1-目标函数" class="headerlink" title="3.3.1 目标函数"></a>3.3.1 目标函数</h4><p>不同于逻辑回归和SVM等算法中固定的损失函数写法，集成算法中的损失函数式可选的，要选用什么损失函数取决于我们希望解决什么问题，以及希望使用什么的模型。只要我们选出的函数式一个可微的，能够代表某种损失的函数，它就可以使XGB的损失函数</p><p>并且XGB引入了模型复杂度来衡量算法的运算效率，因此目标函数被写作：传统损失函数+模型复杂度<br>$$0bj = \sum_{i=1}^ml(y_i,\hat y_i)+\sum_{k=1}^k\Omega (f_k)$$</p><p>其中$i$代表数据集中的第$i$个样本，$m$表示导入第k课树的数据总量，$K$代表建立的所有树(n_estimators)</p><p><strong>注意，第二项中没有特征矩阵$x_i$的介入</strong></p><p>第一项传统损失函数式与已建好的所有树相关的</p><p>$$\hat y_i^{(t)}=\sum_k^t f_k(x_i)=\sum_k^{t-1}f_k(x_i)+f_t(x_i)$$</p><p>一个集成模型$(f)$在位置数据集$(D)$上的泛化误差$E(f;D)$,有方差(var)，偏差(bais)和噪声$(\epsilon)$共同决定。</p><p><img src="https://note.youdao.com/yws/api/personal/file/48279AFEA82B4F87A43B6C43E9140635?method=download&shareKey=ec4af651ab4bd7023b0bcaa0f4657e25" alt></p><p>我们使用参数”objective”来确定我们目标函数的第一部分，也是衡量损失的部分</p><table><thead><tr><th align="left">输入</th><th align="left">选用的损失函数</th></tr></thead><tbody><tr><td align="left">reg:linear</td><td align="left">使用线性回归的损失函数，均方误差，回归时使用</td></tr><tr><td align="left">binary:logistic</td><td align="left">使用逻辑回归的损失函数，对数损失log_loss，二分类时使用</td></tr><tr><td align="left">binary:hinge</td><td align="left">使用支持向量机的损失函数，Hinge Loss，二分类时使用</td></tr><tr><td align="left">multi:softmax</td><td align="left">使用softmax损失函数，多分类时使用</td></tr></tbody></table><p>并且允许自定义损失函数（但通常我们还是使用类已经设置好的损失函数）</p><h4 id="3-3-2-求解XGB的目标函数"><a href="#3-3-2-求解XGB的目标函数" class="headerlink" title="3.3.2 求解XGB的目标函数"></a>3.3.2 求解XGB的目标函数</h4><p>由于XGB迭代的是树，不是数字组成的向量，因此无法使用梯度下降，而是将目标函数转化为更简单的，与树结构直接相关的写法，以此来建立树的结构与模型的效果（泛化能力与运行速度）之间的直接联系，因为这种联系，XGB的目标函数又被称为“结构分数”。</p><p>首先，进行第一步转换：</p><p><img src="https://note.youdao.com/yws/api/personal/file/2200B3AF1AD249FD85F2101CC7F50213?method=download&shareKey=5ebe9bb0fea9178231e97a37e0f99383" alt></p><p>其中$g_i,h_i$分别是在损失函数$l(y_i^t,\hat y_i^{(t-1)})$上对$\hat y_i^{(t-1)}$所求的一阶倒数和二阶导数。</p><p>因此，我们的目标函数可以被转化为：</p><p>$$Obj = \sum_{i=1}^m[f_t(x_i)g_i+\frac{1}{2}(f_t(x_i))^2h_i]+\Omega (f_t)$$</p><p>这个式子中，$g_i,h_i$只与传统损失函数相关，核心的部分是我们需要决定的树$f_t$</p><h4 id="3-3-3-参数化决策树-f-k-x"><a href="#3-3-3-参数化决策树-f-k-x" class="headerlink" title="3.3.3 参数化决策树$f_k(x)$"></a>3.3.3 参数化决策树$f_k(x)$</h4><p>对于回归树，通常来说每个叶子节点上的预测值是这个叶子节点上所有样本的标签的均值，但XGB作为普通回归树的改进算法，在$\hat y$上却有所不同。</p><p>对于XGB来说，每个叶子节点上都会有一个预测分数，也称叶子权重，用$f_k(x)$或$w$来表示</p><p>当有多课树的时候，集成模型的回归结果就是所有树的预测分数之和，假设这个集成模型中共有K棵决策树，则整个模型在这个样本$i$上给出的预测结果为:<br>$$\hat y_i^{(k)}=\sum_k^Kf_k(x_i)$$</p><p>我们使用$q(x_i)$表示样本$x_i$所在的叶子节点，并且使用$w_{q(x_i)}$表示这个样本落到第$t$棵树上的第$q(x_i)$个叶子节点中所获得的分数，于是有：</p><p>$$f_t(x_i)=w_q(x_i)$$</p><p>设一棵树上总共包含了$T$个叶子节点，其中每个叶子节点的索引为$j$，则这个叶子节点上的样本权重是$w_j$，依据这个，我们定义模型的复杂度$\Omega(f)$为<br>$$\Omega(f)=\gamma T+正则项(Regularization)$$</p><h4 id="3-3-4-寻找最佳树结构：求解-w-与-T"><a href="#3-3-4-寻找最佳树结构：求解-w-与-T" class="headerlink" title="3.3.4 寻找最佳树结构：求解$w$与$T$"></a>3.3.4 寻找最佳树结构：求解$w$与$T$</h4><p>我们定义了树和树的复杂度表达式：</p><p>$$f_t(x_i)=w_q(x_i), \ \Omega(f_t)=\gamma T+\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2$$</p><p>假设现在第$t$棵树的结构已经被确定为q,可以将树的结构代入我们的损失函数，来继续转化我们的目标函数。转化目标函数的目的是：建立树的结构（叶子节点的数量）与目标函数的大小之间的直接联系，以求出在第$t$次迭代中需要求解的最优树$f_t$。</p><p><img src="https://note.youdao.com/yws/api/personal/file/64A336827C294238BBE661A25CE488DF?method=download&shareKey=477b767da38b33f7f049ac795ad5f71a" alt></p><p>对于橙色框的转化<br><img src="https://note.youdao.com/yws/api/personal/file/14DEB79D037D47E69496EE06E38D9930?method=download&shareKey=2ba7a8c972206128b62f304ef25f46aa" alt></p><p>可以有：<br>$$\sum_{i=1}^m w_{q(x_i)} * g_i = w_{q(x_1)} * g_1 + w_{q(x_2)} * g_2+ w_{q(x_3)} * g_3$$<br>$$=w_1(g_1+g_2)+ w_2*g_3$$<br>$$=\sum_{j=1}^T(w_j\sum_{i\in I_j}g_i)$$</p><p>我们定义：<br>$$G_j = \sum_{i\in I_j}g_i, \ H_j = \sum_{i\in I_j}h_i$$</p><p>于是可以有：</p><p>$$Obj^{(t)}=\sum_{j=1}^T[w_jG_j+\frac{1}{2}w_j^2(H_j+\lambda)]+\gamma T$$</p><p>$$F^{*}(w_j)=w_jG_j+\frac{1}{2}w_j^2(H_j+\lambda)$$</p><p>其中每个$j$取值下都是一个以$w_j$为自变量的二次函数$F^{<em>}$，我们的目标追求是让$Obj$最小，只要单独每一个叶子$j$取值下的二次函数都最小。于是在$F^{</em>}$对$w_j$求导，让一阶导数等于0，可得：</p><p>$$\frac{\partial F^{*}(w_j)}{\partial w_j}=G_j+w_j(H_j+\lambda)$$<br>$$0=G_j+w_j(H_j+\lambda)$$<br>$$w_j = -\frac{G_j}{H_j+\lambda}$$</p><p>代入目标函数，则有：<br>$$Obj^{(t)}=\sum_{j=1}^T[-\frac{G_j}{H_j+\lambda} * G_j + \frac{1}{2}(-\frac{G_j}{H_j+\lambda})]+\gamma T$$<br>$$=\sum_{j=1}^T[-\frac{G_j^2}{H_j+\lambda}+\frac{1}{2} * \frac{G_j^2}{H_j+\lambda}]+\gamma T$$<br>$$=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{H_j+\lambda}+\gamma T$$</p><p>这样我们就建立了树的结构（叶子）和模型效果的直接联系</p><p>下面来看一个例子：</p><p><img src="https://note.youdao.com/yws/api/personal/file/9C5D143BEFCA42FC94E784306DFAA089?method=download&shareKey=5423ee0322a0c25fbdc19bfef02e51cb" alt></p><p>$$Obj = -(\frac{g_1^2}{h_1+\lambda}+\frac{g_4^2}{h_4+\lambda}+\frac{(g_2+g_3+g_5)^2}{h_2+h_3+h_5+\lambda})+3\gamma$$</p><h4 id="3-3-5-寻找最佳分枝：结构分数之差"><a href="#3-3-5-寻找最佳分枝：结构分数之差" class="headerlink" title="3.3.5 寻找最佳分枝：结构分数之差"></a>3.3.5 寻找最佳分枝：结构分数之差</h4><p>XGB使用贪婪算法，认为如果每片叶子都是最优的，则整体生成的树结构就是最优，可以避免枚举所有可能的树结构</p><p><img src="https://note.youdao.com/yws/api/personal/file/40FD6184DB4342098CFA5C45D9053E81?method=download&shareKey=6fcc1916a4df5e8182cd835a0a0a20c0" alt></p><h4 id="3-3-6-让树停止生长：重要参数gamma"><a href="#3-3-6-让树停止生长：重要参数gamma" class="headerlink" title="3.3.6 让树停止生长：重要参数gamma"></a>3.3.6 让树停止生长：重要参数gamma</h4><p>$\gamma$是对梯度提升树影响最大的参数之一，让树停止生长</p><p>对于目标函数减小量的要求是：</p><p>$$\frac{1}{2}[\frac{G^2_L}{H_L+\lambda}+\frac{G^2_R}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]&gt;\lambda$$</p><h3 id="3-4-Lightgbm"><a href="#3-4-Lightgbm" class="headerlink" title="3.4 Lightgbm"></a>3.4 Lightgbm</h3><p>传统的Boost算法需要对每一个特征扫描所有的样本点来选择最好的切分点，非常耗时。为了解决这种在大样本高纬度数据的环境下耗时问题，Lightgbm使用了两种解决办法</p><ol><li>GOSS (Gradient-based One-Side Sampling, 基于梯度的单边采样)，不是使用所有的样本点来计算梯度，而是对样本进行采样计算梯度</li><li>EFB（Exclusive Feature Bundling， 互斥特征捆绑）， 不是使用所有的特征来进行扫描获得最佳的切分点，而是将某些特征进行捆绑在一起来降低特征的维度，以减少寻找最佳切分点的耗时。 </li></ol><h4 id="3-4-1-GOSS算法"><a href="#3-4-1-GOSS算法" class="headerlink" title="3.4.1 GOSS算法"></a>3.4.1 GOSS算法</h4><p>每个样本的梯度对采样也提供了非常有用的信息，如果一个样本点的梯度小，那么该样本点的训练误差就小并且已经经过了很好的训练</p><p>输入：训练数据，迭代步数$d$，大梯度数据的采样率$a$,小梯度的数据采样率$b$，损失函数和弱学习器的类型；</p><p>输出：训练好的强学习器；</p><ol><li>根据样本点的梯度绝对值进行降序排序；</li><li>对排序后的结果选取前$a * 100%$的样本生成一个大梯度样本点的子集；</li><li>对剩下的样本$（1-a） * 100%$，随机选取$b * （1-a）* 100%$生成小梯度样本点的集合；</li><li>将大梯度样本和采样的小梯度样本合并；</li><li>将小梯度样本乘上一个权重系数$\frac{1-a}{b}$；</li><li>使用上述的采样方法训练一个新的弱学习器；</li><li>不断重复1-6步骤知道达到规定的迭代次数或者收敛</li></ol><p>通过GOSS算法，可以在不改变数据分布的前提下不损失学习器精度的同时大大减少模型的学习速率</p><h4 id="3-4-2-EFB算法"><a href="#3-4-2-EFB算法" class="headerlink" title="3.4.2 EFB算法"></a>3.4.2 EFB算法</h4><p>Lightgbm实现中不仅进行了数据采样，也进行了特征抽样。但是该特征抽样与一般不同，将互斥特征绑定在一起从而减少特征维度。</p><p>主要思想是，实际中高纬度数据往往都是稀疏数据，在稀疏特征空间中许多特征都是互斥的，可以基于直方图（histograms）的方法将互斥的特征捆绑形成一个特征，从而减少特征维度。</p><p>并且允许小部分的冲突，使得模型的性能被影响$O([(1-\gamma)n]^{-2/3})$,这里的$\gamma$是每个绑定的最大冲突率。</p><p>输入：特征F，最大冲突K，图G；<br>输出： 特征捆绑集合bundles;</p><ol><li>构造一个边带有权重的图，其权值对应于特征之间的总冲突；</li><li>通过特征在图中的度来降序排序特征</li><li>检查有序列表中的每个特征，并将其分配给具有小冲突的现有bunding或创建新bunding</li></ol><h4 id="3-4-3-合并互斥特征"><a href="#3-4-3-合并互斥特征" class="headerlink" title="3.4.3 合并互斥特征"></a>3.4.3 合并互斥特征</h4><p>Lightgbm关于互斥特征的合并用到了直方图（Histogram）算法。直方图算法的基本思想是先把连续的特征值离散化成k个整数，同时构造一个宽度为k的直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。</p><p>由于基于直方图的算法存储的是离散的bins而不是连续的特征值，我们可以通过让互斥特征驻留在不同的bins中来构造feature bundle。这可以通过增加特征原始值的偏移量来实现。比如，假设我们有两个特征，特征A的取值范围是[0,10)，而特征B的取值范围是[0,20)，我们可以给特征B增加偏移量10，使得特征B的取值范围为[10, 30)，最后合并特征A和B，形成新的特征，取值范围为[0,30)来取代特征A和特征B。</p><p>当然，Histogram算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；差一点的切分点也有正则化的效果，可以有效地防止过拟合；即使单棵树的训练误差比精确分割的算法稍大，但在Gradient Boosting的框架下没有太大的影响。</p><p><img src="https://note.youdao.com/yws/api/personal/file/BB4E003C937C441D80F12A44CEE7B01D?method=download&shareKey=6214970cf9c295e487ce3ed91422ef38" alt></p><h3 id="3-5-Boosting算法优缺点对比"><a href="#3-5-Boosting算法优缺点对比" class="headerlink" title="3.5 Boosting算法优缺点对比"></a>3.5 Boosting算法优缺点对比</h3><h4 id="3-5-1-XGBoost-vs-GBDT"><a href="#3-5-1-XGBoost-vs-GBDT" class="headerlink" title="3.5.1 XGBoost vs GBDT"></a>3.5.1 XGBoost vs GBDT</h4><p>1）GBDT以传统CART作为基分类器，而XGBoost支持线性分类器，相当于引入L1和L2正则化项的逻辑回归（分类问题）和线性回归（回归问题）；</p><p>2）GBDT在优化时只用到一阶导数，XGBoost对代价函数做了二阶Talor展开，引入了一阶导数和二阶导数。XGBoost支持自定义的损失函数，只要是能满足二阶连续可导的函数均可以作为损失函数；</p><p>3）XGBoost在损失函数中引入正则化项，用于控制模型的复杂度。正则化项包含全部叶子节点的个数，每个叶子节点输出的score的L2模的平方和。从Bias-variance tradeoff角度考虑，正则项降低了模型的方差，防止模型过拟合，这也是xgboost优于传统GBDT的一个特性。</p><p>4）当样本存在缺失值是，xgBoosting能自动学习分裂方向，即XGBoost对样本缺失值不敏感；</p><p>5）XGBoost借鉴RF的做法，支持列抽样，这样不仅能防止过拟合，还能降低计算，这也是xgboost异于传统gbdt的一个特性。</p><p>6）XGBoost在每次迭代之后，会将叶子节点的权重乘上一个学习率（相当于XGBoost中的eta，论文中的Shrinkage），主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点；</p><p>7）XGBoost工具支持并行，但并行不是tree粒度的并行，XGBoost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值），XGBoost的并行是在特征粒度上的。XGBoost在训练之前，预先对数据进行了排序，然后保存为(block)结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个块结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行；</p><p>8）可并行的近似直方图算法，树结点在进行分裂时，需要计算每个节点的增益，若数据量较大，对所有节点的特征进行排序，遍历的得到最优分割点，这种贪心法异常耗时，这时引进近似直方图算法，用于生成高效的分割点，即用分裂后的某种值减去分裂前的某种值，获得增益，为了限制树的增长，引入阈值，当增益大于阈值时，进行分裂；</p><h4 id="3-5-2-XGboost-vs-LightGBM"><a href="#3-5-2-XGboost-vs-LightGBM" class="headerlink" title="3.5.2 XGboost vs LightGBM"></a>3.5.2 XGboost vs LightGBM</h4><p>1）XGBoost采用预排序，在迭代之前，对结点的特征做预排序，遍历选择最优分割点，数据量大时，贪心法耗时，LightGBM方法采用histogram算法，占用的内存低，数据分割的复杂度更低，但是不能找到最精确的数据分割点；</p><p>2）XGBoost采用level-wise生成决策树策略，同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合，但很多叶子节点的分裂增益较低，没必要进行更进一步的分裂，这就带来了不必要的开销；LightGBM采用leaf-wise生长策略，每次从当前叶子中选择增益最大的叶子进行分裂，如此循环，但会生长出更深的决策树，产生过拟合，因此 LightGBM 在leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合）。另一个比较巧妙的优化是 histogram 做差加速。一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。</p><h2 id="4-结合策略"><a href="#4-结合策略" class="headerlink" title="4 结合策略"></a>4 结合策略</h2><p>不同的结合策略也会影响集成模型性能，主要分为平均法、投票法和学习法，我们这里重点介绍学习法Stacking</p><h3 id="4-1-平均法"><a href="#4-1-平均法" class="headerlink" title="4.1 平均法"></a>4.1 平均法</h3><ul><li>简单平均法</li><li>加权平均法</li></ul><h3 id="4-2-投票法"><a href="#4-2-投票法" class="headerlink" title="4.2 投票法"></a>4.2 投票法</h3><ul><li>绝对多数投票法</li><li>相对多数投票法</li><li>加权投票法</li></ul><h3 id="4-3-学习法"><a href="#4-3-学习法" class="headerlink" title="4.3 学习法"></a>4.3 学习法</h3><p>当训练数据很多时，一种更为强大的结合策略是使用“学习法”，即通过另一个学习器来进行结合.Stacking是学习法的经典代表，这里我们吧个体学习器称为初级学习器，用于结合的学习器称为刺激学习器或元学习器。</p><p><img src="https://note.youdao.com/yws/api/personal/file/119ABC7D390F428F8A036B925FD7C6E8?method=download&shareKey=85e6961c6b845acd5fab61326ede0493" alt></p><p>次级学习器的输入属性表示和次级学习算法对Stacking集成的泛化性能有很大影响。研究表明，将初级学习器的输出类概率作为次级学习器的输入属性，用多响应线性回归（Multi-response Linear Regression，MLR）作为次级学算法效果较好。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1 概述&quot;&gt;&lt;/a&gt;1 概述&lt;/h2&gt;&lt;p&gt;多个模型集成称为的模型叫作集成评估器（ensemble estimator），组成集成评估器的每个模型都叫作基评估器(base estimator)。通常来说，有两类集成算法：装袋法（Bagging），提升法(Boosting)。要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，并且要有“多样性”&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://note.youdao.com/yws/api/personal/file/ADF733049258402C8AD900FD965CB288?method=download&amp;shareKey=18ded5ff7e25a56d46886670b21ef009&quot; alt&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;装袋法：多个相互独立的评估器，对其预测进行平均或多数表决原则来决定集成评估器的结果（随机森林）&lt;/li&gt;
&lt;li&gt;提升法：基评估器是相关的，是按顺序一一构建的。其核心思想是结合弱评估器的力量一次次对难以评估的样本进行预测，从而构成一个强评估器（Adaboost，梯度提升树）&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（四）逻辑回归</title>
    <link href="https://liangggggg.github.io/2020/07/24/LogisticRegression/"/>
    <id>https://liangggggg.github.io/2020/07/24/LogisticRegression/</id>
    <published>2020-07-24T00:38:18.000Z</published>
    <updated>2020-07-25T06:59:42.597Z</updated>
    
    <content type="html"><![CDATA[<p>逻辑回归，是一种名为“回归”的线性分类器，其本质是由线性回归变化而来，一种广泛使用于分类问题的广义回归算法。</p><h2 id="1-逻辑回归原理"><a href="#1-逻辑回归原理" class="headerlink" title="1 逻辑回归原理"></a>1 逻辑回归原理</h2><p>理解逻辑回归，先要理解线性回归，线性回归的方程为：<br>$$z=\theta_0+\theta_1x_1+\theta_2x_2+\dots+\theta_nx_n$$</p><p>其中，$\theta$被统称为模型的参数，其中$\theta_0$被称为截距，$\theta_1\sim\theta_n$被称为系数，用矩阵来表示这个方程，其中$x,\theta$都可以被看作是一个列矩阵，则有：</p><a id="more"></a><p>$$z=\begin{bmatrix}\theta_0,\theta_1,\theta_2,\dots,\theta_n \end{bmatrix}*<br>\begin{bmatrix}x_0\\<br>x_1\\<br>x_2\\<br>\dots\\<br>\theta_n<br>\end{bmatrix}$$</p><p>通过函数$z$，可以使用输入的特征矩阵$X$来输出一组连续型的标签纸$y_pred$，以完成预测连续型变量的任务。但是如果标签是离散变量，则需要通过引入联系函数，将线性回归的方程$z$变成$g(z)$，并且令$g(z)$的值分布在$(0,1)$之间，对于逻辑回归来说，这个联系函数式Sigmoid函数：<br>$$g(z)=\frac{1}{1+\exp^{-z}}$$<br><img src="https://note.youdao.com/yws/api/personal/file/CF992254DF284E19AAF3D5065557A539?method=download&shareKey=55ac36a4ac1688679e29b3df6f2c94c4" alt></p><p>线性回归中$z=\theta^Tx$，将$z$代入，可以得到二元逻辑回归模型的一般形式：<br>$$g(z)=y(x)=\frac{1}{1+\exp^{-\theta^Tx}}$$</p><p>$y(x)$取值都在$[0,1]$之间，$y(x)$被视为样本$x$作为正例的可能性，则$1-y(x)$是其反例的可能性，两者的比值：<br>$$\frac{y}{1-y}$$</p><p>称为“几率”（odds），反映了$x$作为正例的相对可能性，对几率取对数则得到“对数几率”(log odds,亦称logit): $ln\frac{y}{1-y}$</p><p>在此基础上取对数，可以得到：<br>$$ln\frac{y(x)}{1-y(x)}=ln(\frac{\frac{1}{1+e^{-\theta^Tx}}}{1-\frac{1}{1+\exp^{-\theta^Tx}}})$$<br>$$=ln(\frac{\frac{1}{1+\exp^{-\theta^Tx}}}{\frac{\exp^{-\theta^Tx}}{1+\exp^{-\theta^Tx}}})$$<br>$$=ln(\exp^{\theta^Tx})$$<br>$$=\theta^Tx$$</p><p>我们发现，$y(x)$的形式几率取对数的本质其实就是线性回归$z$，<strong>注意，虽然我们熟悉的逻辑回归通常被用于处理二分类问题，但逻辑回归也可以做多分类</strong></p><h2 id="2-二元逻辑回归的损失函数"><a href="#2-二元逻辑回归的损失函数" class="headerlink" title="2 二元逻辑回归的损失函数"></a>2 二元逻辑回归的损失函数</h2><p>逻辑回归的损失函数式由极大似然估计推导出来的，具体结果可以写作:<br>$$J(\theta)=-\sum_{i=1}^m(y_i*log(y_\theta(x_i))+(1-y_i) * log(1-y_\theta(x_i)))$$</p><p>其中，$\theta$表示求解出来的一组参数，$m$是样本的个数，$y_i$是样本$i$上真实的标签，$y_\theta(x_i)$是样本$i$上，基于参数$\theta$计算出来的逻辑回归返回值，$x_i$是样本i各个特征的取值。</p><h3 id="2-1-损失函数极大似然推导"><a href="#2-1-损失函数极大似然推导" class="headerlink" title="2.1 损失函数极大似然推导"></a>2.1 损失函数极大似然推导</h3><p>二元逻辑回归的标签服从伯努利分布（0-1分布），因此我们可以将一个特征向量$x$,参数为$\theta$的模型中的一个样本$i$的预测情况表现为如下形式：</p><ul><li><p>样本$i$在由特征向量$x_i$和参数$\theta$组成的预测函数中，样本标签被预测为1的概率为：<br>$$P_1 = P(\hat y_i = 1|x_i,\theta)=y_\theta(x_i)$$</p></li><li><p>样本$i$在由特征向量$x_i$和参数$\theta$组成的预测函数中，样本标签被预测为0的概率为：<br>$$P_1 = P(\hat y_i = 0|x_i,\theta)=1-y_\theta(x_i)$$</p></li></ul><p>当$P_1$为1时，预测为1，当$P_0$为1时，代表预测为0</p><p>将两种取值的概率整合，可以得到如下等式：</p><p>$$P(\hat y_i|x_i,\theta)=P_i^{y_i}*P_0^{1-y_i}$$</p><p>$P(\hat y_i|x_i,\theta)$的本质是样本$i$由特征向量$x_i$和参数$\theta$组成的预测函数中，预测出所有可能的$\hat y_i$的概率，因此1是它的最大值，因此我们是在追求$P(\hat y_i|x_i,\theta)$的最大值。</p><p>$P(\hat y_i|x_i,\theta)$是对单个样本$i$而言的函数，对一个训练集的$m$个样本来说，所有样本在特征矩阵$X$和参数$\theta$组成的预测函数中，预测出所有可能的$\hat y$的概率$P$为：</p><p>$$P = \prod_{i=1}^m P(\hat y_i|x_i,\theta)$$<br>$$= \prod_{i=1}^m (P_i^{y_i})$$<br>$$= \prod_{i=1}^m (y_0(x_i)^{y_i}*(1-y_0(x_i))^{1-y_i})$$</p><p>对该概率$P$取对数，再有$log(A*B)=logA+logB$和$logA^B=BlogA$可得到：</p><p>$$logP= log\prod_{i=1}^m (y_0(x_i)^{y_i}*(1-y_0(x_i))^{1-y_i})$$</p><p>$$=\sum_{i=1}^m log(y_0(x_i)^{y_i}*(1-y_0(x_i))^{1-y_i})$$</p><p>$$=\sum_{i=1}^m(logy_0(x_i)^{y_i}+log(1-y_0(x_i))^{1-y_i})$$</p><p>$$=\sum_{i=1}^m(y_i * log(y_0(x_i))+(1-y_i) * log(1-y_0(x_i)))$$</p><p>这就是交叉熵函数，为了便于定义“损失”含义，把极大值问题转换为极小值问题，因此我们对$logP$取负，并且让参数$\theta$作为函数的自变量，就得到了我们的损失函数$J(\theta)$</p><p>$$J(\theta)=-\sum_{i=1}^m(y_i * log(y_\theta(x_i))+(1-y_i) * log(1-y_0(x_i)))$$</p><h3 id="2-2-正则化"><a href="#2-2-正则化" class="headerlink" title="2.2 正则化"></a>2.2 正则化</h3><p>正则化是用来防止模型过拟合的过程，常用的有$L_1$正则化和$L_2$正则化，如下所示：</p><p>$$ J(\theta)_{L_1} = C * J(\theta) +\sum_j^n |\theta_j|\ (j&gt;=1)$$</p><p>$$J(\theta)_{L_2}=C * J(\theta)+\sqrt{\sum_j^n(\theta_j)^2}\ (j&gt;=1)$$</p><table><thead><tr><th align="left">参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">penalty</td><td align="left">可以输入”l1”或”l2”来指定使用哪一种正则化方式，不填写默认”l2”。注意，若选择”l1”正则化，参数solver仅能够使用求解方式”liblinear”和”saga“，若使用“l2”正则化，参数solver中所有的求解方式都可以使用。</td></tr><tr><td align="left">C</td><td align="left">C正则化强度的倒数，必须是一个大于0的浮点数，不填写默认1.0，即默认正则项与损失函数的比值是1：1。C越小，损失函数会越小，模型对损失函数的惩罚越重，正则化的效力越强，参数会逐渐被压缩得越来越小。</td></tr></tbody></table><h3 id="2-3-梯度下降"><a href="#2-3-梯度下降" class="headerlink" title="2.3 梯度下降"></a>2.3 梯度下降</h3><p>现在有一个带两个特征并且没有截距的逻辑回归$y(x_1,x_2)$，两个特征所对应的参数分别为$[\theta_1,\theta_2]$。下面这个平面就是我们损失函数$J(\theta_1,\theta_2)$在$\theta_1,\theta_2,j$为坐标轴的三维立体坐标系上的图像，我们寻求损失函数的最小值，也就是求图像的最低点。</p><p><img src="https://note.youdao.com/yws/api/personal/file/EA89311DC35C43BCB583EE77B28C5533?method=download&shareKey=40697b4035e3fb639c03e8a3a6ee3593" alt></p><p>在逻辑回归中，我们的损失函数为：</p><p>$$J(\theta)=-\sum_{i=1}^m(y_i * log(y_\theta(x_i))+(1-y_i) * log(1-y_0(x_i)))$$</p><p>对这个函数的自变量$\theta$求偏导，可以得到梯度向量在第$j$组$\theta$的坐标点上的表示形式：</p><p>$$\frac{\partial}{\partial \theta_j}J(\theta)=d_j = \sum_{i=1}^m(y_\theta(x_i)-y_i)x_{ij}$$</p><p>在这个公式下，只要给定一组$\theta$的取值$\theta_j$再代入特征矩阵$x$，就可以求得这一组$\theta$取值下的预测结果$y_\theta(x_i)$，结合真实标签$y$，就可以获得这一组$\theta_j$取值下的梯度向量，其大小表示为$d_j$</p><p>我们的目的是在可能的$\theta$上进行遍历，一次次计算梯度向量，并在梯度向量的反方向上让损失函数$J$下降至最小值，在这个过程中，我们的$\theta$和梯度向量的大小$d$都会不断改变，遍历$\theta$的过程可以描述为：</p><p>$$\theta_{j+1}=\theta_j-\alpha * d_j$$</p><p>$$=\theta_j-\alpha * \sum_{i=1}^m(y_\theta(x_i)-y_i)x_{ij}$$</p><p>其中$\theta_{j+1}$是第$j+1$次迭代后的参数向量，$\theta_j$是第$j$此迭代的参数向量，$\alpha$被称为步长，控制着每一步$\theta$的变化</p><p>下面是一张二维平面的求导三角形图，抛物线就是我们的损失函数$J(\theta)$，$A(\theta_a, J(\theta_a))$就是小球最初在的位置，$B(\theta_b, J(\theta_b))$就是一次滚动后小球移动到的位置，A到B的方向就是梯度向量的反方向，指向损失函数在A点下降最快的方向，而梯度向量的大小是点A在图像上对$\theta$求导后的结果，也是点A切线方向的斜率，橙色角$tan$结果，记为$d$</p><p><img src="https://note.youdao.com/yws/api/personal/file/C5409617143F42ECA36A291937F5E6CF?method=download&shareKey=86b3dbbcb321f5712bf5dccd8497561b" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;逻辑回归，是一种名为“回归”的线性分类器，其本质是由线性回归变化而来，一种广泛使用于分类问题的广义回归算法。&lt;/p&gt;
&lt;h2 id=&quot;1-逻辑回归原理&quot;&gt;&lt;a href=&quot;#1-逻辑回归原理&quot; class=&quot;headerlink&quot; title=&quot;1 逻辑回归原理&quot;&gt;&lt;/a&gt;1 逻辑回归原理&lt;/h2&gt;&lt;p&gt;理解逻辑回归，先要理解线性回归，线性回归的方程为：&lt;br&gt;$$z=\theta_0+\theta_1x_1+\theta_2x_2+\dots+\theta_nx_n$$&lt;/p&gt;
&lt;p&gt;其中，$\theta$被统称为模型的参数，其中$\theta_0$被称为截距，$\theta_1\sim\theta_n$被称为系数，用矩阵来表示这个方程，其中$x,\theta$都可以被看作是一个列矩阵，则有：&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>行测笔记（三）：资料分析与数量关系</title>
    <link href="https://liangggggg.github.io/2020/07/23/xingce3/"/>
    <id>https://liangggggg.github.io/2020/07/23/xingce3/</id>
    <published>2020-07-23T07:57:25.000Z</published>
    <updated>2020-08-19T11:48:51.894Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-资料分析"><a href="#1-资料分析" class="headerlink" title="1 资料分析"></a>1 资料分析</h1><h2 id="一、速算技巧"><a href="#一、速算技巧" class="headerlink" title="一、速算技巧"></a>一、速算技巧</h2><p>（1）截位直除</p><p>截位，看下一位，四舍五入</p><ul><li>一步除法，建议只截分母($\frac{36225}{81245}$)</li><li>多步除法，截分子，分母（$\frac{1421}{8041}*\frac{1521}{9023}$）<a id="more"></a></li></ul><p>一般情况下，截两位计算快，截三位计算准</p><p>看最接近选项差距</p><p>差距大，截两位</p><ol><li>首位都不同</li><li>首位有相同，第二位差值&gt;首位</li></ol><p>差距小，截三位</p><ol><li>首位有相同，第二位差值=首位</li><li>首位有相同，第二位差值&lt;首位</li></ol><p>若选项之间存在约10、100倍的关系时</p><ol><li>截两位</li><li>保留量级</li></ol><p>（2）分数比较</p><p>一大一小（$\frac{25}{8}$,$\frac{36}{5}$）分子大，分数大</p><p>同达同小（\frac{27}{8}，$\frac{9}{4}$）</p><p>纵向用直除，横向看倍数（谁大谁留下，小的看成1）</p><p>直除看首位</p><h2 id="二、阅读材料"><a href="#二、阅读材料" class="headerlink" title="二、阅读材料"></a>二、阅读材料</h2><p>（1）纯文字材料</p><p>特点：数据多，相近词多</p><p>方法：结构阅读</p><ol><li>总分结构</li><li>10秒内每段画出1-2个与众不同的关键词</li></ol><p>（2）图表材料</p><p>特点：类型多，有陷阱</p><p>方法：</p><ol><li>看表头三要素（时间、主体、单位）</li><li>有注释一定要看注释</li></ol><p>（3）综合材料</p><p>方法：</p><ol><li>个看个的</li><li>找文字与图表之间的区别</li></ol><h2 id="三、基期与现期"><a href="#三、基期与现期" class="headerlink" title="三、基期与现期"></a>三、基期与现期</h2><p>时间靠前的为基期，时间靠后的为现期</p><p>（1）$基期=现期-增长量$</p><p>精确加减计算，用尾数法，末一位相同，看末两位</p><p>（2）$基期=\frac{基期}{1+r}$</p><p>（3）同比与环比</p><p>同比看头，环比看尾</p><p>2020年（头）5月（尾），同比与2019年5月相比，环比2020年4月相比</p><p>（4）化除为乘</p><p>应用环境：求基期，差距小$|r|&lt;=5%$</p><p>$$\frac{A}{1+r}\approx A*(1-r)$$</p><p>$$\frac{A}{1-r}\approx A*(1+r)$$</p><p>操作：变号-去百分号-估算乘法</p><p>（5）基期差值</p><p>$$\frac{A}{1+a}-\frac{B}{1+b}分母同号，考计算或分析$$</p><p>$$\frac{A}{1+a}-\frac{B}{1-b}分母异号，考分析$$</p><ol><li>先计算现期坑，排除</li><li>再看大小关系，选择</li></ol><h2 id="四、一般增长率"><a href="#四、一般增长率" class="headerlink" title="四、一般增长率"></a>四、一般增长率</h2><p>（1）基本术语</p><ul><li>增长率与倍数</li></ul><p>倍数：指两数的直接比值</p><p>增长率：比基数多出的比率</p><p>两者联系：$是几倍=增长率+1$</p><ul><li>番数</li></ul><p>于番数，化倍数，翻$N$番，变为原来的$2^N$倍</p><p>（2）计算</p><ol><li>给百分点型，高减低加</li><li>给具体量型，套公式</li></ol><p>已知：现期、基期</p><ol><li>增长率：$r=\frac{增长量}{基期}$</li><li>多个年份增长率$&gt;10%$：$现期&gt;1.1基期$</li></ol><p>（3）增长率的比较</p><ol><li>按照公式</li><li>看现期和基期倍数关系是否明显</li></ol><p>当现期与基期的比值小于2，则用公式</p><p>如果现期与基期的比值大于2，则直接比现期与基期</p><h2 id="五、增长量"><a href="#五、增长量" class="headerlink" title="五、增长量"></a>五、增长量</h2><p>识别：增长+单位（绝对量）</p><p>（1）增长量的计算</p><ol><li>已知：现期、基期</li><li>年均增长量</li><li>已知：现期、增长率</li></ol><p>公式：$增长量=\frac{现期}{1+r}*r$</p><p>第一步：$|r|=1/N$</p><p>第二步：$增长量=现期/（N+1）$，$减少量=现期/（N-1）$</p><p>百分数转换常用分数：</p><ol><li>常用分数”1-5“</li><li>记住“7-12“，加和（整数部分+分母=20）</li><li>记住（16，6）和（14，7）互换的两对</li><li>（17，18，19）记住5.963</li><li>记住6.7%=$\frac{1}{15}$</li></ol><p>（2）增长量的比较</p><p>大大则大，一大一小白分化</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-资料分析&quot;&gt;&lt;a href=&quot;#1-资料分析&quot; class=&quot;headerlink&quot; title=&quot;1 资料分析&quot;&gt;&lt;/a&gt;1 资料分析&lt;/h1&gt;&lt;h2 id=&quot;一、速算技巧&quot;&gt;&lt;a href=&quot;#一、速算技巧&quot; class=&quot;headerlink&quot; title=&quot;一、速算技巧&quot;&gt;&lt;/a&gt;一、速算技巧&lt;/h2&gt;&lt;p&gt;（1）截位直除&lt;/p&gt;
&lt;p&gt;截位，看下一位，四舍五入&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一步除法，建议只截分母($\frac{36225}{81245}$)&lt;/li&gt;
&lt;li&gt;多步除法，截分子，分母（$\frac{1421}{8041}*\frac{1521}{9023}$）&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="行测笔试" scheme="https://liangggggg.github.io/categories/%E8%A1%8C%E6%B5%8B%E7%AC%94%E8%AF%95/"/>
    
    
      <category term="行测笔试" scheme="https://liangggggg.github.io/tags/%E8%A1%8C%E6%B5%8B%E7%AC%94%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>行测笔记（二）：言语理解与表达</title>
    <link href="https://liangggggg.github.io/2020/07/22/xingce2/"/>
    <id>https://liangggggg.github.io/2020/07/22/xingce2/</id>
    <published>2020-07-22T12:45:12.000Z</published>
    <updated>2020-08-19T11:43:09.267Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-片段阅读"><a href="#1-片段阅读" class="headerlink" title="1 片段阅读"></a>1 片段阅读</h1><p>解题顺序：提问————文段————选项</p><p>对比择优，好的答案是对比出来的</p><h2 id="一、中心理解题"><a href="#一、中心理解题" class="headerlink" title="一、中心理解题"></a>一、中心理解题</h2><h3 id="（1）重点词之关联词"><a href="#（1）重点词之关联词" class="headerlink" title="（1）重点词之关联词"></a>（1）重点词之关联词</h3><a id="more"></a><ol><li>转折关系，转折之后是重点</li></ol><p>错误选项特征：</p><ul><li>转折前的内容</li><li>例子、原因、背景…</li><li>无中生有</li><li>绝对表述</li><li>与文意相悖</li></ul><p>略读句子特征：</p><ul><li>例子</li><li>原因</li><li>背景</li></ul><ol start="2"><li><p>因果关系，结论是重点</p></li><li><p>必要条件关系</p></li></ol><p>典型格式：只有…才…</p><p>必要条件是重点（“只有”和“才”之间的部分）</p><ol start="4"><li>并列关系</li></ol><p>理论要点：概括全面完整</p><p>文段特征：</p><ul><li>包含并列关联词</li><li>句式相近或相同</li><li>无明显其他关联词</li></ul><p>选项特征：</p><ul><li>两方面情况：和、及、与、同</li><li>更多情况：许多、一些、不同、各种、一系列</li></ul><h3 id="（2）行文脉络"><a href="#（2）行文脉络" class="headerlink" title="（2）行文脉络"></a>（2）行文脉络</h3><p>理论要点：把握中心句及分述句的特点</p><p>中心句特征：观点（结论、评价、对策）</p><ol><li>总————分（观点+解释说明）</li><li>分————总</li><li>总————分————总</li><li>分————总————分</li><li>分————分</li></ol><h2 id="二、细节判断"><a href="#二、细节判断" class="headerlink" title="二、细节判断"></a>二、细节判断</h2><h3 id="（1）典型细节题"><a href="#（1）典型细节题" class="headerlink" title="（1）典型细节题"></a>（1）典型细节题</h3><p>错误选项类型：</p><ol><li>无中生有</li><li>偷换概念</li><li>偷换时态</li><li>偷换逻辑</li><li>因果偷换</li><li>并列偷换</li></ol><p>快速解题技巧：</p><ol><li><p>对比项</p></li><li><p>相对绝对项</p></li><li><p>表述与实际不符项</p></li></ol><h3 id="（2）细节主旨化"><a href="#（2）细节主旨化" class="headerlink" title="（2）细节主旨化"></a>（2）细节主旨化</h3><p>理论要点：优选契合主旨的选项</p><h1 id="2-语句表达"><a href="#2-语句表达" class="headerlink" title="2 语句表达"></a>2 语句表达</h1><h2 id="一、语句排序题"><a href="#一、语句排序题" class="headerlink" title="一、语句排序题"></a>一、语句排序题</h2><h3 id="（1）根据选项提示，对比后确定首句（一定要对比）"><a href="#（1）根据选项提示，对比后确定首句（一定要对比）" class="headerlink" title="（1）根据选项提示，对比后确定首句（一定要对比）"></a>（1）根据选项提示，对比后确定首句（一定要对比）</h3><ol><li>下定义 </li><li>背景引入</li><li>非首句特征<ul><li>关联词后半部分</li><li>指代词（一句话单独出现指代词，但是并未出现指代对象，则该句不能作首句）</li></ul></li></ol><h3 id="（2）确定捆绑集团（紧紧绑在一起，中间不允许有“第三者”介入）-确定顺序-确定尾句"><a href="#（2）确定捆绑集团（紧紧绑在一起，中间不允许有“第三者”介入）-确定顺序-确定尾句" class="headerlink" title="（2）确定捆绑集团（紧紧绑在一起，中间不允许有“第三者”介入）/确定顺序/确定尾句"></a>（2）确定捆绑集团（紧紧绑在一起，中间不允许有“第三者”介入）/确定顺序/确定尾句</h3><h4 id="确定捆绑集团"><a href="#确定捆绑集团" class="headerlink" title="确定捆绑集团"></a>确定捆绑集团</h4><ol><li>指代词捆绑（这、那、他、该、其）</li><li>关联词<ul><li>配套出现（不但…而且…）</li><li>单独一个（但、同时 分析句子意思）</li></ul></li></ol><h4 id="确定顺序"><a href="#确定顺序" class="headerlink" title="确定顺序"></a>确定顺序</h4><ol><li>时间顺序</li><li>逻辑顺序</li></ol><h4 id="确定尾句"><a href="#确定尾句" class="headerlink" title="确定尾句"></a>确定尾句</h4><p>结论、对策</p><h3 id="（3）验证（只验证你基本锁定的答案，而非全部验证）"><a href="#（3）验证（只验证你基本锁定的答案，而非全部验证）" class="headerlink" title="（3）验证（只验证你基本锁定的答案，而非全部验证）"></a>（3）验证（只验证你基本锁定的答案，而非全部验证）</h3><h2 id="二、语句填空题"><a href="#二、语句填空题" class="headerlink" title="二、语句填空题"></a>二、语句填空题</h2><h3 id="（1）横线在结尾"><a href="#（1）横线在结尾" class="headerlink" title="（1）横线在结尾"></a>（1）横线在结尾</h3><ol><li>总结前文</li><li>提出对策</li></ol><h3 id="（2）横线在开头"><a href="#（2）横线在开头" class="headerlink" title="（2）横线在开头"></a>（2）横线在开头</h3><p>需要概括文段的中心内容</p><h3 id="（3）横线在中间"><a href="#（3）横线在中间" class="headerlink" title="（3）横线在中间"></a>（3）横线在中间</h3><ol><li>注意与上下文联系</li><li>把握好主题词，保证文段话题一致</li></ol><h2 id="三、接语选择题"><a href="#三、接语选择题" class="headerlink" title="三、接语选择题"></a>三、接语选择题</h2><p>重点关注文段最后一句话</p><h1 id="3-逻辑填空"><a href="#3-逻辑填空" class="headerlink" title="3 逻辑填空"></a>3 逻辑填空</h1><h2 id="一、词的辨析"><a href="#一、词的辨析" class="headerlink" title="一、词的辨析"></a>一、词的辨析</h2><h3 id="（1）词义侧重"><a href="#（1）词义侧重" class="headerlink" title="（1）词义侧重"></a>（1）词义侧重</h3><ol><li>用不一样的字组词</li><li>整词进行固定搭配</li></ol><h3 id="（2）固定搭配"><a href="#（2）固定搭配" class="headerlink" title="（2）固定搭配"></a>（2）固定搭配</h3><p>找准搭配对象（常用词、热点词）</p><p>横线所填词搭配由“和、及、与”引导的并列结构，所填词语需与并列结构搭配恰当</p><h3 id="（3）程度轻重"><a href="#（3）程度轻重" class="headerlink" title="（3）程度轻重"></a>（3）程度轻重</h3><p>所填词语的程度与文段意思的轻重保持一致</p><h3 id="（4）感情色彩"><a href="#（4）感情色彩" class="headerlink" title="（4）感情色彩"></a>（4）感情色彩</h3><p>所填词语的感情色彩和文段的感情色彩保持一致</p><h2 id="二、语境分析"><a href="#二、语境分析" class="headerlink" title="二、语境分析"></a>二、语境分析</h2><p>###（1）关联关系</p><ol><li>转折</li><li>递进</li><li>并列</li></ol><h3 id="（2）对应关系"><a href="#（2）对应关系" class="headerlink" title="（2）对应关系"></a>（2）对应关系</h3><ol><li>解释类、重点语句<ul><li>指代词</li><li>主题词</li><li>形象表达</li><li>完整语句</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-片段阅读&quot;&gt;&lt;a href=&quot;#1-片段阅读&quot; class=&quot;headerlink&quot; title=&quot;1 片段阅读&quot;&gt;&lt;/a&gt;1 片段阅读&lt;/h1&gt;&lt;p&gt;解题顺序：提问————文段————选项&lt;/p&gt;
&lt;p&gt;对比择优，好的答案是对比出来的&lt;/p&gt;
&lt;h2 id=&quot;一、中心理解题&quot;&gt;&lt;a href=&quot;#一、中心理解题&quot; class=&quot;headerlink&quot; title=&quot;一、中心理解题&quot;&gt;&lt;/a&gt;一、中心理解题&lt;/h2&gt;&lt;h3 id=&quot;（1）重点词之关联词&quot;&gt;&lt;a href=&quot;#（1）重点词之关联词&quot; class=&quot;headerlink&quot; title=&quot;（1）重点词之关联词&quot;&gt;&lt;/a&gt;（1）重点词之关联词&lt;/h3&gt;
    
    </summary>
    
    
      <category term="行测笔试" scheme="https://liangggggg.github.io/categories/%E8%A1%8C%E6%B5%8B%E7%AC%94%E8%AF%95/"/>
    
    
      <category term="行测笔试" scheme="https://liangggggg.github.io/tags/%E8%A1%8C%E6%B5%8B%E7%AC%94%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（三）线性回归</title>
    <link href="https://liangggggg.github.io/2020/07/22/LinearRegression/"/>
    <id>https://liangggggg.github.io/2020/07/22/LinearRegression/</id>
    <published>2020-07-22T01:53:28.000Z</published>
    <updated>2020-07-23T03:50:00.106Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-多元线性回归LinearRegression"><a href="#1-多元线性回归LinearRegression" class="headerlink" title="1 多元线性回归LinearRegression"></a>1 多元线性回归LinearRegression</h1><h2 id="1-1-多元线性回归的基本原理"><a href="#1-1-多元线性回归的基本原理" class="headerlink" title="1.1 多元线性回归的基本原理"></a>1.1 多元线性回归的基本原理</h2><p>对于一个$n$个特征的样本$i$而言，回归方程为：<br>$$\hat y_i = w_0 +w_1x_{i1}+w_2x_{i2}+\dots+w_nx_{in}$$</p><p>$w_0$被称为截距，$w_1 \sim w_n$被称为回归系数，$w_{i1} \sim x_{in}$是样本$i$上的不同特征，如果考虑我们有m个样本，则回归可以被写作：<br>$$\hat y = w_0 +w_1x_{1}+w_2x_{2}+\dots+w_nx_{n}$$</p><a id="more"></a><p>其中$y$是包含了m个全部样本回归的列向量，$w$可以被看作是结构为$(n+1,1)$的列矩阵，$X$是一个结构为$(m,n+1)$的特征矩阵，则有：</p><p>$$\begin{bmatrix}<br>\hat y_1 \\<br>\hat y_2\\<br>\hat y_3\\<br>\dots\\<br>\hat y_m\\<br>\end{bmatrix}=\begin{bmatrix}<br>1&amp; x_{11} &amp; x_{12} &amp; x_{13} &amp; \dots &amp; x_{1n} \\<br>1&amp; x_{21} &amp; x_{22} &amp; x_{23} &amp; \dots &amp; x_{2n}\\<br>1&amp; x_{31} &amp; x_{32} &amp; x_{33} &amp; \dots &amp; x_{3n}\\<br>\dots\\<br>1&amp; x_{m1} &amp; x_{m2} &amp; x_{m3} &amp; \dots &amp; x_{mn}\\<br>\end{bmatrix} * \begin{bmatrix}<br>w_0 \\<br>w_1 \\<br>w_2 \\<br>\dots\\<br>w_n \\<br>\end{bmatrix}$$</p><p>$$\hat y = Xw$$</p><p>在多元线性回归中，定义损失函数如下：</p><p>$$\sum_{i=1}^m(y_i-\hat y_i)^2=\sum_{i=1}^m(y_i-X_iw)^2$$</p><p>其中$y_i$是样本$i$对应的真实标签，$\hat y_i$，也就是$X_iw$样本$i$在一组参数$w$下的预测标签。</p><p>因此，最小化损失，将求解目标转化为：<br>$$\min_w||y-Xw||^2_2$$</p><p>我们称这个式子为SEE(Sum of Sqaured Error, 误差平方和)或者RSS(Residual Sum of Squares 残差平方和)</p><h2 id="1-2-最小二乘法求解多元线性回归的参数"><a href="#1-2-最小二乘法求解多元线性回归的参数" class="headerlink" title="1.2 最小二乘法求解多元线性回归的参数"></a>1.2 最小二乘法求解多元线性回归的参数</h2><p>首先，我们对$w$求导：<br>$$<br>\begin{equation}\begin{split}<br>\frac{\partial RSS}{\partial w}&amp;=\frac{\partial ||y-Xw||^2_2}{\partial w} \\<br>&amp; =\frac{\partial (y-Xw)^T(y-Xw)}{\partial w}<br>\end{split}\end{equation}<br>$$<br>$$\because (A-B)^T = A^T-B^T 并且(AB)^T=B^T*A^T$$<br>$$\therefore =\frac{\partial (y^T-w^TX^T)(y-Xw)}{\partial w}$$<br>$$=\frac{\partial(y^Ty-w^TX^Ty-y^TXw+w^TX^TXw)}{\partial w}$$</p><p>$\because$ 矩阵求导中，$a$为常数，有如下规则：<br>$$\frac{\partial a}{\partial A}=0,\frac{\partial A^TB^TC}{\partial A}=B^TC,\frac{\partial C^TBA}{\partial A}=B^TC,\frac{\partial A^TBA}{\partial A}=(B+B^T)A$$</p><p>$$=0-X^Ty-X^Ty+2X^TXw$$<br>$$=X^TXw-X^Ty$$</p><p>然后让一阶导数为0：<br>$$X^TXw-X^Ty=0$$<br>$$X^TXw=X^Ty$$<br>左乘一个$(X^TX)^{-1}$则有：<br>$$w=(X^TX)^{-1}X^Ty$$</p><p>在这里，逆矩阵的充分必要条件是特征矩阵不存在多重共线性。并且在统计学中，使用最小二乘法求解线性回归方程式一种“无偏估计”的方法，也就是标签的分布必须服从正太分布。</p><h2 id="1-3-linear-model-LinearRegression"><a href="#1-3-linear-model-LinearRegression" class="headerlink" title="1.3 linear_model.LinearRegression"></a>1.3 linear_model.LinearRegression</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.LinearRegression (ﬁt_intercept&#x3D;True, normalize&#x3D;False, copy_X&#x3D;True, n_jobs&#x3D;None)</span><br></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">ﬁt_intercept</td><td align="left">布尔值，可不填，默认为True是否计算此模型的截距。如果设置为False，则不会计算截距</td></tr><tr><td align="left">normalize</td><td align="left">布尔值，可不填，默认为False当ﬁt_intercept设置为False时，将忽略此参数。如果为True，则特征矩阵X在进入回归之前将会被减去均值（中心化）并除以L2范式（缩放）。如果你希望进行标准化，请在ﬁt数据之前   使用preprocessing模块中的标准化专用类StandardScaler</td></tr><tr><td align="left">copy_X</td><td align="left">布尔值，可不填，默认为True如果为真，将在X.copy()上进行操作，否则的话原本的特征矩阵X可能被线性回归影响并覆盖</td></tr><tr><td align="left">n_jobs</td><td align="left">整数或者None，可不填，默认为None用于计算的作业数。只在多标签的回归和数据量足够大的时候才生效。除非None在joblib.parallel_backend上下文中，否则None统一表示为1。如果输入 -1，则表示使用全部的CPU来进行计算。</td></tr></tbody></table><h1 id="2-多重共线性：岭回归与Lasso"><a href="#2-多重共线性：岭回归与Lasso" class="headerlink" title="2 多重共线性：岭回归与Lasso"></a>2 多重共线性：岭回归与Lasso</h1><h2 id="2-1-多重共线性"><a href="#2-1-多重共线性" class="headerlink" title="2.1 多重共线性"></a>2.1 多重共线性</h2><p><img src="https://note.youdao.com/yws/api/personal/file/A616BDB61AA6498B98A1A83048F5B23F?method=download&shareKey=8d479565cbc667165d0e688acf357ea0" alt></p><ul><li>多重共线性与相关性</li></ul><p>多重共线性如果存在，则线性回归就无法使用最小二乘法求解，但是不代表不能存在相关性——机器学习不要求特征之间必须独立，只要不是高度相关就好。</p><h2 id="2-2-岭回归"><a href="#2-2-岭回归" class="headerlink" title="2.2 岭回归"></a>2.2 岭回归</h2><h3 id="2-2-1-岭回归解决多重共线性问题"><a href="#2-2-1-岭回归解决多重共线性问题" class="headerlink" title="2.2.1 岭回归解决多重共线性问题"></a>2.2.1 岭回归解决多重共线性问题</h3><p>岭回归在多元线性回归的损失函数上加了正则项，表达为系数$w$的$L_2$范式乘以正则化系数$\alpha$，岭回归的损失函数的完整表达式写作：<br>$$\min_w||Xw-y||^2_2+\alpha||w||_2^2$$</p><p>现在对$w$进行求导：<br>$$\frac{\partial(RSS+\alpha||w||^2_2)}{\partial w}=\frac{\partial(||y-Xw||^2_2+\alpha||w||^2_2)}{\partial w}$$<br>$$=\frac{\partial(y-Xw)^T(y-Xw)}{\partial w}+\frac{\partial \alpha||w||^2_2}{\partial w}$$<br>$$=0-2X^Ty+2X^TXw+2\alpha$$<br>将含有$w$的项合并，其中$\alpha$为常数<br>为了实现矩阵相加，乘以一个结构为$n*n$的单位矩阵$I$:<br>$$=(X^TX+\alpha I)w-X^Ty$$<br>$$(X^TX+\alpha I)w=X^Ty$$</p><p>现在，只要$(X^TX+\alpha I)$存在逆矩阵，就可以解出$w$。一个矩阵存在逆举证的充分必要条件是这个矩阵的行列式不为0.</p><p>假设原本的特征矩阵$X^TX$不满秩：</p><p>$$X^TX=\begin{vmatrix}<br>\alpha_{11} &amp; \alpha_{12} &amp;\alpha_{13}&amp;\dots &amp;\alpha_{1n} \\<br>0 &amp; \alpha_{22} &amp;\alpha_{23}&amp;\dots &amp;\alpha_{2n} \\<br>0 &amp; 0 &amp;\alpha_{33}&amp;\dots &amp;\alpha_{3n} \\<br>&amp; &amp; \dots &amp;\\<br>0 &amp; 0 &amp;0&amp;\dots &amp;0 \\<br>\end{vmatrix}$$</p><p>然而，加上了$\alpha I$后：</p><p>$$X^TX+\alpha I=\begin{vmatrix}<br>\alpha_{11}+\alpha &amp; \alpha_{12} &amp;\alpha_{13}&amp;\dots &amp;\alpha_{1n} \\<br>0 &amp; \alpha_{22} &amp;\alpha_{23}+\alpha&amp;\dots &amp;\alpha_{2n} \\<br>0 &amp; 0 &amp;\alpha_{33}&amp;\dots &amp;\alpha_{3n}+\alpha \\<br>&amp; &amp; \dots &amp;\\<br>0 &amp; 0 &amp;0&amp;\dots &amp;\alpha \\<br>\end{vmatrix}$$</p><p>现在，这个行列式不存在全0行或者全0列了，除非：</p><ol><li>$\alpha=0$</li><li>原本矩阵$X^TX$存在对角线上元素为$-\alpha$，其他元素都为0的行或者列</li></ol><p>因此，$w$就可以写作：<br>$$w=(X^TX+\alpha I)^{-1}X^Ty$$</p><h3 id="2-2-2-linear-model-Ridge"><a href="#2-2-2-linear-model-Ridge" class="headerlink" title="2.2.2 linear_model.Ridge"></a>2.2.2 linear_model.Ridge</h3><p>在sklearn中，岭回归由线性模型库中的Ridge类来调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.Ridge (alpha&#x3D;1.0, ﬁt_intercept&#x3D;True, normalize&#x3D;False, copy_X&#x3D;True, max_iter&#x3D;None, tol&#x3D;0.001, solver&#x3D;’auto’, random_state&#x3D;None)</span><br></pre></td></tr></table></figure><h2 id="2-3-Lasso"><a href="#2-3-Lasso" class="headerlink" title="2.3 Lasso"></a>2.3 Lasso</h2><h3 id="2-3-1-Lasso与多重共线性"><a href="#2-3-1-Lasso与多重共线性" class="headerlink" title="2.3.1 Lasso与多重共线性"></a>2.3.1 Lasso与多重共线性</h3><p>Lasso使用的是系数$w$的$L_1$范式乘以正则化系数$\alpha$，因此Lasso的损失函数表达式为：<br>$$\min_w||Xw-y||^2_2+\alpha||w||_1$$</p><p>对损失函数进行求导：</p><p>$$\frac{\partial(RSS+||w||_1)}{\partial w}=\frac{\partial(||y-Xw||^2_2)+\alpha||w||_1}{\partial w}$$<br>$$=\frac{\partial(y-Xw)^T(y-Xw)}{\partial w}+\frac{\partial \alpha||w||_1}{\partial w}$$<br>$$=0-2X^Ty+2X^TXw+\alpha$$<br>将含有$w$的项合并，其中$\alpha$为常数</p><p>为实现矩阵相加，乘以一个结构为$n*n$的单位矩阵$I:$<br>$$=X^TXw-X^Ty+\frac{\alpha I}{2}$$<br>$$X^TXw=X^Ty-\frac{\alpha I}{2}$$</p><p>而$L_1$范式所带的正则项$\alpha$在求导之后并不带有$w$这个项，因此<strong>Lasso无法解决特征之间“精确相关”的问题</strong></p><p>假设方阵$X^TX$的逆是一定存在的，那我们可以有：<br>$$w=(X^TX)^{-1}(X^Ty-\frac{\alpha I}{2})$$</p><p>通过增大$\alpha$，可以为$w$的计算增肌按一个负项，从而限制参数估计中$w$的大小，而防止多重共线性引起的失准问题。因此<strong>Lasso不是从根本上解决多重共线性问题，而是限制多重共线性带来的影响</strong></p><p>$L_1,L_2$正则化一个核心差异就是他们对系数$w$的影响：两个正则化都会压缩系数$w$的大小，对标签贡献更少的特征系数会更小，也会更容易被压缩，不过$L_2$正则化只会将系数压缩到尽可能接近0，但$L_1$正则化主导稀疏性，会将系数压缩到0，这个性质让Lasso称为了线性模型中的特征选择工具首选。</p><h3 id="2-3-2-Lasso的核心作用：特征选择"><a href="#2-3-2-Lasso的核心作用：特征选择" class="headerlink" title="2.3.2 Lasso的核心作用：特征选择"></a>2.3.2 Lasso的核心作用：特征选择</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.linear_model.Lasso (alpha&#x3D;1.0, ﬁt_intercept&#x3D;True, normalize&#x3D;False, precompute&#x3D;False, copy_X&#x3D;True, max_iter&#x3D;1000, tol&#x3D;0.0001, warm_start&#x3D;False, positive&#x3D;False, random_state&#x3D;None, selection&#x3D;’cyclic’)</span><br></pre></td></tr></table></figure><h1 id="3-非线性问题：多项式回归"><a href="#3-非线性问题：多项式回归" class="headerlink" title="3 非线性问题：多项式回归"></a>3 非线性问题：多项式回归</h1><h2 id="3-1-“线性”概念"><a href="#3-1-“线性”概念" class="headerlink" title="3.1 “线性”概念"></a>3.1 “线性”概念</h2><h3 id="3-1-1-变量之间的线性关系"><a href="#3-1-1-变量之间的线性关系" class="headerlink" title="3.1.1 变量之间的线性关系"></a>3.1.1 变量之间的线性关系</h3><p>两个变量之间的关系可以展示为一条直线</p><p><img src="https://note.youdao.com/yws/api/personal/file/97AE26C1073A4E8F862543C4AD9A3223?method=download&shareKey=e4b169f42f176d2c0e21bfa46b06d126" alt></p><h3 id="3-1-2-数据的线性与非线性"><a href="#3-1-2-数据的线性与非线性" class="headerlink" title="3.1.2 数据的线性与非线性"></a>3.1.2 数据的线性与非线性</h3><p>一组数据由多个特征和标签组成。当这些特征分别与标签存在线性关系的时候，我们就说这一组数据是线性数据。当需要用三角函数，指数函数等来定义，则说这种数据叫作“非线性数据”</p><p><img src="https://note.youdao.com/yws/api/personal/file/D4B139AFD9FA4DF19C2C2E9CA44526FC?method=download&shareKey=f750e469a64f7fe5ed9af4c120d7772c" alt></p><h3 id="3-1-3-线性模型和非线性模型"><a href="#3-1-3-线性模型和非线性模型" class="headerlink" title="3.1.3 线性模型和非线性模型"></a>3.1.3 线性模型和非线性模型</h3><p>线性回归方程中，其自变量都是一次项，线性模型可以用来拟合非线性数据，而非线性模型也可以用来拟合线性数据，有的模型既可以使线性也可以使非线性模型。</p><ul><li>非线性模型拟合线性数据</li></ul><p>非线性模型几乎都可以在线性可分数据上有不逊于线性模型的表现<br><img src="https://note.youdao.com/yws/api/personal/file/1D70B4CDFF03423E97ABC37F0C1B8733?method=download&shareKey=f3b9556697932b23dedc04c06ae3a3cd" alt></p><ul><li>线性模型拟合非线性数据</li></ul><p>但是相反的，线性模型用来拟合非线性数据，通常表现糟糕。改善线性模型在非线性数据上的效果的方法之一是进行分箱，甚至可以搞过一些非线性模型。</p><p><img src="https://note.youdao.com/yws/api/personal/file/A2F08F0D7A8D4761B16B779877453614?method=download&shareKey=36e49e3e63725e9534077264653e4574" alt></p><ul><li>即是线性，也是非线性的模型</li></ul><p>有一些模型，即可以处理线性数据又可以处理非线性数据，比如支持向量机。这个模型的线性和非线性取决于它的核函数。</p><p><img src="https://note.youdao.com/yws/api/personal/file/19A7E95570314268BD269B76FF89ED2E?method=download&shareKey=5c1d7a4c6fd76e78ffad5e1fb8a91204" alt></p><h2 id="3-2-使用分箱处理非线性问题"><a href="#3-2-使用分箱处理非线性问题" class="headerlink" title="3.2 使用分箱处理非线性问题"></a>3.2 使用分箱处理非线性问题</h2><p>让线性回归在非线性数据上表现提升的核心方法之一是对数据进行分箱，也就是离散化。</p><p>在工业中，大量离散化变量与线性模型连用的实例很多，在深度学习出现之前，这种模式甚至一度统治一些工业中的机器学习应用场景，可见效果优秀，应用广泛。对于现在的很多工业场景而言，大量离散化特征的情况可能已经不是那么多了，不过大家依然需要对“分箱能够解决线性模型无法处理非线性数据的问题”有所了解。</p><h2 id="3-3-多项式回归PolynomialFeatures"><a href="#3-3-多项式回归PolynomialFeatures" class="headerlink" title="3.3 多项式回归PolynomialFeatures"></a>3.3 多项式回归PolynomialFeatures</h2><h3 id="3-3-1-多项式对数据做了什么"><a href="#3-3-1-多项式对数据做了什么" class="headerlink" title="3.3.1 多项式对数据做了什么"></a>3.3.1 多项式对数据做了什么</h3><p>除了分箱之外，另一种更普遍的用于解决”线性回归只能处理线性数据“问题的手段，就是使用多项式回归对线性回归进行改进。这样的手法是机器学习研究者们从支持向量机中获得的：支持向量机通过升维可以将非线性可分数据转化为线性可分，然后使用核函数在低维空间中进行计算，这是一种“高维呈现，低维解释”的思维。那我们为什么不能让线性回归使用类似于升维的转换，将数据由非线性转换为线性，从而为线性回归赋予处理非线性数据的能力呢？当然可以。<br><img src="https://note.youdao.com/yws/api/personal/file/176FBDF502BB4D36ADAB608843183733?method=download&shareKey=0326e48215aac4f9a94d6ef3365e2d11" alt></p><p>接下来，我们就来看看线性模型中的升维工具：多项式变化。这是一种通过增加自变量上的次数，而将数据映射到高维空间的方法，只要我们设定一个自变量上的次数（大于1），就可以相应地获得数据投影在高次方的空间中的结果。这种方法可以非常容易地通过sklearn中的类PolynomialFeatures来实现。我们先来简单看看这个类是如何使用的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.preprocessing.PolyinomialFeatures(degree&#x3D;2, interaction_only&#x3D;False,include_bias&#x3D;True)</span><br></pre></td></tr></table></figure><h3 id="3-3-2-多项式回归的可解释性"><a href="#3-3-2-多项式回归的可解释性" class="headerlink" title="3.3.2 多项式回归的可解释性"></a>3.3.2 多项式回归的可解释性</h3><p>多项式回归的可解释性还存在，并且我们可以通过这样的手段做特征工程——特征创造。多项式帮助我们进行了一些列特征之间相乘的结合，若讷讷够找出组合起来后对标签贡献巨大的特征，那我们就是创造了新的有效特征，对任何学科而言发现新特征都是非常有价值的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-多元线性回归LinearRegression&quot;&gt;&lt;a href=&quot;#1-多元线性回归LinearRegression&quot; class=&quot;headerlink&quot; title=&quot;1 多元线性回归LinearRegression&quot;&gt;&lt;/a&gt;1 多元线性回归LinearRegression&lt;/h1&gt;&lt;h2 id=&quot;1-1-多元线性回归的基本原理&quot;&gt;&lt;a href=&quot;#1-1-多元线性回归的基本原理&quot; class=&quot;headerlink&quot; title=&quot;1.1 多元线性回归的基本原理&quot;&gt;&lt;/a&gt;1.1 多元线性回归的基本原理&lt;/h2&gt;&lt;p&gt;对于一个$n$个特征的样本$i$而言，回归方程为：&lt;br&gt;$$\hat y_i = w_0 +w_1x_{i1}+w_2x_{i2}+\dots+w_nx_{in}$$&lt;/p&gt;
&lt;p&gt;$w_0$被称为截距，$w_1 \sim w_n$被称为回归系数，$w_{i1} \sim x_{in}$是样本$i$上的不同特征，如果考虑我们有m个样本，则回归可以被写作：&lt;br&gt;$$\hat y = w_0 +w_1x_{1}+w_2x_{2}+\dots+w_nx_{n}$$&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（二）支持向量机（SVM）</title>
    <link href="https://liangggggg.github.io/2020/07/16/svm/"/>
    <id>https://liangggggg.github.io/2020/07/16/svm/</id>
    <published>2020-07-16T13:24:13.000Z</published>
    <updated>2020-07-18T06:27:12.058Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-支持向量机（SVM）原理"><a href="#1-支持向量机（SVM）原理" class="headerlink" title="1 支持向量机（SVM）原理"></a>1 支持向量机（SVM）原理</h1><p>从算法的功能来看，SVM几乎涵盖了机器学习的所有算法需求</p><table><thead><tr><th align="left"></th><th align="left">功能</th></tr></thead><tbody><tr><td align="left">有监督学习</td><td align="left">线性二分类与多分类（Linear Support Vector Classiﬁcation）</td></tr><tr><td align="left"></td><td align="left">非线性二分类与多分类（Support Vector Classiﬁcation, SVC）</td></tr><tr><td align="left"></td><td align="left">普通连续型变量的回归（Support Vector Regression）</td></tr><tr><td align="left"></td><td align="left">概率型连续变量的回归（Bayesian SVM）</td></tr><tr><td align="left">无监督学习</td><td align="left">支持向量聚类（Support Vector Clustering，SVC）</td></tr><tr><td align="left"></td><td align="left">异常值检测（One-class SVM）</td></tr><tr><td align="left">半监督学习</td><td align="left">转导支持向量机（Transductive Support Vector Machines，TSVM）</td></tr></tbody></table><a id="more"></a><h2 id="1-1-线性SVM用于分类的原理"><a href="#1-1-线性SVM用于分类的原理" class="headerlink" title="1.1 线性SVM用于分类的原理"></a>1.1 线性SVM用于分类的原理</h2><p>要理解SVM的损失函数，先定义决策边界，假设数据中共计有$N$个训练样本，每个训练样本$i$可以被表示为$(x_i,y_i)(i=1,2,\dots N)$，其中$x_i$是$(x_{1i},x_{2i}\dots x_{ni})^T$这样一个特征向量，每个样本总共包含$n$个特征。</p><p>二分类标签$y_i$取值为${-1,1}$</p><p>若$n=2$，则有$i=(x_{1i},x_{2i},y_i)^T$，在二维平面上，以$x_2$为横坐标，$x_1$为从坐标，$y$为颜色，来可视化所有的$N$个样本</p><p><img src="https://note.youdao.com/yws/api/personal/file/A4A7E90B88454F098F8BDBDCCF02B27D?method=download&shareKey=a5c90f8c069094d544bacfbb471dbd02" alt></p><p>所以要在这个数据集上找寻一个决策边界(超平面)，让紫色点的标签为1，红色点的标签为-1</p><p>二维平面上，任意一条线可以表示为：<br>$$x_1 = ax_2+b$$</p><p>将表达式变换：<br>$$0=ax_2-x_1+b$$<br>$$0=(a,-1)*\binom{x_2}{x_1}+b$$<br>$$0=w^Tx+b$$</p><p>其中$(a,-1)$是参数向量$w$，$x$是特征向量，$b$是截距，在SVM中，使用这个表达式表示决策边界。</p><p><strong>我们的目标是求解能够让边际最大化的决策边界</strong></p><p>如果在决策边界上任意取两个点$x_a,x_b$，并代入决策边界的表达式，则有：<br>$$w^Tx_a+b=0$$<br>$$w^Tx_b+b=0$$<br>两式相减，可以得到：<br>$$w^T*(x_a-x_b)=0$$</p><p>两个向量的点积为0，证明参数向量$w$的方向垂直与我们的决策边界</p><p><img src="https://note.youdao.com/yws/api/personal/file/F29C776BA1854D9C87B9BA1EEFF2F3B9?method=download&shareKey=f6addba1a1e3223deb09059443ef2cf1" alt></p><p>由于紫色的点代表标签$y=1，y=-1$，因此以下式判定：<br>$$<br>y=<br>\begin{cases}<br>1, &amp;if\ w*x_t+b&gt;0\\<br>-1, &amp;if\ w * x_t+b&lt;0<br>\end{cases}<br>$$</p><p><strong>注意：决策边界以上的点都为正，以下的点都为负，是人为规定的，不会影响对参数$w$和截距$b$的求解</strong></p><p>决策边界的两边要有两个超平面，两个超平面在二维空间中是两条平行线（虚线超平面），而他们之间的距离就是我们的边际$d$。<br>我们将这两条平行线表示为：</p><p>$$w * x+b=k, w * x+b=-k$$</p><p>两边同时除以$k$,则可以得到：</p><p>$$w * x+b=1, w * x+b=-1$$</p><p>表达式两边1和-1分别表示了两条平行决策边界的虚线到决策边界的相对距离。让这两条线分别过两类数据中距离决策边界最近的点，这些点被称为“支持向量”。</p><p>令紫色类的点为$x_p$，红色类的点为$x_r$，则可以得到：</p><p>$$w * x_p+b=1,w * x_r+b=-1$$</p><p>两个式相减，则有：<br>$$w * (w_p-w_r)=2$$<br>如下图所示，$(x_p-x_r)$可以表示为两点之间的连线，而边际$d$是平行于$w$的。</p><p>又因为以下数学性质：</p><table><thead><tr><th align="left">线性代数中模长的运用</th></tr></thead><tbody><tr><td align="left">向量$b$除以自身的模长可以得到$b$方向上的单位向量</td></tr><tr><td align="left">向量a乘以向量b方向上的单位向量，可以得到向量a在向量b方向上的投影的长度。</td></tr></tbody></table><p>所以，将上述式子两边同时除以$||w||$, 则可以得到：<br>$$\frac{w*(x_p-x_r)}{||w||}=\frac{2}{||w||}$$<br>$$d = \frac{2}{||w||}$$</p><p><img src="https://note.youdao.com/yws/api/personal/file/B26C385AAC024C1791BBFDDF643F3D01?method=download&shareKey=aa3e06d8df0f9b472581aa1282400ae3" alt></p><p>所以，求最大边界，对应的就是最大化d,求解以下函数的最小值：<br>$$f(w)=\frac{||w||^2}{2}$$</p><p>对于任意样本，可以把决策函数写作：<br>$$w * x_i+b&gt;=1\   if\ y_i=1$$<br>$$w * x_i+b&lt;=-1 \  if\ y_i=-1$$<br>将两个式子整合：<br>$$y_i(w*x_i+b)&gt;=1, i=1,2,\dots N$$</p><h2 id="1-2-线性SVM的拉格朗日对偶函数和决策函数"><a href="#1-2-线性SVM的拉格朗日对偶函数和决策函数" class="headerlink" title="1.2 线性SVM的拉格朗日对偶函数和决策函数"></a>1.2 线性SVM的拉格朗日对偶函数和决策函数</h2><p>损失函数分为两个部分：最要最小化的函数，以及参数求解后必须满足的约束条件</p><h3 id="1-2-1-将损失函数从最初形态转换为拉格朗日乘数形态"><a href="#1-2-1-将损失函数从最初形态转换为拉格朗日乘数形态" class="headerlink" title="1.2.1 将损失函数从最初形态转换为拉格朗日乘数形态"></a>1.2.1 将损失函数从最初形态转换为拉格朗日乘数形态</h3><p><strong>1.为什么要进行转换？</strong></p><p>我们的目标是求解让损失函数最小化的$w$，希望能够找出一种方式，能在满足条件$y_i(w*x_i+b)&gt;=1$，因此，一种业界认可的方式是使用拉格朗日乘数法(standard Lagrange multiplier method)</p><p><strong>2.为什么可以进行转换</strong></p><p>拉格朗日乘数法正好可以用来解决凸优化问题，使用拉格朗日乘数法将损失函数改写为考虑了约束条件的形式：<br>$$L(w,b,\alpha)=\frac{1}{2}||w||^2-\sum_{i=1}^N\alpha_i(y_i(w*x_i+b)-1) (\alpha_i&gt;=0)$$</p><p>其中，$\alpha_i$叫作拉格朗日乘数。</p><p><strong>3.怎样进行转换</strong></p><p>拉格朗日函数分为两个部分，第一部分是原始损失函数，第二部分是约束条件。我们希望，$L(w,b,\alpha)$在满足约束条件下，最小化损失函数。所以要先以$\alpha$为参数，求解$L(w,b,\alpha)$的最大值，在以$w,b$为参数，求解$L(w,b,\alpha)$的最小值。</p><p>因此，我们的目标可写作：</p><p>$$\min_{w,b}\max_{\alpha_i&gt;=0}L(w,b,\alpha) (\alpha_i&gt;=0)$$</p><p>首先，第一步执行max，即最大化$L(w,b,\alpha)$，有两种情况：</p><ul><li>当$y_i(w * x_i+b)&gt;1$，函数的第二部分$\sum_{i=1}^N\alpha_i(y_i(w*x_i+b)-1)$一定为正，式子$\frac{1}{2}||w||^2$就要减去一个正数，此时若需要最大化$L(w,b,\alpha)$,则$\alpha$必须取到0</li><li>当$y_i(w * x_i+b)&lt;1$，函数的第二部分$\sum_{i=1}^N\alpha_i(y_i(w*x_i+b)-1)$一定为负，式子$\frac{1}{2}||w||^2$就要减去一个负数，此时若需要最大化$L(w,b,\alpha)$,则$\alpha$必须取到正无穷</li></ul><p>因此，可以把函数的第二部分当做一个惩罚项，只有当$y_i(w*x_i+b)&gt;1$时函数没有受到惩罚，从而在求解最小值的时候让约束条件满足</p><p>现在，$L(w,b,\alpha)$是我们新的损失函数，目标要通过先最大化，再最小化求解$w，b$</p><h3 id="1-2-2-将拉格朗日函数转换为拉格朗日对偶函数"><a href="#1-2-2-将拉格朗日函数转换为拉格朗日对偶函数" class="headerlink" title="1.2.2 将拉格朗日函数转换为拉格朗日对偶函数"></a>1.2.2 将拉格朗日函数转换为拉格朗日对偶函数</h3><p><strong>1.为什么要进行转换？</strong><br>求极值，最简单的方法是对参数求导后让一阶导数为0，这里对参数$w,b$分别求偏导并使其为0</p><p>$$<br>\begin{equation}\begin{split}<br>L(w,b,\alpha)&amp;=\frac{1}{2}||w||^2-\sum_{i=1}^N\alpha_i(y_i(w * x_i+b)-1)\\<br>&amp;=\frac{1}{2}||w||^2-\sum_{i=1}^N(\alpha_iy_iw * x_i+\alpha_iy_ib-\alpha_i) \\<br>&amp; =\frac{1}{2}||w||^2-\sum_{i=1}^N(\alpha_iy_iw * x_i)-\sum_{i=1}^N\alpha_iy_ib+\sum_{i=1}^N\alpha_i\\<br>&amp;=\frac{1}{2}(w^Tw)^{\frac{1}{2}*2}-\sum_{i=1}^N(\alpha_iy_iw * x_i)-\sum_{i=1}^N\alpha_iy_ib+\sum_{i=1}^N\alpha_i<br>\end{split}\end{equation}<br>$$</p><p>$$<br>\begin{equation}\begin{split}<br>\frac{\partial L(w,b,\alpha)}{\partial w}&amp;=\frac{1}{2}*2w-\sum_{i=1}^N\alpha_iy_ix_i \\<br>&amp;=w-\sum_{i=1}^N\alpha_iy_ix_i=0 \to w = \sum_{i=1}^N\alpha_iy_ix_i<br>\end{split}\end{equation}<br>$$</p><p>$$<br>\begin{equation}\begin{split}<br>\frac{\partial L(w,b,\alpha)}{\partial b}&amp;=\sum_{i=1}^N\alpha_iy_i=0 \to \sum_{i=1}^N\alpha_iy_i=0 \\<br>\end{split}\end{equation}<br>$$</p><p>由于两个求偏导结果中都带有未知的拉格朗日乘数$\alpha_i$，因此需要有一种方法来求解拉格朗日乘数，而拉格朗日对偶函数，是只带有$alpha_i$而不带有$w,b$的形式，可以求解$\alpha_i$然后再代入（2）、（3）式中来求解参数$w,b$</p><p><strong>2.为什么能够进行转换</strong></p><p>对于任意一个拉格朗日函数$L(x,\alpha)=f(x)+\sum_{i=1}^q\alpha_ih_i(x)$，都存在一个与它对应的对偶函数$g(\alpha)$，只带有拉格朗日乘数$\alpha$作为唯一参数。如果$L(x,\alpha)$存在最优解并可以表示为$\min_xL(x,\alpha)$，并且对偶函数的最优解也存在并可以表示为$\max_\alpha g(\alpha)$，则可以定义对偶差异(dual gap)<br>$$\Delta = \min_{x}L(x,\alpha)-\max_\alpha g(\alpha)$$</p><p>如果$\Delta=0$,则称$L(x,\alpha)$与其对偶函数之间存在强对偶关系，此时可以通过求其对偶函数的最优解来代替原始函数。</p><p>强对偶关系存在需要满足KKT(Karush-Kuhn-Tucker)条件：<br>$$<br>\begin{equation}\begin{split}<br>\frac{\partial L}{\partial x_i}=0,\forall_i = 1,2,\dots,d \\<br>h_i(x)&lt;=0,\forall_i = 1,2,\dots,q \\<br>\alpha_i&gt;=0,\forall_i = 1,2,\dots,q \\<br>\alpha_ih_i(x)=0,\forall_i = 1,2,\dots,q \\<br>\end{split}\end{equation}<br>$$</p><p>如果我们可以让KKT条件全部成立，则可以求解出$L(w,b,\alpha)$的对偶函数来求解$\alpha$</p><p>之前求偏导时，得到<br>$$w = \sum_{i=1}^N\alpha_iy_ix_i$$<br>$$\sum_{i=1}^N\alpha_iy_i=0$$</p><p>并且满足：<br>$$-(y(w*x_i+b)-1)&lt;=0, \alpha_i&gt;=0$$</p><p>接下来，只需要满足：<br>$$\alpha_i(y_i(w*x_i+b)-1)=0$$</p><p>当这个条件满足时，能够让$y_i(w*x_i+b)-1=0$是在虚线的超平面上的样本点，即我们的支持向量，其余样本点必须满足$\alpha_i=0$。</p><p>现在KKT的五个条件都得到了满足，可以使用对偶函数求解。</p><p><strong>3.怎样进行转换</strong></p><p>首先将求导为0代入原始：<br>$$<br>\begin{equation}\begin{split}<br>L(w,b,\alpha)&amp;=\frac{1}{2}||w||^2-\sum_{i=1}^N\alpha_i(y_i(w * x_i+b)-1)\\<br>&amp;=\frac{1}{2}||w||^2-\sum_{i=1}^N(\alpha_iy_iw * x_i+\alpha_iy_ib-\alpha_i) \\<br>&amp; =\frac{1}{2}||w||^2-\sum_{i=1}^N(\alpha_iy_iw * x_i)-\sum_{i=1}^N\alpha_iy_ib+\sum_{i=1}^N\alpha_i\\<br>&amp;=\frac{1}{2}(w^Tw)^{\frac{1}{2}*2}-w\sum_{i=1}^N(\alpha_iy_i * x_i)-b\sum_{i=1}^N\alpha_iy_i+\sum_{i=1}^N\alpha_i \\<br>\end{split}\end{equation}</p><p>将（2）、（3）式代入则有<br>$$=\frac{1}{2}w^Tw-w^Tw+\sum_{i=1}^N\alpha_i $$</p><p>$$=-\frac{1}{2}w^Tw+\sum_{i=1}^N\alpha_i$$</p><p>将（2）式代入，则有：<br>$$=-\frac{1}{2}\sum_{i=1}^N\alpha_iy_ix_i^T * \sum_{i=1}^N\alpha_iy_ix_i+\sum_{i=1}^N\alpha_i$$</p><p>令这两个$w$源于不同的特征和标签：<br>$$=-\frac{1}{2}\sum_{i=1,j=1}^N\alpha_iy_ix_i^T\alpha_iy_ix_i+\sum_{i=1}^N\alpha_i$$</p><p>$$=\sum_{i=1}^N\alpha_i-\frac{1}{2}\sum_{i=1,j=1}^N\alpha_i\alpha_jy_iy_jx_i^Tx_j$$</p><p>将矩阵相乘转换为内积形式：<br>$$L_d = \sum_{i=1}^N\alpha_i-\frac{1}{2}\sum_{i=1,j=1}^N\alpha_i\alpha_jy_iy_jx_i * x_j$$</p><p>函数$L_d$就是对偶函数，其对偶差异$L(w,b,\alpha)$和$L_d$，则有：<br>$$\Delta = \min_{w,b}\max_{\alpha_i&gt;=0}L(w,b,\alpha)-\max_{\alpha_i&gt;=0}L_d$$</p><p>又因为在推导$L_d$时，对$L(w,b,\alpha)$偏导为0，所以可以把公式写成：<br>$$\Delta = \min_{w,b}\max_{\alpha_i&gt;=0}L(w,b,\alpha)-\max_{\alpha_i&gt;=0}\min_{w,b}L(w,b,\alpha)$$</p><p>又因为所有KKT条件满足，所以：<br>$$ \min_{w,b}\max_{\alpha_i&gt;=0}L(w,b,\alpha)=\max_{\alpha_i&gt;=0}\min_{w,b}L(w,b,\alpha)$$</p><p>所以，我们只需要求解对偶函数的最大值就可以了，最终，目标函数变化为：<br>$$\max_{\alpha_i&gt;=0}(\sum_{i=1}^N\alpha_i-\frac{1}{2}\sum_{i=1,j=1}^N\alpha_i\alpha_jy_iy_jx_i * x_j)$$</p><h3 id="1-2-3-求解拉格朗日对偶函数极值及其后续过程"><a href="#1-2-3-求解拉格朗日对偶函数极值及其后续过程" class="headerlink" title="1.2.3 求解拉格朗日对偶函数极值及其后续过程"></a>1.2.3 求解拉格朗日对偶函数极值及其后续过程</h3><p>需要使用梯度下降、SMO或者二次规划(QP, quadratic programming)来求解，但是这一过程对数学要求的程度已经远远超出了需要的程度，因此不再深入了解。</p><p>只需要知道，一旦求到了$\alpha$值，就可以求得决策边界参数$w,b$</p><p>当求得参数后，就可以得到决策边界的表达式：<br>$$f(x_{test})=sign(w*x_{test}+b)$$</p><p>其中$x_{test}$是任意测试样本，$sign(h)$是符号函数。</p><p>至此，我们对SVM的原理已经有了一个比较深刻的理解。</p><h2 id="1-3-非线性SVM与核函数"><a href="#1-3-非线性SVM与核函数" class="headerlink" title="1.3 非线性SVM与核函数"></a>1.3 非线性SVM与核函数</h2><h3 id="1-3-1-SVC在非线性数据上的推广"><a href="#1-3-1-SVC在非线性数据上的推广" class="headerlink" title="1.3.1 SVC在非线性数据上的推广"></a>1.3.1 SVC在非线性数据上的推广</h3><p>为了找出非线性数据的线性决策边界，我们需要将数据从原始空间$x$，投射到新空间$\Phi(x)$中，$\Phi(x)$是一个映射函数，代表某种非线性变换。线性SVM的原理可以很容易推广到非线性情况下，推导过程和逻辑都与线性SVM一样，只是在定义决策边界之前，需要对数据升维，将原始的$x$，转换成$\Phi(x)$</p><p>因此，非线性SVM的损失函数初始形态为：<br>$$\min_{w,b}\frac{||w||^2}{2}$$<br>$$subject\  to\  y_i(w * \Phi(x)+b&gt;=1), i=1,2,\dots,N$$<br>拉格朗日和拉格朗日对偶函数也可得：<br>$$L(w,b,\alpha)=\frac{1}{2}||w||^2-\sum_{i=1}^N\alpha_i(y_i(w * \Phi(x)+b)-1)$$<br>$$L_d = \sum_{i=1}^N\alpha_i - \frac{1}{2}\sum_{i,j}\alpha_i\alpha_j y_i y_j\Phi(x_i)\Phi(x_j)$$</p><p>同理可以使用相同的推导方式让拉格朗日函数满足KKT条件，并且对每个参数求导，再使用梯度下降或SMO等方式求解，最终得到决策边界函数：<br>$$f(x_{test})=sign(w*\Phi(x_{test})+b)$$</p><h3 id="1-3-2-重要参数kernel"><a href="#1-3-2-重要参数kernel" class="headerlink" title="1.3.2 重要参数kernel"></a>1.3.2 重要参数kernel</h3><p>但是，我们不清楚什么样的数据应该使用什么类型的映射函数确保在变换空间中可以找出决策边界。</p><table><thead><tr><th align="left">关键概念：核函数</th></tr></thead><tbody><tr><td align="left">解决这个问题的数学方式，叫作“核技巧”(Kernel Trick)，是一种讷讷够使用数据原始空间中的向量计算表示生维后的空间中的点积结果的数学方式$K(u,v)=\Phi(u)*\Phi(v)$,而这个点积函数$K(u,v)$，就被叫作“核函数”(Kernel Funciton)</td></tr></tbody></table><p>选用不同的核函数，就可以解决不同数据分布下寻找超平面的问题。以下是“kernel”在Sklearn中的几种选项：</p><p><img src="https://note.youdao.com/yws/api/personal/file/0D76DD0804FD486EA95C591CDF1335C5?method=download&shareKey=c5e8aae3bd6137b2f4c315008302565b" alt></p><h3 id="1-3-3-核函数的优势和缺陷"><a href="#1-3-3-核函数的优势和缺陷" class="headerlink" title="1.3.3 核函数的优势和缺陷"></a>1.3.3 核函数的优势和缺陷</h3><ol><li>线性核，尤其是多项式核：在高次项计算非常缓慢</li><li>rbf和多项式核不擅长处理量纲不统一的数据集</li></ol><p><strong>因此，SVM执行之前，推荐先进行数据的无量纲化处理</strong></p><h3 id="1-3-4-核函数相关的参数：degree-amp-gamma-amp-coef0"><a href="#1-3-4-核函数相关的参数：degree-amp-gamma-amp-coef0" class="headerlink" title="1.3.4 核函数相关的参数：degree &amp; gamma &amp; coef0"></a>1.3.4 核函数相关的参数：degree &amp; gamma &amp; coef0</h3><ul><li>gamma是表达式中的$\gamma$</li><li>degree是多项式核函数的次数$d$</li><li>ceof0是常数项</li></ul><table><thead><tr><th align="left">参数</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">degree</td><td align="left">整数，可不填，默认3</td></tr><tr><td align="left"></td><td align="left">多项式核函数的次数（’poly’），如果核函数没有选择”poly”，这个参数会被忽略</td></tr><tr><td align="left">gamma</td><td align="left">浮点数，可不填，默认“auto”</td></tr><tr><td align="left"></td><td align="left">核函数的系数，仅在参数Kernel的选项为”rbf”,”poly”和”sigmoid”的时候有效</td></tr><tr><td align="left"></td><td align="left">输入“auto”，自动使用1/(n_features)作为gamma的取值</td></tr><tr><td align="left"></td><td align="left">输入”scale”，则使用1/(n_features * X.std())作为gamma的取值</td></tr><tr><td align="left">ceof0</td><td align="left">浮点数，可不填，默认=0.0</td></tr><tr><td align="left"></td><td align="left">核函数中的常数项，它只在参数kernel为’poly’和’sigmoid’的时候有效。</td></tr></tbody></table><h2 id="1-4-硬间隔与软间隔：重要参数C"><a href="#1-4-硬间隔与软间隔：重要参数C" class="headerlink" title="1.4 硬间隔与软间隔：重要参数C"></a>1.4 硬间隔与软间隔：重要参数C</h2><h3 id="1-4-1-SVM在软间隔数据上的推广"><a href="#1-4-1-SVM在软间隔数据上的推广" class="headerlink" title="1.4.1 SVM在软间隔数据上的推广"></a>1.4.1 SVM在软间隔数据上的推广</h3><p>我们可以通过调整我们对决策边界的定义，将硬间隔时得出的数学结论推广到软间隔的情况上，让决策边界能够忍  受一小部分训练误差。这个时候，我们的决策边界就不是单纯地寻求最大边际了，因为对于软间隔地数据来说，边  际越大被分错的样本也就会越多，因此我们需要找出一个”最大边际“与”被分错的样本数量“之间的平衡<br>|关键概念：硬间隔与软间隔|<br>|:–|<br>|当两组数据是完全线性可分，我们可以找出一个决策边界使得训练集上的分类误差为0，这两种数据就被称为  是存在”硬间隔“的。当两组数据几乎是完全线性可分的，但决策边界在训练集上存在较小的训练误差，这两种数据就被称为是存在”软间隔“。|</p><p><img src="https://note.youdao.com/yws/api/personal/file/C2FFA1AA25854902ACF46B5A0C5D3410?method=download&shareKey=95be7710c6d12317d6fbda16a8bd436e" alt></p><p>由上图可知，超平面无法让数据上的训练误差为0，因此需要放松判别函数的条件，引入松弛系数$\zeta$来帮助优化判别函数：<br>$$w<em>x_i +b&gt;=1-\zeta_i if\ y_i = 1$$<br>$$w</em>x_i +b&lt;=-1+\zeta_i if\ y_i = -1$$</p><p>其中$\zeta_i&gt;0$，在求解最大边际的损失函数中加上一个惩罚项，我们的拉格朗日函数，拉格朗日对偶函数也因此被松弛系数改变：<br>$$\min_{w,b,\zeta}\frac{||w||^2}{2}+C\sum_{i=1}^n\zeta_i$$<br>$$subject to y_i(w* \Phi(x_i)+b&gt;=1-\zeta_i)$$<br>$$\zeta_i&gt;=0,i=1,2,\dots,N$$</p><p>其中，$C$是用来控制惩罚力度的系数</p><p>拉格朗日函数为(其中$\mu$是第二个拉格朗日乘数)：<br>$$L(w,b,\alpha,\zeta)= \frac{1}{2}||w||^2+C\sum_{i=1}^N\zeta_i-\sum_{i=1}^N\alpha_i(y_i(w*\zeta(x_i)+b)-1+\zeta_i)-\sum_{i=1}^N\mu_i\zeta_i$$</p><p>需要满足的KKT条件为：<br>$$\frac{\partial L(w,b,\alpha,\zeta)}{\partial w}=\frac{\partial L(w,b,\alpha,\zeta)}{\partial b}=\frac{\partial L(w,b,\alpha,\zeta)}{\partial \zeta}=0$$</p><p>$$\zeta_i&gt;=0,\alpha_i&gt;=0,\mu_i&gt;=0$$<br>$$\alpha_i(y_i(w*\Phi(x_i)+b)-1+\zeta_i)=0$$<br>$$\mu_i\zeta_i=0$$</p><p>拉格朗日对偶函数为：<br>$$L_D = \sum_{i=1}^N\alpha_i - \frac{1}{2}\sum_{i,j}\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j)$$<br>$$subject\  to\  C &gt;=\alpha_i&gt;=0$$<br>公式中唯一出现的新变量，松弛系数惩罚力度$C$。由参数$C$来进行控制</p><h3 id="1-4-2-重要参数C"><a href="#1-4-2-重要参数C" class="headerlink" title="1.4.2 重要参数C"></a>1.4.2 重要参数C</h3><p>参数C用于权衡”训练样本的正确分类“与”决策函数的边际最大化“两个不可同时完成的目标，希望找出一个平衡点来让模型的效果最佳。</p><table><thead><tr><th align="left">参数</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">C</td><td align="left">浮点数，默认1，必须大于等于0，可不填</td></tr><tr><td align="left"></td><td align="left">松弛系数的惩罚项系数。如果C值设定比较大，那SVC可能会选择边际较小的，能够更好地分类所有训练点的决策边界，不过模型的训练时间也会更长。如果C的设定值较小，那SVC会尽量最大化边界，决策功能会更简单，但代价是训练的准确度。换句话说，C在SVM中的影响就像正则化参数对逻辑回归的影响。</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-支持向量机（SVM）原理&quot;&gt;&lt;a href=&quot;#1-支持向量机（SVM）原理&quot; class=&quot;headerlink&quot; title=&quot;1 支持向量机（SVM）原理&quot;&gt;&lt;/a&gt;1 支持向量机（SVM）原理&lt;/h1&gt;&lt;p&gt;从算法的功能来看，SVM几乎涵盖了机器学习的所有算法需求&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;有监督学习&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;线性二分类与多分类（Linear Support Vector Classiﬁcation）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;非线性二分类与多分类（Support Vector Classiﬁcation, SVC）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;普通连续型变量的回归（Support Vector Regression）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;概率型连续变量的回归（Bayesian SVM）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;无监督学习&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;支持向量聚类（Support Vector Clustering，SVC）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;异常值检测（One-class SVM）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;半监督学习&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;转导支持向量机（Transductive Support Vector Machines，TSVM）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（一）决策树</title>
    <link href="https://liangggggg.github.io/2020/07/15/tree/"/>
    <id>https://liangggggg.github.io/2020/07/15/tree/</id>
    <published>2020-07-15T08:04:19.000Z</published>
    <updated>2020-07-22T01:50:00.743Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="1-决策树原理"><a href="#1-决策树原理" class="headerlink" title="1 决策树原理"></a>1 决策树原理</h2><h3 id="1-1-决策树是如何工作的"><a href="#1-1-决策树是如何工作的" class="headerlink" title="1.1 决策树是如何工作的"></a>1.1 决策树是如何工作的</h3><p>决策树（Decision Tree）是一种非常参数的有监督学习方法，它能够从一系列有特征和标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，在解决各种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。</p><a id="more"></a><p><strong>决策树算法的核心是要解决两个问题：</strong><br>1）如何从数据表中找出最佳结点和最佳分枝<br>2）如何让决策树停止生长，防止过拟合？</p><p>几乎所有决策树有关的模型调整方法，都围绕这两个问题展开。</p><h3 id="1-2-构建决策树"><a href="#1-2-构建决策树" class="headerlink" title="1.2 构建决策树"></a>1.2 构建决策树</h3><p>原则上讲，任意一个数据集上的所有特征都可以被拿来分枝，特征上的任意结点又可以自由组合，所以一个数据集上可以发展处非常多测决策树，其数量可达指数级。但在这些树中，总有那么一棵树比其他的树分类效力都好，那样的树叫做“全局最优树”。</p><table><thead><tr><th align="left">关键概念：全局最优，局部最优</th></tr></thead><tbody><tr><td align="left">全局最优：经过组合形成的，整体来说分类效果最好的模型</td></tr><tr><td align="left">局部最优：每一次分枝的时候都向着更好的分类效果分枝，但无法确认如此生成的树在全局上是否是最优的</td></tr></tbody></table><p>要在这么多决策树中去一次性找到分类效果最佳的那一棵是不可能的，如果通过排列组合来进行筛选，计算量过于大而低效。<br>因此，机器学习研究者们开发了一些有效的算法，能够在合理的时间内构造出具有一定准确率的次最优决策树。这些算法基本都执行“贪心策略”，即通过局部最优来达到接近全局最优的结果</p><table><thead><tr><th align="left">关键概念：贪心算法</th></tr></thead><tbody><tr><td align="left">通过实现局部最优来达到接近全局最优结果的算法，所有的树模型都是这样的算法</td></tr></tbody></table><h3 id="1-2-1-ID3算法构建决策树"><a href="#1-2-1-ID3算法构建决策树" class="headerlink" title="1.2.1 ID3算法构建决策树"></a>1.2.1 ID3算法构建决策树</h3><p>ID3算法原型为J.R Quinlan的博士论文，是基础理论较为完善，使用较为广泛的决策树模型，并在此基础上优化退出了C4.5和C5.0决策树算法，后两者已经成为最流行的决策树算法。</p><p>决策树需要找出最佳节点和最佳的分枝方法，而衡量这个“最佳”的指标叫做“不纯度”。<br>不纯度基于叶子节点来计算的，所以树中的每个节点都会有一个不纯度，并且子节点的不纯度一定是低于父节点的。</p><table><thead><tr><th align="left">关键概念：不纯度</th></tr></thead><tbody><tr><td align="left">如果有某一类标签占有较大的比例，我们就说叶子节点“纯”，分枝分得好。若各类标签都很平均，则说明叶子节点“不纯”</td></tr></tbody></table><h4 id="怎样计算不纯度？"><a href="#怎样计算不纯度？" class="headerlink" title="怎样计算不纯度？"></a>怎样计算不纯度？</h4><p>对于节点不纯度的计算和表示方法因决策树模型而异，但不管不纯度的度量方法如何，都是由误差率衍生而来，其计算公式如下：<br>$$Classification error(t) = 1-\max_{i=1}[p(i|t)]$$</p><p>误差率越低，则纯度越高。由此还衍生出了其他两个常用指标，一个是ID3重的Information gain（信息增益）的计算方法可用Entropy推导，即最为人熟知的信息熵，又叫香农熵，其计算公式如下：<br>$$Entropy(t)=-\sum^{c-1}_{i=0}p(i|t)\log_2p(i|t)$$</p><p>其中c表示叶子节点上标签类别的个数，c-1表示标签的索引</p><p><strong>从第0类标签开始计算，设定$\log_20=0$</strong></p><p>另一个指标则是<strong>Gini（基尼）指数</strong>，主要用于CART决策树的纯度判定中，其计算公式如下：<br>$$Gini = 1-\sum_{i=0}^{c-1}[p(i|t)]^2$$</p><p>决策树最终的优化目标是使得叶节点的总不纯度最低。因此ID3决策树在觉得是否对某节点进性切分的时候，会尽可能选取使得该节点对应的子节点信息熵最小的特征进行切分，换而言之，就是要求父节点信息熵和子节点总信息熵之差要最大，对ID3而言，二者之差就是信息增益。</p><p><strong>一个父节点下可能有多个子节点，所以信息增益为父节点信息熵-所有子节点信息熵的加权平均</strong></p><p>$$I(child) = \sum_{j=1}^k\frac{N(v_j)}{N}I(v_j)$$</p><p>而父节点和子节点的不纯度下降数可由下属公式进行计算：<br>$$\Delta = I(parent)-I(child)$$</p><p>$I(.)$是给定节点的不纯性度量，$N$是父节点上的样本树，$k$是这一层上子节点的个数，$N(v_j)$是与子节点$v_j$相关联的子样本个数</p><p>决策树算法会选择最大化增益的条件，因为对任何分枝过程来说，$I(parent)$都是一个不变的值，所以最大化增益等价于最小化子节点的不纯性衡量的加权平均。</p><h3 id="1-2-3-ID3的局限性"><a href="#1-2-3-ID3的局限性" class="headerlink" title="1.2.3 ID3的局限性"></a>1.2.3 ID3的局限性</h3><p>ID3局限性主要源于局部最优化条件，即信息增益的计算方法，其局限性主要有以下几点：</p><ul><li>分支度越高（分类水平越多）离散变量往往子节点的总信息熵会更小，ID3是按照某一列进行切分，在极限情况下取ID作为切分字段，每个分类的纯度都是100%，因此这样的分类方式是没有效益的</li><li>不能直接处理连续型变量，若使用ID3处理连续型变量，则首先需要对连续型变量进行离散化</li><li>对缺失值比较敏感，使用ID3之前需要提前对缺失值进行处理</li><li>没有剪枝的设置，容易导致过拟合，即在训练集上表现很好，测试集上表现很差</li></ul><h3 id="1-3-C4-5算法-amp-CART算法"><a href="#1-3-C4-5算法-amp-CART算法" class="headerlink" title="1.3 C4.5算法 &amp; CART算法"></a>1.3 C4.5算法 &amp; CART算法</h3><h3 id="1-3-1-修改局部最优化条件"><a href="#1-3-1-修改局部最优化条件" class="headerlink" title="1.3.1 修改局部最优化条件"></a>1.3.1 修改局部最优化条件</h3><p>在C4.5中，首先通过引入分支度（IV:Information Value）概念，对信息增益的计算方法进行修正。</p><p>将信息熵计算公式中的$p(i|t)$（<strong>即某类别样例占总样例数</strong>）改成了$P(v_i)$，即<strong>某子节点的总样本数占父节点总样本数的比例</strong></p><p>$$Information Value = -\sum_{i=1}^kP(v_i)\log_2P(v_i)$$</p><p>其中，$i$表示父节点的第$i$个子节点，$v_i$表示第$i$个子节点样例数，$P(v_i)$表示第$i$个子节点拥有样例数占父节点总样例数的比例。</p><p>最终，在C4.5中，使用之前的信息增益除以分支度作为选取切分字段的参考指标，该指标被称作Gain Ratio(增益率)，计算公式如下：<br>$$Gain Ratio = \frac{Information Gain}{Information Value}$$</p><p>本质是信息增益最大，分支度又比较小的列（也就是纯度提升很快，但又不是靠着把类别分特别细来提升的那些特征）</p><h3 id="1-3-2-连续变量处理手段"><a href="#1-3-2-连续变量处理手段" class="headerlink" title="1.3.2 连续变量处理手段"></a>1.3.2 连续变量处理手段</h3><p>在C4.5中，同样还增加了针对连续变量的处理手段。如果输入特征字段是连续型变量，则有下列步骤：</p><ol><li>算法首先会对这一列数进行从小到大排序</li><li>选取相邻的两个数的中间数作为切分数据集的备选点，若一个连续变量有N个值，则在C4.5的处理过程中将产生N-1个备选切点，并且每个切分点都代表着一种二叉树的切分方案</li></ol><p>因此在对于包含连续变量的数据集进行树模型构建的过程中要消耗更多的运算资源。但与此同时，我们也会发现，当连续变量的某中间点参与到决策树的二分过程中，往往代表该店对于最终分类结果有较大影响，这也为我们连续变量的分箱压缩提供了指导性的意见。也是最重要的模型指导分箱方法。</p><p>CART树本质其实和C4.5区别不大，只不过CART树所有的层都是二叉树</p><ol><li>首先特征从小到大一次排列</li><li>计算两两相邻的均值</li><li>按均值所在的点，对连续型变量进行二分，二分得到的点交做决策树的“树桩”</li><li>找每种二分切分方案的获益比例，获益比例最大的切分点，就是切点</li><li>切完之后，计算加权信息熵，计算信息增益，引入分支度，计算增益比例</li></ol><hr><h2 id="2-sklearn中的决策树"><a href="#2-sklearn中的决策树" class="headerlink" title="2 sklearn中的决策树"></a>2 sklearn中的决策树</h2><ul><li>模块sklearn.tree</li></ul><p>模块总共包含五个类：</p><table><thead><tr><th align="left">tree.DecisionTreeClassifier</th><th align="left">分类树</th></tr></thead><tbody><tr><td align="left">tree.DecisionTreeRegressor</td><td align="left">回归树</td></tr><tr><td align="left">tree.export_graphviz</td><td align="left">将生成的决策树导出为DOT格式</td></tr><tr><td align="left">tree.ExtraTreeClassifier</td><td align="left">高随机版本的分类树</td></tr><tr><td align="left">tree.ExtraTreeRegressor</td><td align="left">高随机版本的回归树</td></tr></tbody></table><h3 id="2-1-重要参数"><a href="#2-1-重要参数" class="headerlink" title="2.1 重要参数"></a>2.1 重要参数</h3><h3 id="2-2-1-criterion"><a href="#2-2-1-criterion" class="headerlink" title="2.2.1 criterion"></a>2.2.1 criterion</h3><p>这个参数用来决定不纯度的计算方法</p><table><thead><tr><th align="left">参数</th><th align="left">criterion</th></tr></thead><tbody><tr><td align="left">如何影响模型?</td><td align="left">确定不纯度的计算方法，帮忙找出最佳节点和最佳分枝，不纯度越低，决策树对训练集 的拟合越好</td></tr><tr><td align="left">可能的输入有哪些？</td><td align="left">不填默认基尼系数，填写gini使用基尼系数，填写entropy使用信息增益</td></tr><tr><td align="left">怎样选取参数？</td><td align="left">通常使用基尼系数</td></tr></tbody></table><h3 id="2-2-2-random-state-amp-splitter"><a href="#2-2-2-random-state-amp-splitter" class="headerlink" title="2.2.2 random_state &amp; splitter"></a>2.2.2 random_state &amp; splitter</h3><ul><li><p>random_state 用来设置分枝中的随机模式的参数，默认None，在高维度时随机性会表现更明显，低维度的数据（比如鸢尾花数据集），随机性几乎不会显现。输入任意整数，会一直长出同一棵树，让模型稳定下来。</p></li><li><p>splitter 也是用来控制决策树中的随机选项的，有两种输入值，输入”best”，决策树在分枝时虽然随机，但是还是会优先选择更重要的特征进行分枝（重要性可以通过属性feature_importances_查看），输入“random”，决策树在分枝时会更加随机，树会因为含有更多的不必要信息而更深更大，并因这些不必要信息而降低对训练集的拟合。这也是防止过拟合的一种方式。当你预测到你的模型会过拟合，用这两个参数来帮助你降低树建成之后过拟合的可能性。当然，树一旦建成，我们依然是使用剪枝参数来防止过拟合。</p></li></ul><h3 id="2-2-3-剪枝参数"><a href="#2-2-3-剪枝参数" class="headerlink" title="2.2.3 剪枝参数"></a>2.2.3 剪枝参数</h3><ul><li><p>max_depth 限制树的最大深度，超过设定深度的树枝全部剪掉这是用得最广泛的剪枝参数，在高维度低样本量时非常有效。决策树多生长一层，对样本量的需求会增加一倍，所  以限制树深度能够有效地限制过拟合。在集成算法中也非常实用。实际使用时，建议从=3开始尝试，看看拟合的效  果再决定是否增加设定深度。</p></li><li><p>min_samples_leaf 限定，一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本，否则分  枝就不会发生，或者，分枝会朝着满足每个子节点都包含min_samples_leaf个样本的方向去发生。一般搭配max_depth使用，在回归树中有神奇的效果，可以让模型变得更加平滑。这个参数的数量设置得太小会引起过拟合，设置得太大就会阻止模型学习数据。一般来说，建议从=5开始使用。如果叶节点中含有的样本量变化很 大，建议输入浮点数作为样本量的百分比来使用。同时，这个参数可以保证每个叶子的最小尺寸，可以在回归问题  中避免低方差，过拟合的叶子节点出现。对于类别不多的分类问题，=1通常就是最佳选择。</p></li><li><p>min_samples_split 限定，一个节点必须要包含至少min_samples_split个训练样本，这个节点才允许被分枝，否则  分枝就不会发生。</p></li><li><p>max_features 限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃。和max_depth异曲同工， max_features是用来限制高维度数据的过拟合的剪枝参数，但其方法比较暴力，是直接限制可以使用的特征数量而强行使决策树停下的参数，在不知道决策树中的各个特征的重要性的情况下，强行设定这个参数可能会导致模型学习不足。如果希望通过降维的方式防止过拟合，建议使用PCA，ICA或者特征选择模块中的降维算法。</p></li><li><p>min_impurity_decrease 限制信息增益的大小，信息增益小于设定数值的分枝不会发生。这是在0.19版本中更新的    功能，在0.19版本之前时使用min_impurity_split。</p></li></ul><h3 id="2-2-4-目标权重参数"><a href="#2-2-4-目标权重参数" class="headerlink" title="2.2.4 目标权重参数"></a>2.2.4 目标权重参数</h3><ul><li><p>class_weight 完成样本标签平衡的参数。样本不平衡是指在一组数据集中，标签的一类天生占有很大的比例。因此我们要使用class_weight参数对样本标签进行一定的均衡，给少量的标签更多的权重，让模型更偏向少数类，向捕获少数类的方向建模。该参数默认None，此模式表示自动给  与数据集中的所有标签相同的权重。</p></li><li><p>min_weight_fraction_leaf 有了权重之后，样本量就不再是单纯地记录数目，而是受输入的权重影响了，因此这时候剪枝，就需要搭配min_ weight_fraction_leaf这个基于权重的剪枝参数来使用。另请注意，基于权重的剪枝参数（例如min_weight_ fraction_leaf）将比不知道样本权重的标准（比如min_samples_leaf）更少偏向主导类。如果样本是加权的，则使用基于权重的预修剪标准来更容易优化树结构，这确保叶节点至少包含样本权重的总和的一小部分。</p></li></ul><h2 id="3-决策树的优缺点"><a href="#3-决策树的优缺点" class="headerlink" title="3 决策树的优缺点"></a>3 决策树的优缺点</h2><h3 id="3-1-决策树优点"><a href="#3-1-决策树优点" class="headerlink" title="3.1 决策树优点"></a>3.1 决策树优点</h3><ol><li>易于理解和解释，因为树木可以画出来被看见</li><li>需要很少的数据准备。其他很多算法通常都需要数据规范化，需要创建虚拟变量并删除空值等。但请注意，sklearn中的决策树模块不支持对缺失值的处理。</li><li>使用树的成本（比如说，在预测数据的时候）是用于训练树的数据点的数量的对数，相比于其他算法，这是一个很低的成本。</li><li>能够同时处理数字和分类数据，既可以做回归又可以做分类。其他技术通常专门用于分析仅具有一种变量类型的数据集。</li><li>能够处理多输出问题，即含有多个标签的问题，注意与一个标签中含有多种标签分类的问题区别开</li><li>是一个白盒模型，结果很容易能够被解释。如果在模型中可以观察到给定的情况，则可以通过布尔逻辑轻松解释条件。相反，在黑盒模型中（例如，在人工神经网络中），结果可能更难以解释。</li><li>可以使用统计测试验证模型，这让我们可以考虑模型的可靠性。</li><li>即使其假设在某种程度上违反了生成数据的真实模型，也能够表现良好。</li></ol><h3 id="3-2-决策树的缺点"><a href="#3-2-决策树的缺点" class="headerlink" title="3.2 决策树的缺点"></a>3.2 决策树的缺点</h3><ol><li>决策树学习者可能创建过于复杂的树，这些树不能很好地推广数据。这称为过度拟合。修剪，设置叶节点所需的最小样本数或设置树的最大深度等机制是避免此问题所必需的，而这些参数的整合和调整对初学者来说会比较晦涩</li><li>决策树可能不稳定，数据中微小的变化可能导致生成完全不同的树，这个问题需要通过集成算法来解决。</li><li>决策树的学习是基于贪婪算法，它靠优化局部最优（每个节点的最优）来试图达到整体的最优，但这种做法不能保证返回全局最优决策树。这个问题也可以由集成算法来解决，在随机森林中，特征和样本会在分枝过程中被随机采样。</li><li>有些概念很难学习，因为决策树不容易表达它们，例如XOR，奇偶校验或多路复用器问题。</li><li>如果标签中的某些类占主导地位，决策树学习者会创建偏向主导类的树。因此，建议在拟合决策树之前平衡数据集。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;h2 id=&quot;1-决策树原理&quot;&gt;&lt;a href=&quot;#1-决策树原理&quot; class=&quot;headerlink&quot; title=&quot;1 决策树原理&quot;&gt;&lt;/a&gt;1 决策树原理&lt;/h2&gt;&lt;h3 id=&quot;1-1-决策树是如何工作的&quot;&gt;&lt;a href=&quot;#1-1-决策树是如何工作的&quot; class=&quot;headerlink&quot; title=&quot;1.1 决策树是如何工作的&quot;&gt;&lt;/a&gt;1.1 决策树是如何工作的&lt;/h3&gt;&lt;p&gt;决策树（Decision Tree）是一种非常参数的有监督学习方法，它能够从一系列有特征和标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，在解决各种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liangggggg.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>行测笔记（一）：判断推理</title>
    <link href="https://liangggggg.github.io/2020/07/15/xingce/"/>
    <id>https://liangggggg.github.io/2020/07/15/xingce/</id>
    <published>2020-07-15T00:28:45.000Z</published>
    <updated>2020-08-13T11:43:15.796Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-图形推理"><a href="#1-图形推理" class="headerlink" title="1 图形推理"></a>1 图形推理</h1><h2 id="图形推理的命题形式"><a href="#图形推理的命题形式" class="headerlink" title="图形推理的命题形式"></a>图形推理的命题形式</h2><ol><li>一组图：从左往右读题，找整体规律的共同点。或间隔跳跃观察</li><li>两组图：找第一组规律，应用于第二组</li><li>九宫格：横行（最多）、数列、对角线观察规律</li><li>分组分类：找寻每组统一规律</li><li>空间类：折纸盒，转化成平面思维（截面图、三视图、立体拼合）<a id="more"></a></li></ol><h2 id="图形推理考什么？（学习重点：识别图形特征）"><a href="#图形推理考什么？（学习重点：识别图形特征）" class="headerlink" title="图形推理考什么？（学习重点：识别图形特征）"></a>图形推理考什么？（学习重点：识别图形特征）</h2><ol><li>位置规律</li><li>样式规律</li><li>属性规律</li><li>特殊规律</li><li>数量规律</li><li>空间规律</li></ol><h2 id="一、位置规律"><a href="#一、位置规律" class="headerlink" title="一、位置规律"></a>一、位置规律</h2><h3 id="位置类识别特征（各图元素组成相同）"><a href="#位置类识别特征（各图元素组成相同）" class="headerlink" title="位置类识别特征（各图元素组成相同）"></a>位置类识别特征（各图元素组成相同）</h3><h3 id="（1）平移："><a href="#（1）平移：" class="headerlink" title="（1）平移："></a>（1）平移：</h3><ol><li>方向 ：直线（上下、左右、对角线）、绕圈（顺/逆时针）</li><li>步数 ：恒定、递增（等差）、周期（考的少）</li></ol><p><strong>技巧：1.多个元素分开看，边做边排除 2.位置规律——就近走原则</strong></p><h3 id="宫格型黑块平移"><a href="#宫格型黑块平移" class="headerlink" title="宫格型黑块平移"></a>宫格型黑块平移</h3><p><strong>1.个别黑块可重合</strong></p><ul><li>题干和选项大部分元素组成完全一致，个别一两幅图少黑块</li><li>题干第一幅图的黑块一般不会重合</li></ul><p><strong>2.黑块走到头后怎么办？</strong></p><ul><li>循环走：从头开始</li><li>折返走：直接弹回</li></ul><p><strong>3.“双胞胎”黑块们如何分辨</strong>：就近走原则</p><h3 id="多宫格方向判定"><a href="#多宫格方向判定" class="headerlink" title="多宫格方向判定"></a>多宫格方向判定</h3><p>题型特征：16宫格图形多个黑块平移</p><ol><li>绕圈走：中间颜色数量相同，优先考虑内外圈分开看</li><li>走直线：中间颜色数量不同，有限考虑走直线</li></ol><h3 id="（2）旋转："><a href="#（2）旋转：" class="headerlink" title="（2）旋转："></a>（2）旋转：</h3><ol><li>方向：顺时针、逆时针</li><li>常见角度：45、60、90、180度等</li></ol><p><strong>技巧：元素多，没思路？相邻比较走起来！</strong></p><p><strong>钟表类：外面一个框，中心一个点，绕了一圈线——常考旋转</strong></p><h3 id="（3）翻转"><a href="#（3）翻转" class="headerlink" title="（3）翻转"></a>（3）翻转</h3><ol><li>左右翻转：竖轴对称</li><li>上下翻转：横轴对称</li></ol><p><strong>元素组成相同优先看位置：对称通常是图形自身的规律，而不是两幅图之间的翻转</strong></p><p><strong>技巧：先看容易看懂的，旋转180度看不出来就转卷子！</strong></p><p><strong>如何区分旋转与翻转</strong><br>只有左右互换（上下不变）——左右翻<br>只有上下互换（左右不变）——上下翻<br>上下、左右都互换——旋转180度</p><p><strong>思维导图</strong><br><img src="https://note.youdao.com/yws/api/personal/file/CC02E070330340E8880E45623154A7F9?method=download&shareKey=ab0d5ad994f7c4d39f8370b641a8faa8" alt></p><h2 id="二、样式规律"><a href="#二、样式规律" class="headerlink" title="二、样式规律"></a>二、样式规律</h2><h3 id="样式类别识别特征：元素组成相似"><a href="#样式类别识别特征：元素组成相似" class="headerlink" title="样式类别识别特征：元素组成相似"></a>样式类别识别特征：元素组成相似</h3><h3 id="（1）加、减、同、异"><a href="#（1）加、减、同、异" class="headerlink" title="（1）加、减、同、异"></a>（1）加、减、同、异</h3><p><strong>识别特征：相同线条重复出现</strong></p><ol><li>相加、相减</li><li>求异（保留不同）</li><li>求同（保留相同）</li></ol><p><strong>技巧：对比选项，从特殊线条入手（横线、竖线、最长最短线）</strong></p><p><strong>位置+样式类题目，先转谁呢？  谁搞特殊，先转谁！</strong></p><ol><li>图1与图2有相同部分——先求同求异再转</li><li>图2与图3有相同部分——转图1</li><li>图1与图3有想吐部分——转图2</li></ol><h3 id="（2）黑白运算"><a href="#（2）黑白运算" class="headerlink" title="（2）黑白运算"></a>（2）黑白运算</h3><p><strong>识别特征：图形轮廓和分割区域相同，内部的颜色不同</strong><br><strong>方法：相同位置颜色做加法（注意顺序）</strong></p><p><strong>注意：</strong></p><ol><li>运算规则具体题目具体找</li><li>黑+白 不等于 白+黑，要具体题目具体验证</li><li>与黑块平移区分：黑块数量相同，优先平移；黑块数量不同，优先黑白运算</li></ol><p><strong>技巧：在确定可能考黑白运算后，从问好处着手解题更快，边找边验证</strong></p><p><strong>思维导图</strong><br><img src="https://note.youdao.com/yws/api/personal/file/96D9D2A1C7614181B52F461B9C1872E7?method=download&shareKey=bb4bd7eaf38467812c12098b8c66fbff" alt></p><h2 id="三、属性规律"><a href="#三、属性规律" class="headerlink" title="三、属性规律"></a>三、属性规律</h2><h3 id="属性类别识别特征-元素组成不相同、不相似——优先属性"><a href="#属性类别识别特征-元素组成不相同、不相似——优先属性" class="headerlink" title="属性类别识别特征: 元素组成不相同、不相似——优先属性"></a>属性类别识别特征: 元素组成不相同、不相似——优先属性</h3><h3 id="（1）对称性"><a href="#（1）对称性" class="headerlink" title="（1）对称性"></a>（1）对称性</h3><ol><li>轴对称：”等腰”元素出现</li><li>中心对称：平行四边形，N,Z,S变形图出现</li><li>轴对称+中心对称：图形存在相互垂直的对称轴</li><li>对称性的细化考法<ul><li>对称轴的方向与数量</li><li>对称轴与图形中线的位置关系：重合、垂直、交点</li><li>角度：平行、垂直、交叉某角度</li></ul></li></ol><p><strong>优先考虑对称轴时，先画出图形对称轴！</strong></p><p><strong>技巧：整体没有规律，分开看</strong></p><h3 id="（2）曲直性"><a href="#（2）曲直性" class="headerlink" title="（2）曲直性"></a>（2）曲直性</h3><ol><li>全直线图形</li><li>全曲线图形</li><li>曲+直图形</li></ol><p><strong>常见考法：三种情况均出现；与其他考点结合命题</strong></p><p><strong>所有图形均有外框——分开看</strong></p><h3 id="（3）开闭性"><a href="#（3）开闭性" class="headerlink" title="（3）开闭性"></a>（3）开闭性</h3><p><strong>题型特征：完整图的图形留了小开口，可以考虑开闭性</strong></p><ol><li>全封闭图形</li><li>全开放图形</li><li>半封闭图形</li></ol><p><strong>黑色粗线条，生活化元素/图形留有小开口——考虑开闭性</strong></p><p><strong>思维导图</strong><br><img src="https://note.youdao.com/yws/api/personal/file/F59E60D6989F4394BE9C6BDDDC9887CF?method=download&shareKey=649c8319245813b64168677ca4240c22" alt></p><h2 id="四、特殊规律"><a href="#四、特殊规律" class="headerlink" title="四、特殊规律"></a>四、特殊规律</h2><h3 id="（1）图形间关系"><a href="#（1）图形间关系" class="headerlink" title="（1）图形间关系"></a>（1）图形间关系</h3><p><strong>识别特征：两个或多个封闭图形连在一起</strong></p><ol><li>相离</li><li>相交<ul><li>相交于点</li><li>相交于边（数量、样式：边的长短、整体还是部分）</li><li>相较于面（形状）</li></ul></li></ol><p><strong>一根线牵出多个图形考虑相交于点，其他考虑相交于边或面</strong></p><h3 id="（2）功能元素"><a href="#（2）功能元素" class="headerlink" title="（2）功能元素"></a>（2）功能元素</h3><p><strong>识别特征：黑点、白点、箭头、小图形</strong></p><ol><li>标记位置（上、下、左、右、内、外）</li><li>标记图形<ul><li>点：交点</li><li>线：直线、曲线 / 最长边、最短边</li><li>角：直角、锐角、钝角 / 最大角、最小角</li><li>面：相交面 / 最大面、最小面 / 直线面、曲线面 / 特殊形状面</li></ul></li></ol><p><strong>思维导图</strong><br><img src="https://note.youdao.com/yws/api/personal/file/84A38B8255CA4301907F28ECCE456AEE?method=download&shareKey=b6b8b1a759af355f000b27566005c2c3" alt></p><h2 id="五、数量规律"><a href="#五、数量规律" class="headerlink" title="五、数量规律"></a>五、数量规律</h2><p><strong>识别特征：元素组成不同、不相似、且属性没规律，数量规律明显</strong></p><h3 id="（1）面数量"><a href="#（1）面数量" class="headerlink" title="（1）面数量"></a>（1）面数量</h3><p><strong>注意：只有封闭的白色区域才算面</strong><br><strong>识别特征</strong><br><strong>1.图形被分割，封闭面明显</strong><br><strong>2.生活化图形、粗线条图形中留空白区域</strong></p><p>面的细化考法：数面特征图，但整体数面无答案</p><ol><li>面的形状：三角形、四边形</li><li>相同面数量</li><li>特殊面的形状：最大面、最小面、相交面</li></ol><h3 id="（2）线数量"><a href="#（2）线数量" class="headerlink" title="（2）线数量"></a>（2）线数量</h3><p><strong>识别特征</strong><br><strong>1.直线数特征图：多边形、单一直线</strong><br><strong>2.曲线数特征图：曲线图形（圆、弧、单一曲线）</strong></p><p><strong>直线和曲线分开数</strong></p><p><strong>线的细化考法</strong></p><ol><li>线的位置：边框线条、框内线条</li><li>直线的细化：横线/竖线</li></ol><p><strong>大部分图形题中有曲线，优先考虑曲线规律</strong></p><p><strong>3.线的特殊考点：笔画问题</strong><br><strong>识别特征</strong><br><strong>1.五角星、圆相切/相交、“日”变形、“田”变形</strong><br><strong>2.多端点、出头端点、圆相交(近年热点)</strong></p><ol><li>可以一笔画<ul><li>线条之间连通</li><li>奇点数量为0或2（奇点：以一个点为中心，发射出奇数条线）</li></ul></li></ol><p><strong>端点都是奇点，别忘了数！</strong></p><ol start="2"><li>多笔画<ul><li>笔画数 = 奇点数/2 (奇点数一定是偶数)</li></ul></li></ol><p><strong>不连通图直接数笔画</strong></p><h3 id="（3）点数量"><a href="#（3）点数量" class="headerlink" title="（3）点数量"></a>（3）点数量</h3><p><strong>识别特征</strong><br>1.线条交叉明显（大树杈）<br>2.乱糟糟一团线交叉<br>3.相切较多<br><strong>注意：线与线的交点数量</strong><br>1.顶点、切点是交点<br>2.端点不是交点</p><p><strong>点的细化考法：数点特征图，但整体点无规律</strong></p><ol><li><p>按线的属性细化：曲直交点</p><ul><li>特征：圆或弧多，且存在曲直相交</li></ul></li><li><p>按线的位置细化：内外交点</p><ul><li>特征：图形都有外框（内外分开看思维）</li></ul></li></ol><h3 id="（4）素数量"><a href="#（4）素数量" class="headerlink" title="（4）素数量"></a>（4）素数量</h3><p><strong>识别特征：独立的小图形</strong></p><ol><li>元素种类</li><li>元素个数</li></ol><p><strong>形状一致，大小不一致也看作一种元素</strong></p><ol start="3"><li>部分数：连在一起的就是一部分</li></ol><p><strong>识别特征：生活化图形、黑色粗线条图形</strong></p><p><strong>数量规律特征图总汇(按考频排序)</strong></p><p><img src="https://note.youdao.com/yws/api/personal/file/56CAC826F4B14DAAB59B45411A39D32E?method=download&shareKey=1d6c6fbe4ab78574d6561879d6ab8f91" alt></p><p><strong>思维导图</strong></p><p><img src="https://note.youdao.com/yws/api/personal/file/99C081A3826E4102AC4C11414BEA5180?method=download&shareKey=e819a2b5c9eb4b8fa4c807d63b28184a" alt></p><h2 id="六、空间规律"><a href="#六、空间规律" class="headerlink" title="六、空间规律"></a>六、空间规律</h2><h3 id="（1）相对面"><a href="#（1）相对面" class="headerlink" title="（1）相对面"></a>（1）相对面</h3><p>应用：一组相对面同时出现的选项排除</p><ol><li>同行同列相隔一个面</li><li>Z字形紧邻中线的两端</li></ol><p><strong>出题可能会有无中生有的面</strong></p><h3 id="（2）相邻面——公共边"><a href="#（2）相邻面——公共边" class="headerlink" title="（2）相邻面——公共边"></a>（2）相邻面——公共边</h3><p><strong>方法1：折叠前后相邻关系保持不变</strong></p><ol><li>平面图直接相邻的两个面的公共边</li><li>平面图中构成直角的两个边是同一条边</li><li>一排4个面，两头的两条边是同一条边（1-4-1）</li></ol><p><strong>方法2：画边法</strong></p><ol><li>结合选项，找一个特殊面的唯一点<ul><li>特殊面：只出现一次，有可以区分的唯一点</li><li>唯一点：是指该面中唯一的，没有与其一样的点</li></ul></li><li>顺（逆）时针方向画边，并标出序号</li></ol><p><strong>注意：同一个面、同一个点、同方向</strong><br>3. 题干与选项对应：面不一致排除</p><p><strong>思维导图</strong><br><img src="https://note.youdao.com/yws/api/personal/file/0E167A466553402EB97E034F3FA658C2?method=download&shareKey=0071ee3ee90162d908695fcb5c0c9bc4" alt></p><h1 id="2-类比推理"><a href="#2-类比推理" class="headerlink" title="2 类比推理"></a>2 类比推理</h1><h2 id="一、语义关系"><a href="#一、语义关系" class="headerlink" title="一、语义关系"></a>一、语义关系</h2><h3 id="（1）近义关系、反义关系"><a href="#（1）近义关系、反义关系" class="headerlink" title="（1）近义关系、反义关系"></a>（1）近义关系、反义关系</h3><p>如果一级关系（近反义关系）选不出答案——进行二级辨析</p><p>常见的二级辨析：感情色彩（褒义、贬义、中性）</p><h3 id="（2）比喻义、象征义"><a href="#（2）比喻义、象征义" class="headerlink" title="（2）比喻义、象征义"></a>（2）比喻义、象征义</h3><h2 id="二、逻辑关系"><a href="#二、逻辑关系" class="headerlink" title="二、逻辑关系"></a>二、逻辑关系</h2><h3 id="（1）全同关系"><a href="#（1）全同关系" class="headerlink" title="（1）全同关系"></a>（1）全同关系</h3><h3 id="（2）并列关系"><a href="#（2）并列关系" class="headerlink" title="（2）并列关系"></a>（2）并列关系</h3><ol><li>矛盾关系（只有两者）</li><li>反对关系（有第三者）</li></ol><p><strong>并列的细分考点：并列关系+功能相同</strong></p><h3 id="（3）包容关系"><a href="#（3）包容关系" class="headerlink" title="（3）包容关系"></a>（3）包容关系</h3><ol><li>种属关系</li><li>组成关系</li></ol><p><strong>区分：能用“谁是谁”造句的就是种属关系</strong></p><h3 id="（4）交叉关系"><a href="#（4）交叉关系" class="headerlink" title="（4）交叉关系"></a>（4）交叉关系</h3><h3 id="（5）对应关系"><a href="#（5）对应关系" class="headerlink" title="（5）对应关系"></a>（5）对应关系</h3><ol><li>材料</li><li>工艺</li><li>属性</li><li>功能（二级辨析：主要功能、次要功能）</li><li>时间顺序：多个行为同时出现</li></ol><p><strong>当出现多个选项符合时间顺序时，考虑动作主体</strong><br>6. 因果关系（方式目的）</p><h2 id="三、语法关系"><a href="#三、语法关系" class="headerlink" title="三、语法关系"></a>三、语法关系</h2><h3 id="（1）主谓关系"><a href="#（1）主谓关系" class="headerlink" title="（1）主谓关系"></a>（1）主谓关系</h3><h3 id="（2）动宾关系"><a href="#（2）动宾关系" class="headerlink" title="（2）动宾关系"></a>（2）动宾关系</h3><h3 id="（3）主宾关系"><a href="#（3）主宾关系" class="headerlink" title="（3）主宾关系"></a>（3）主宾关系</h3><h2 id="四、词语拆分"><a href="#四、词语拆分" class="headerlink" title="四、词语拆分"></a>四、词语拆分</h2><h3 id="（1）单字拆分"><a href="#（1）单字拆分" class="headerlink" title="（1）单字拆分"></a>（1）单字拆分</h3><h3 id="（2）成语被拆分"><a href="#（2）成语被拆分" class="headerlink" title="（2）成语被拆分"></a>（2）成语被拆分</h3><h3 id="（3）两组词语之间没有明显逻辑关系"><a href="#（3）两组词语之间没有明显逻辑关系" class="headerlink" title="（3）两组词语之间没有明显逻辑关系"></a>（3）两组词语之间没有明显逻辑关系</h3><h1 id="3-定义判断"><a href="#3-定义判断" class="headerlink" title="3 定义判断"></a>3 定义判断</h1><h2 id="解题思维："><a href="#解题思维：" class="headerlink" title="解题思维："></a>解题思维：</h2><ol><li>看提问——看清“属于/符合”,“不属于/不符合”定义等</li><li>看题干——识别有效信息：找准关键词、关键句</li><li>看选项——纠结时选项对比择优<!-- more --></li></ol><h2 id="一、快速识别有效信息"><a href="#一、快速识别有效信息" class="headerlink" title="一、快速识别有效信息"></a>一、快速识别有效信息</h2><h3 id="（1）关键词——主体、客体"><a href="#（1）关键词——主体、客体" class="headerlink" title="（1）关键词——主体、客体"></a>（1）关键词——主体、客体</h3><ol><li>主体——行为、活动的出发者</li><li>客体——行为、活动作用的对象</li></ol><ul><li>不是每题一定都有主题和客体，但是出现了要重点看</li><li>主客体不符合的选项一定不符合定义</li><li>范围越小、越明确的主/客体，越容易成为考点</li></ul><p><strong>常考主客体：</strong></p><ol><li>行政机关</li><li>全力机关</li><li>司法机关</li><li>事业单位</li><li>社会组织 </li></ol><h3 id="（2）句式引导词——引导的内容重点看"><a href="#（2）句式引导词——引导的内容重点看" class="headerlink" title="（2）句式引导词——引导的内容重点看"></a>（2）句式引导词——引导的内容重点看</h3><ol><li>方式：通过/利用…</li><li>目的：以/以达到…</li><li>原因：因为/由于…</li><li>结果：导致/从而/使得…</li><li>时间：当…时/在…情况下</li></ol><h3 id="（3）优先看到定义所在的那句话的句号和补充说明"><a href="#（3）优先看到定义所在的那句话的句号和补充说明" class="headerlink" title="（3）优先看到定义所在的那句话的句号和补充说明"></a>（3）优先看到定义所在的那句话的句号和补充说明</h3><h3 id="（4）多定义：做题方法与单定义题目一致"><a href="#（4）多定义：做题方法与单定义题目一致" class="headerlink" title="（4）多定义：做题方法与单定义题目一致"></a>（4）多定义：做题方法与单定义题目一致</h3><ol><li>问啥看啥：看清题干问的是哪个定义，重点看目标定义</li><li>比较定义：纠结两个选项时，再与其他定义比较</li></ol><h2 id="二、小技巧"><a href="#二、小技巧" class="headerlink" title="二、小技巧"></a>二、小技巧</h2><h3 id="（1）拆词"><a href="#（1）拆词" class="headerlink" title="（1）拆词"></a>（1）拆词</h3><p>从定义本身找信息，如果定义名称有明确的限定语并简单易懂，可利用定义词快速破题</p><h3 id="（2）同构选项排除法"><a href="#（2）同构选项排除法" class="headerlink" title="（2）同构选项排除法"></a>（2）同构选项排除法</h3><p>意思相似、结构相似的选项排除</p><ol><li>题干或下选项能够读不懂</li><li>同构选项出现，可以一起排除</li><li>同构有风险，使用需谨慎…</li></ol><h1 id="4-逻辑判断"><a href="#4-逻辑判断" class="headerlink" title="4 逻辑判断"></a>4 逻辑判断</h1><h2 id="一、翻译推理"><a href="#一、翻译推理" class="headerlink" title="一、翻译推理"></a>一、翻译推理</h2><p><strong>题目特征</strong></p><ol><li>题干和选项中存在明显的逻辑关联词</li><li>提问方式为：可以推出/不能推出</li></ol><p><strong>解题思维</strong></p><ol><li>先翻译</li><li>再推理<!-- more --></li></ol><h3 id="（1）翻译规则之“前-rightarrow-后”"><a href="#（1）翻译规则之“前-rightarrow-后”" class="headerlink" title="（1）翻译规则之“前$\rightarrow$后”"></a>（1）翻译规则之“前$\rightarrow$后”</h3><ol><li>若…则</li><li>只要..就</li><li>所有…都</li><li>为了…一定</li><li>…是…的充分条件</li></ol><p>（出现如果/就/都/一定）</p><h3 id="（2）推理规则之“逆否等价”"><a href="#（2）推理规则之“逆否等价”" class="headerlink" title="（2）推理规则之“逆否等价”"></a>（2）推理规则之“逆否等价”</h3><p>符号表示：$A\rightarrow B = -B\rightarrow -A$</p><p>文字表示:肯前比肯后、否后必否前</p><p>否前、肯后无必然结论</p><h3 id="（3）翻译规则之“后推前”"><a href="#（3）翻译规则之“后推前”" class="headerlink" title="（3）翻译规则之“后推前”"></a>（3）翻译规则之“后推前”</h3><ol><li>只有…才…</li><li>不…不…</li><li>除非..否则不…</li><li>…是…的基础/假设/前提/关键</li><li>…是…的必要/必不可少条件</li></ol><p><strong>“否则不”是一个整体</strong><br>6. 基础/前提/关键;不可缺少/必不可少/必要条件</p><p><strong>谁必不可少，谁在箭头后</strong></p><p>都遵循递推原则：$A\rightarrow B，B\rightarrow C $可得$A\rightarrow B\rightarrow C$</p><h3 id="（4）翻译规则之“且、或”"><a href="#（4）翻译规则之“且、或”" class="headerlink" title="（4）翻译规则之“且、或”"></a>（4）翻译规则之“且、或”</h3><p>A且B：二者同时成立</p><ol><li>和</li><li>并且</li><li>即…又…</li><li>不仅…而且..</li><li>…但是…</li></ol><p>A或B：二者至少一个成立</p><ol><li>或者</li><li>或者…或者…</li><li>至少有一个</li></ol><h3 id="（5）推理规则之“否一推一”"><a href="#（5）推理规则之“否一推一”" class="headerlink" title="（5）推理规则之“否一推一”"></a>（5）推理规则之“否一推一”</h3><p>“或”的翻译：否1$\rightarrow$1</p><p>“或”关系为真，否定一项可以得到另一项</p><p>题干中有确定信息，可由确定信息出发，排除法做题</p><h3 id="（6）推理规则之“德-摩根定律”"><a href="#（6）推理规则之“德-摩根定律”" class="headerlink" title="（6）推理规则之“德*摩根定律”"></a>（6）推理规则之“德*摩根定律”</h3><ol><li>-(A且B) = -A或-B</li><li>-(A或B) = -A且-B</li></ol><p>“且”关系常考考点：缺一不可</p><p>A$\rightarrow$B且C，可以得到：-B$\rightarrow$-A/-C$\rightarrow$-A</p><h3 id="（7）推理方式"><a href="#（7）推理方式" class="headerlink" title="（7）推理方式"></a>（7）推理方式</h3><p>提问方式：</p><p>一下哪项中的推理方式/结构与题干中的推理方式/结构相同</p><p>重结构、轻内容——字母代入做题</p><p>不考虑推理是否正确，只考虑与题干是否一致</p><h2 id="二、组合排列"><a href="#二、组合排列" class="headerlink" title="二、组合排列"></a>二、组合排列</h2><ol><li>两组及以上对象</li><li>对象之间的关系</li></ol><h3 id="（1）排除法、代入法"><a href="#（1）排除法、代入法" class="headerlink" title="（1）排除法、代入法"></a>（1）排除法、代入法</h3><ol><li>排除法：读一句，排一句<ul><li>快速找到“谁”是“谁”</li><li>快速确定“谁”不是“谁”</li></ul></li></ol><p>组合排列常用思维——谁一定不是谁</p><ol start="2"><li>代入法：假设选项正确，代入题干验证是否符合题意<ul><li>题干条件确定优先排除；题干条件不确定代入                                      </li><li>设问中有“可能”、“不可能”考虑代入<br>只猜中一半（一对一错）——混搭来破题</li></ul></li></ol><h3 id="（2）辅助技巧"><a href="#（2）辅助技巧" class="headerlink" title="（2）辅助技巧"></a>（2）辅助技巧</h3><ol><li>最大信息（题干条件中出现次数最多的信息）<br>以此作为推理起点</li><li>符号：”&gt;”、“&lt;”、“=”<br>往往涉及年龄、成绩、收入、身高等大小比较</li></ol><p>比较大小技巧——极值做排除</p><ol start="3"><li>画表格（4个及以上信息）<br>先填入确定信息</li></ol><h3 id="3-特殊题型——材料题"><a href="#3-特殊题型——材料题" class="headerlink" title="(3) 特殊题型——材料题"></a>(3) 特殊题型——材料题</h3><ol><li>与非材料题解题方式一致——一则材料、多种技巧</li><li>通过材料直接推出来的结论可以直接应用于所有题目</li></ol><p>当且仅当表示充要条件，即A$\rightarrow$B，且B$\rightarrow$A</p><h2 id="三、逻辑论证"><a href="#三、逻辑论证" class="headerlink" title="三、逻辑论证"></a>三、逻辑论证</h2><h3 id="（1）削弱之否定论点"><a href="#（1）削弱之否定论点" class="headerlink" title="（1）削弱之否定论点"></a>（1）削弱之否定论点</h3><p>选题特征：与论点表述意思相反</p><p>文段特征：</p><ol><li>文段只有论点，无论据</li><li>文段的论点和论据话题一致</li></ol><h3 id="（2）削弱之拆桥"><a href="#（2）削弱之拆桥" class="headerlink" title="（2）削弱之拆桥"></a>（2）削弱之拆桥</h3><p>论点与论据之间没有必然联系</p><p>题型特质：</p><ol><li>论点和论据的话题不一致</li><li>提问方式为“削弱论证”</li><li>没有否论点的选项</li></ol><h3 id="（3）削弱之否定论据"><a href="#（3）削弱之否定论据" class="headerlink" title="（3）削弱之否定论据"></a>（3）削弱之否定论据</h3><p>题型特征：</p><ol><li>题干中支持方，反对方观点相反</li><li>题干中存在论点、论据，但无否论点和拆桥选项</li></ol><p>选项特征：与论据表述的意思相反</p><h3 id="（4）削弱之因果倒置和他因削弱"><a href="#（4）削弱之因果倒置和他因削弱" class="headerlink" title="（4）削弱之因果倒置和他因削弱"></a>（4）削弱之因果倒置和他因削弱</h3><p>题干特征：论点具有因果关系<br>选项特征：</p><ol><li>因果倒置：将论点中的因果关系顺序颠倒</li><li>他因削弱：在原来1的基础上，选项增加另一个同时存在的原因2也能导致相同的结果，削弱的是原来原因的重要性或唯一性</li></ol><h3 id="（5）加强之补充论据"><a href="#（5）加强之补充论据" class="headerlink" title="（5）加强之补充论据"></a>（5）加强之补充论据</h3><ol><li>解释原因：说明论点成立的原因</li><li>举例支持：证明论点成立的例子</li></ol><h3 id="（6）加强之搭桥"><a href="#（6）加强之搭桥" class="headerlink" title="（6）加强之搭桥"></a>（6）加强之搭桥</h3><p>题型特征：</p><ol><li>论点论据话题不一致</li><li>提问方式为前提、假设、必要条件、论证，优先考虑搭桥 </li></ol><h3 id="（7）加强之必要条件"><a href="#（7）加强之必要条件" class="headerlink" title="（7）加强之必要条件"></a>（7）加强之必要条件</h3><p>必要条件：选项为论点成立的必要条件</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-图形推理&quot;&gt;&lt;a href=&quot;#1-图形推理&quot; class=&quot;headerlink&quot; title=&quot;1 图形推理&quot;&gt;&lt;/a&gt;1 图形推理&lt;/h1&gt;&lt;h2 id=&quot;图形推理的命题形式&quot;&gt;&lt;a href=&quot;#图形推理的命题形式&quot; class=&quot;headerlink&quot; title=&quot;图形推理的命题形式&quot;&gt;&lt;/a&gt;图形推理的命题形式&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;一组图：从左往右读题，找整体规律的共同点。或间隔跳跃观察&lt;/li&gt;
&lt;li&gt;两组图：找第一组规律，应用于第二组&lt;/li&gt;
&lt;li&gt;九宫格：横行（最多）、数列、对角线观察规律&lt;/li&gt;
&lt;li&gt;分组分类：找寻每组统一规律&lt;/li&gt;
&lt;li&gt;空间类：折纸盒，转化成平面思维（截面图、三视图、立体拼合）&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="行测笔试" scheme="https://liangggggg.github.io/categories/%E8%A1%8C%E6%B5%8B%E7%AC%94%E8%AF%95/"/>
    
    
      <category term="行测笔试" scheme="https://liangggggg.github.io/tags/%E8%A1%8C%E6%B5%8B%E7%AC%94%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>学习日志：2020智慧海洋建设top5方案学习</title>
    <link href="https://liangggggg.github.io/2020/05/30/My-New-Post/"/>
    <id>https://liangggggg.github.io/2020/05/30/My-New-Post/</id>
    <published>2020-05-30T01:15:34.000Z</published>
    <updated>2020-06-04T02:25:15.553Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2020-5-30-赛题解读"><a href="#2020-5-30-赛题解读" class="headerlink" title="2020.5.30 赛题解读"></a>2020.5.30 赛题解读</h2><h3 id="赛题背景：渔船作业分类"><a href="#赛题背景：渔船作业分类" class="headerlink" title="赛题背景：渔船作业分类"></a>赛题背景：渔船作业分类</h3><p>本赛题基于位置数据对海上目标进行智能识别和作业行为分析，要求选手通过分析渔船北斗设备位置数据，得出该船的生产作业行为，具体判断出是拖网作业、围网作业还是流刺网作业。初赛将提供11000条(其中7000条训练数据、2000条testA、2000条testB)渔船轨迹北斗数据。</p><a id="more"></a><p>复赛考虑以往渔船在海上作业时主要依赖AIS数据，北斗相比AIS数据，数据上报频率和数据质量均低于AIS数据，因此复赛拟加入AIS轨迹数据辅助北斗数据更好的做渔船类型识别，其中AIS数据与北斗数据的匹配需选手自行实现，具体细节复赛开赛时更新。同时，希望选手通过数据可视化与分析，挖掘更多海洋通信导航设备的应用价值。</p><h3 id="竞赛数据"><a href="#竞赛数据" class="headerlink" title="竞赛数据:"></a>竞赛数据:</h3><p>提供11000条渔船北斗数据，数据包含脱敏后的渔船ID、经纬度坐标、上报时间、速度、航向信息，由于真实场景下海上环境复杂，经常出现信号丢失，设备故障等原因导致的上报坐标错误、上报数据丢失、甚至有些设备疯狂上报等。</p><p>数据示例：</p><table><thead><tr><th align="left">渔船ID</th><th align="center">x</th><th align="center">y</th><th align="center">速度</th><th align="center">方向</th><th align="center">time</th><th align="right">type</th></tr></thead><tbody><tr><td align="left">1102</td><td align="center">6283649.656204367</td><td align="center">5284013.963699763</td><td align="center">3</td><td align="center">12.1</td><td align="center">0921 09:00</td><td align="right">围网</td></tr></tbody></table><p>渔船ID：渔船的唯一识别，结果文件以此ID为标示</p><p>x: 渔船在平面坐标系的x轴坐标</p><p>y: 渔船在平面坐标系的y轴坐标</p><p>速度：渔船当前时刻航速，单位节</p><p>方向：渔船当前时刻航首向，单位度</p><p>time：数据上报时刻，单位月日 时：分</p><p>type：渔船label，作业类型</p><p>原始数据经过脱敏处理，渔船信息被隐去，坐标等信息精度和位置被转换偏移。<br>选手可通过学习围网、刺网、拖网等专业知识辅助大赛数据处理。<br>AIS数据</p><table><thead><tr><th align="left">ais_id</th><th align="center">lon</th><th align="center">lat</th><th align="center">速度</th><th align="center">航向</th><th align="right">time</th></tr></thead><tbody><tr><td align="left">110</td><td align="center">119.6705</td><td align="center">26.5938</td><td align="center">3</td><td align="center">12.1</td><td align="right">0921 09:00</td></tr></tbody></table><p>ais_id：AIS设备的唯一识别ID</p><h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><p>选手提交结果与实际渔船作业类型结果进行对比，以3种类别的各自F1值取平均做为评价指标，结果越大越好，具体计算公式如下：</p><p>$$Score ={F1_{围网}+F1_{刺网}+F1_{拖网}  \over 3}$$</p><p>$$F1 ={2\ast P\ast R\over P+R}$$</p><p>其中P为某类别的准确率，R为某类别的召回率，评测程序f1函数为sklearn.metrics.f1_score，average=’macro’。</p><h2 id="模型大致思路"><a href="#模型大致思路" class="headerlink" title="模型大致思路"></a>模型大致思路</h2><ul><li><p>将所有数据数据切入：速度等于0和非0，白天和黑夜，四个数据集对每艘船的速度，方向，xy进行统计。</p></li><li><p>采用TFIDF对速度和XY进行抽取特征并降维</p></li><li><p>采用自然语言思路对速度，xy进行嵌入</p></li><li><p>训练模型前采用Lightgbm进行初步的特征筛选</p></li><li><p>最后用Lightgbm进行模型训练</p></li></ul><h2 id="具体分析"><a href="#具体分析" class="headerlink" title="具体分析"></a>具体分析</h2><p><strong>1. 按照同一个渔船id速度为0和非0两部分进行分析</strong></p><p><img src="https://note.youdao.com/yws/api/personal/file/5045B84827DC4E5B87F4E56EE349769F?method=download&shareKey=7afd0c781b27434a8a4595a52bbd0861" alt></p><p>思路：</p><p>1、针对同一艘渔船，将其数据分为 速度为0和非0两个部分。分别统计该船在速度为0 和 非0情况下做可视化分析，观察经纬度xy、方向direction这些原始特征的变化情况（均值、方差、极值、峰度、偏度等统计特征）</p><p>2、根据1构建的特征，原始特征被构造出一系列统计特征，一种含义的特征会被分成速度为0和非0情况。根据这个特点，对这些特征进行一个比值处理。</p><p><strong>2. 渔船在白天和黑夜会按照同一个渔船id白天和黑夜两部分进行分析</strong></p><p>早6点整至晚8点整设置为白天(图标识Day)</p><p>晚8点整至早6点整设置为黑夜(图标识Night)</p><p><img src="https://note.youdao.com/yws/api/personal/file/5045B84827DC4E5B87F4E56EE349769F?method=download&shareKey=7afd0c781b27434a8a4595a52bbd0861" alt></p><p>思路：<br>1、    数据按照时间划分成白天和黑夜两部分，分别统计该船在不同时间做可视化分析，观察经纬度xy、方向direction这些原始特征的变化情况（均值、方差、极值、峰度、偏度等统计特征）</p><p>2、    根据1构造的两组时间特征，提取关键的速度speed、经纬度xy进行白天与黑夜特征的对比。</p><p><strong>3. 借鉴自然语言处理（NLP）角度去处理船的轨迹特征</strong></p><p>速度speed、经纬度xy按照作业时间排序，可以反映出每艘船的行为规律。而每种作业方式都有其内在的一些规律, 借鉴自然语言处理(NLP)的相关算法进行特征提取。利用nlp的算法对速度、经纬这些序列的学习，尝试挖掘出每艘船的行为特点。</p><p>思路一：TF-IDF + NMF(如图，从左到有分别是ngram=1, ngram=2,ngram=3，经过t-SNE降维的可视化结果)</p><p><img src="https://note.youdao.com/yws/api/personal/file/BAC79B4C1B3440D6BFF6A1D51AC8A0FF?method=download&shareKey=16b799d9748d761fab551bec75914030" alt></p><p>1、    使用不同的ngram去处理每个渔船的速度、经纬度数据，提取出每艘船的TF-IDF特征（ngram=1, 2, 3）。</p><p>2、    并利用非负矩阵分解(NMF)算法，对处理后的速度、经纬度进行降维生成一个主题分布向量。（此题目分成了8类）。</p><p>3、    对每个渔船的主题分布向量进行T-SNE降维，进行可视化。</p><h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><p>该代码主要包括三个文件</p><ul><li>feature_selector.py 特征选择文件</li><li>nmf_list.py 处理轨迹文件</li><li>model.py 模型文件</li></ul><h3 id="1-feature-selector-py代码分析："><a href="#1-feature-selector-py代码分析：" class="headerlink" title="1. feature_selector.py代码分析："></a><strong>1. feature_selector.py代码分析：</strong></h3><pre><code># numpy and pandas for data manipulationimport pandas as pdimport numpy as np# model used for feature importancesimport lightgbm as lgb# utility for early stopping with a validation setfrom sklearn.model_selection import train_test_split# visualizationsimport matplotlib.pyplot as pltimport seaborn as sns# memory managementimport gc# utilitiesfrom itertools import chainclass FeatureSelector():&quot;&quot;&quot;    这个类用于为机器学习或数据预处理执行特征选择实现五种不同的方法来识别要删除的特性1、查找丢失百分比大于指定阈值的列2、查找具有唯一值的列3、找出相关系数大于指定相关系数的相关变量4、从梯度增强机(gbm)中查找特性重要性为0.0的特性5、从gbm中查找不影响指定的累积特性重要性的低重要性特性参数--------data:dataframe    一个数据集，行中有观察值，列中有特性labels : array or series, default = None    数组标签用于训练机器学习模型，以发现特征重要性。它们可以是二进制标签    (如果任务是“分类”)或连续目标(如果任务是“回归”)。    如果没有提供标签，那么基于特征重要性的方法是不可用的。属性--------ops : dict    运行的操作字典和要删除的特性missing_stats : dataframe    所有特征的缺失值的比例record_missing : dataframe    缺失值在阈值以上的特征的缺失值的比例unique_stats: dataframe    所有特性的唯一值的个数record_single_unique: dataframe    记录具有唯一值的特性corr_matrix : dataframe    数据中所有特征之间的所有相关性record_collinear : dataframe    记录相关系数高于阈值的相关变量对feature_importances: dataframe    从梯度增强机的所有特征的重要性record_zero_importance: dataframe    根据gbm记录数据中的零重要性特征record_low_importance: dataframe    根据gbm记录不需要达到累积重要性阈值的最低重要性特征Notes--------    -所有5个操作都可以用identify_all方法运行。    -如果使用特性重要度，则对创建新列的分类变量使用one-hot编码&quot;&quot;&quot;    def __init__(self, data, labels=None):                    # 数据集和标签        self.data = data        self.labels = labels        if labels is None:            print(&apos;No labels provided. Feature importance based methods are not available.&apos;)            # 记录关于要删除的特性的信息            self.record_missing = None        self.record_single_unique = None        self.record_collinear = None        self.record_zero_importance = None        self.record_low_importance = None        self.missing_stats = None        self.unique_stats = None        self.corr_matrix = None        self.feature_importances = None        # 用于保存删除操作的字典        self.ops = {}        self.one_hot_correlated = False    def identify_missing(self, missing_threshold):        # 找到丢失值大于&apos; missing_threshold &apos;的部分特征        self.missing_threshold = missing_threshold        # 计算每一列特征的缺失率        missing_series = self.data.isnull().sum() / self.data.shape[0]        self.missing_stats = pd.DataFrame(missing_series).rename(columns = {&apos;index&apos;: &apos;feature&apos;, 0: &apos;missing_fraction&apos;})        # 将特征的缺失率排序        self.missing_stats = self.missing_stats.sort_values(&apos;missing_fraction&apos;, ascending = False)        #找到缺失百分比大于阈值的列        record_missing = pd.DataFrame(missing_series[missing_series &gt; missing_threshold]).reset_index().rename(columns =                                                                                                                    {&apos;index&apos;: &apos;feature&apos;,                                                                                                                     0: &apos;missing_fraction&apos;})        to_drop = list(record_missing[&apos;feature&apos;])        self.record_missing = record_missing        self.ops[&apos;missing&apos;] = to_drop        print(&apos;%d features with greater than %0.2f missing values.\n&apos; % (len(self.ops[&apos;missing&apos;]), self.missing_threshold))    def identify_single_unique(self):    # 查找只有一个唯一值的特征        # 计算每个列中的惟一计数        unique_counts = self.data.nunique()        self.unique_stats = pd.DataFrame(unique_counts).rename(columns = {&apos;index&apos;: &apos;feature&apos;, 0: &apos;nunique&apos;})        self.unique_stats = self.unique_stats.sort_values(&apos;nunique&apos;, ascending = True)        # 查找只有惟一计数的列        record_single_unique = pd.DataFrame(unique_counts[unique_counts == 1]).reset_index().rename(columns = {&apos;index&apos;: &apos;feature&apos;,                                                                                                                0: &apos;nunique&apos;})        to_drop = list(record_single_unique[&apos;feature&apos;])        self.record_single_unique = record_single_unique        self.ops[&apos;single_unique&apos;] = to_drop        print(&apos;%d features with a single unique value.\n&apos; % len(self.ops[&apos;single_unique&apos;]))    def identify_collinear(self, correlation_threshold, one_hot=False):        &quot;&quot;&quot;        找寻相关系数大于“correlation_threshold”的特征并删除        参数        --------        correlation_threshold : float between 0 and 1        one_hot : boolean, default = False        &quot;&quot;&quot;        self.correlation_threshold = correlation_threshold        self.one_hot_correlated = one_hot        # 计算每一列之间的相关性        if one_hot:            # one_hot编码            features = pd.get_dummies(self.data)            self.one_hot_features = [column for column in features.columns if column not in self.base_features]            # 向原始数据添加一个热编码数据            self.data_all = pd.concat([features[self.one_hot_features], self.data], axis = 1)            corr_matrix = pd.get_dummies(features).corr()        else:            corr_matrix = self.data.corr()        self.corr_matrix = corr_matrix        # 提取关联矩阵的上三角        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))        # 选择相关性高于阈值的特性         # 需要使用绝对值        to_drop = [column for column in upper.columns if any(upper[column].abs() &gt; correlation_threshold)]        # 保存线性相关特征        record_collinear = pd.DataFrame(columns = [&apos;drop_feature&apos;, &apos;corr_feature&apos;, &apos;corr_value&apos;])        # 遍历列以删除相关特性对        for column in to_drop:            # 找出相关特征            corr_features = list(upper.index[upper[column].abs() &gt; correlation_threshold])            # 找出相关系数            corr_values = list(upper[column][upper[column].abs() &gt; correlation_threshold])            drop_features = [column for _ in range(len(corr_features))]            # 记录信息(现在需要一个临时df)            temp_df = pd.DataFrame.from_dict({&apos;drop_feature&apos;: drop_features,                                                 &apos;corr_feature&apos;: corr_features,                                                 &apos;corr_value&apos;: corr_values})            #添加到dataframe            record_collinear = record_collinear.append(temp_df, ignore_index = True)        self.record_collinear = record_collinear        self.ops[&apos;collinear&apos;] = to_drop        print(&apos;%d features with a correlation magnitude greater than %0.2f.\n&apos; % (len(self.ops[&apos;collinear&apos;]), self.correlation_threshold))    def identify_zero_importance(self, task, eval_metric=None,                                  n_iterations=10, early_stopping = True):        &quot;&quot;&quot;        根据梯度增强机识别零重要性的特征。        gbm可以使用验证集进行早期停止训练，以防止过拟合。        在“n_iteration”上对特征重要性求平均值以减少方差。        参数         --------        eval_metric : string            评价指标用于梯度提升机的早期停止，如果&apos; early_stopped &apos;为真，则必须提供        task : string            机器学习任务，是“classification”还是“regression”        n_iterations : int, default = 10            gbm的训练迭代次数        early_stopping : boolean, default = True            是否在训练时使用提前停止与验证集        Notes        --------            - 在训练前热编码特征            - gbm没有针对任何特定任务进行优化，可能需要进行一些超参数调优            - 特性重要性，包括零重要性特性，可以在运行过程中改变        &quot;&quot;&quot;        if early_stopping and eval_metric is None:            raise ValueError(&quot;&quot;&quot;eval metric must be provided with early stopping. Examples include &quot;auc&quot; for classification or                             &quot;l2&quot; for regression.&quot;&quot;&quot;)        if self.labels is None:             raise ValueError(&quot;No training labels provided.&quot;)        # 热编码特征        features = pd.get_dummies(self.data)        self.one_hot_features = [column for column in features.columns if column not in self.base_features]        # 将热编码数据添加到原始数据中        self.data_all = pd.concat([features[self.one_hot_features], self.data], axis = 1)        # 提取特征名字        feature_names = list(features.columns)        # 转换成np array        features = np.array(features)        labels = np.array(self.labels).reshape((-1, ))        # 创建特征重要性数组        feature_importance_values = np.zeros(len(feature_names))        print(&apos;Training Gradient Boosting Model\n&apos;)        # 在每折中迭代        for _ in range(n_iterations):            if task == &apos;classification&apos;:                model = lgb.LGBMClassifier(n_estimators=1000, learning_rate = 0.05, verbose = -1)            elif task == &apos;regression&apos;:                model = lgb.LGBMRegressor(n_estimators=1000, learning_rate = 0.05, verbose = -1)            else:                raise ValueError(&apos;Task must be either &quot;classification&quot; or &quot;regression&quot;&apos;)            # 如果使用早期停止训练需要一个验证集            if early_stopping:                train_features, valid_features, train_labels, valid_labels = train_test_split(features, labels, test_size = 0.15, stratify=labels)                # 使用早停机制训练模型                model.fit(train_features, train_labels, eval_metric = eval_metric,                              eval_set = [(valid_features, valid_labels)],                              early_stopping_rounds = 100, verbose = -1)                # 清空内存                gc.enable()                del train_features, train_labels, valid_features, valid_labels                gc.collect()            else:                model.fit(features, labels)            # 记录特征重要性            feature_importance_values += model.feature_importances_ / n_iterations        feature_importances = pd.DataFrame({&apos;feature&apos;: feature_names, &apos;importance&apos;: feature_importance_values})        # 根据特征重要性排序        feature_importances = feature_importances.sort_values(&apos;importance&apos;, ascending = False).reset_index(drop = True)        # 归一化特征重要性        feature_importances[&apos;normalized_importance&apos;] = feature_importances[&apos;importance&apos;] / feature_importances[&apos;importance&apos;].sum()        feature_importances[&apos;cumulative_importance&apos;] = np.cumsum(feature_importances[&apos;normalized_importance&apos;])        # 提取特征重要性为0的特征        record_zero_importance = feature_importances[feature_importances[&apos;importance&apos;] == 0.0]        to_drop = list(record_zero_importance[&apos;feature&apos;])        self.feature_importances = feature_importances        self.record_zero_importance = record_zero_importance        self.ops[&apos;zero_importance&apos;] = to_drop        print(&apos;\n%d features with zero importance after one-hot encoding.\n&apos; % len(self.ops[&apos;zero_importance&apos;]))    def identify_low_importance(self, cumulative_importance):        &quot;&quot;&quot;        找到特征重要性低于“cumulative_importance”的特征        参数        --------        cumulative_importance : float between 0 and 1            重要性分数        &quot;&quot;&quot;        self.cumulative_importance = cumulative_importance        # 特征重要性需要在运行之前计算        if self.feature_importances is None:            raise NotImplementedError(&quot;&quot;&quot;Feature importances have not yet been determined.                                      Call the `identify_zero_importance` method first.&quot;&quot;&quot;)        # 将特征重要性排序        self.feature_importances = self.feature_importances.sort_values(&apos;cumulative_importance&apos;)        # 识别出特征重要性低于设定阈值的特征        record_low_importance = self.feature_importances[self.feature_importances[&apos;cumulative_importance&apos;] &gt; cumulative_importance]        to_drop = list(record_low_importance[&apos;feature&apos;])        self.record_low_importance = record_low_importance        self.ops[&apos;low_importance&apos;] = to_drop        print(&apos;%d features required for cumulative importance of %0.2f after one hot encoding.&apos; % (len(self.feature_importances) -                                                                            len(self.record_low_importance), self.cumulative_importance))        print(&apos;%d features do not contribute to cumulative importance of %0.2f.\n&apos; % (len(self.ops[&apos;low_importance&apos;]),                                                                                               self.cumulative_importance))    def identify_all(self, selection_params):        &quot;&quot;&quot;        使用所有五种方法来删除不需要的特征        参数        --------        selection_params : dict            在五种特征选择方法中使用的参数。            参数必须包含键[&apos;missing_threshold&apos;， &apos;correlation_threshold&apos;， &apos;eval_metric&apos;， &apos;task&apos;， &apos; collecative_importance &apos;]        # 检查所必要的参数        for param in [&apos;missing_threshold&apos;, &apos;correlation_threshold&apos;, &apos;eval_metric&apos;, &apos;task&apos;, &apos;cumulative_importance&apos;]:            if param not in selection_params.keys():                raise ValueError(&apos;%s is a required parameter for this method.&apos; % param)        # 实现五种方法        self.identify_missing(selection_params[&apos;missing_threshold&apos;])        self.identify_single_unique()        self.identify_collinear(selection_params[&apos;correlation_threshold&apos;])        self.identify_zero_importance(task = selection_params[&apos;task&apos;], eval_metric = selection_params[&apos;eval_metric&apos;])        self.identify_low_importance(selection_params[&apos;cumulative_importance&apos;])        # 查找要删除的特性的数量        self.all_identified = set(list(chain(*list(self.ops.values()))))        self.n_identified = len(self.all_identified)        print(&apos;%d total features out of %d identified for removal after one-hot encoding.\n&apos; % (self.n_identified,                                                                                                   self.data_all.shape[1]))     def check_removal(self, keep_one_hot=True):         &quot;&quot;&quot;         在删除前检查已识别的特征。返回一个列表的独特的功能识别。         &quot;&quot;&quot;        self.all_identified = set(list(chain(*list(self.ops.values()))))        print(&apos;Total of %d features identified for removal&apos; % len(self.all_identified))        if not keep_one_hot:            if self.one_hot_features is None:                print(&apos;Data has not been one-hot encoded&apos;)            else:                one_hot_to_remove = [x for x in self.one_hot_features if x not in self.all_identified]                print(&apos;%d additional one-hot features can be removed&apos; % len(one_hot_to_remove))        return list(self.all_identified)    def remove(self, methods, keep_one_hot = True):        &quot;&quot;&quot;        根据指定的方法从数据中删除特征。        参数        --------            methods : &apos;all&apos; or list of methods                可以是[&apos;missing&apos;， &apos;single_unique&apos;， &apos;collinear&apos;， &apos;zero_importance&apos;， &apos;low_importance&apos;]            keep_one_hot : boolean, default = True                是否热编码        返回        --------            data : dataframe                删除了特征的数据        Notes         --------            -如果使用特性重要度，则一个热编码列将被添加到数据中(然后可能被删除)            -在转换数据之前，检查将被删除的功能!        features_to_drop = []        if methods == &apos;all&apos;:            # 热编码数据            data = self.data_all            print(&apos;{} methods have been run\n&apos;.format(list(self.ops.keys())))            # 找到需要删除的特征            features_to_drop = set(list(chain(*list(self.ops.values()))))        else:            # Need to use one-hot encoded data as well            if &apos;zero_importance&apos; in methods or &apos;low_importance&apos; in methods or self.one_hot_correlated:                data = self.data_all            else:                data = self.data            # 遍历指定方法            for method in methods:                # 确定方法已经在运行                if method not in self.ops.keys():                    raise NotImplementedError(&apos;%s method has not been run&apos; % method)                # 添加要删除的方法                else:                    features_to_drop.append(self.ops[method])            # 找到要删除的特征            features_to_drop = set(list(chain(*features_to_drop)))        features_to_drop = list(features_to_drop)        if not keep_one_hot:            if self.one_hot_features is None:                print(&apos;Data has not been one-hot encoded&apos;)            else:                features_to_drop = list(set(features_to_drop) | set(self.one_hot_features))        # 在原数据中删除特征        data = data.drop(columns = features_to_drop)        self.removed_features = features_to_drop        if not keep_one_hot:            print(&apos;Removed %d features including one-hot features.&apos; % len(features_to_drop))         else:            print(&apos;Removed %d features.&apos; % len(features_to_drop))        return data    # 各种绘图函数    def plot_missing(self):        &quot;&quot;&quot;Histogram of missing fraction in each feature&quot;&quot;&quot;        if self.record_missing is None:            raise NotImplementedError(&quot;Missing values have not been calculated. Run `identify_missing`&quot;)        self.reset_plot()        # Histogram of missing values        plt.style.use(&apos;seaborn-white&apos;)        plt.figure(figsize = (7, 5))        plt.hist(self.missing_stats[&apos;missing_fraction&apos;], bins = np.linspace(0, 1, 11), edgecolor = &apos;k&apos;, color = &apos;red&apos;, linewidth = 1.5)        plt.xticks(np.linspace(0, 1, 11));        plt.xlabel(&apos;Missing Fraction&apos;, size = 14); plt.ylabel(&apos;Count of Features&apos;, size = 14);         plt.title(&quot;Fraction of Missing Values Histogram&quot;, size = 16);    def plot_unique(self):        &quot;&quot;&quot;Histogram of number of unique values in each feature&quot;&quot;&quot;        if self.record_single_unique is None:            raise NotImplementedError(&apos;Unique values have not been calculated. Run `identify_single_unique`&apos;)        self.reset_plot()        # Histogram of number of unique values        self.unique_stats.plot.hist(edgecolor = &apos;k&apos;, figsize = (7, 5))        plt.ylabel(&apos;Frequency&apos;, size = 14); plt.xlabel(&apos;Unique Values&apos;, size = 14);         plt.title(&apos;Number of Unique Values Histogram&apos;, size = 16);    def plot_collinear(self, plot_all = False):        &quot;&quot;&quot;        Heatmap of the correlation values. If plot_all = True plots all the correlations otherwise        plots only those features that have a correlation above the threshold        Notes        --------            - Not all of the plotted correlations are above the threshold because this plots            all the variables that have been idenfitied as having even one correlation above the threshold            - The features on the x-axis are those that will be removed. The features on the y-axis            are the correlated features with those on the x-axis        Code adapted from https://seaborn.pydata.org/examples/many_pairwise_correlations.html        &quot;&quot;&quot;        if self.record_collinear is None:            raise NotImplementedError(&apos;Collinear features have not been idenfitied. Run `identify_collinear`.&apos;)        if plot_all:            corr_matrix_plot = self.corr_matrix            title = &apos;All Correlations&apos;        else:            # Identify the correlations that were above the threshold            # columns (x-axis) are features to drop and rows (y_axis) are correlated pairs            corr_matrix_plot = self.corr_matrix.loc[list(set(self.record_collinear[&apos;corr_feature&apos;])),                                                     list(set(self.record_collinear[&apos;drop_feature&apos;]))]            title = &quot;Correlations Above Threshold&quot;        f, ax = plt.subplots(figsize=(10, 8))        # Diverging colormap        cmap = sns.diverging_palette(220, 10, as_cmap=True)        # Draw the heatmap with a color bar        sns.heatmap(corr_matrix_plot, cmap=cmap, center=0,                    linewidths=.25, cbar_kws={&quot;shrink&quot;: 0.6})        # Set the ylabels         ax.set_yticks([x + 0.5 for x in list(range(corr_matrix_plot.shape[0]))])        ax.set_yticklabels(list(corr_matrix_plot.index), size = int(160 / corr_matrix_plot.shape[0]));        # Set the xlabels         ax.set_xticks([x + 0.5 for x in list(range(corr_matrix_plot.shape[1]))])        ax.set_xticklabels(list(corr_matrix_plot.columns), size = int(160 / corr_matrix_plot.shape[1]));        plt.title(title, size = 14)    def plot_feature_importances(self, plot_n = 15, threshold = None):        &quot;&quot;&quot;        Plots `plot_n` most important features and the cumulative importance of features.        If `threshold` is provided, prints the number of features needed to reach `threshold` cumulative importance.        Parameters        --------        plot_n : int, default = 15            Number of most important features to plot. Defaults to 15 or the maximum number of features whichever is smaller        threshold : float, between 0 and 1 default = None            Threshold for printing information about cumulative importances        &quot;&quot;&quot;        if self.record_zero_importance is None:            raise NotImplementedError(&apos;Feature importances have not been determined. Run `idenfity_zero_importance`&apos;)        # Need to adjust number of features if greater than the features in the data        if plot_n &gt; self.feature_importances.shape[0]:            plot_n = self.feature_importances.shape[0] - 1        self.reset_plot()        # Make a horizontal bar chart of feature importances        plt.figure(figsize = (10, 6))        ax = plt.subplot()        # Need to reverse the index to plot most important on top        # There might be a more efficient method to accomplish this        ax.barh(list(reversed(list(self.feature_importances.index[:plot_n]))),                 self.feature_importances[&apos;normalized_importance&apos;][:plot_n],                 align = &apos;center&apos;, edgecolor = &apos;k&apos;)        # Set the yticks and labels        ax.set_yticks(list(reversed(list(self.feature_importances.index[:plot_n]))))        ax.set_yticklabels(self.feature_importances[&apos;feature&apos;][:plot_n], size = 12)        # Plot labeling        plt.xlabel(&apos;Normalized Importance&apos;, size = 16); plt.title(&apos;Feature Importances&apos;, size = 18)        plt.show()        # Cumulative importance plot        plt.figure(figsize = (6, 4))        plt.plot(list(range(1, len(self.feature_importances) + 1)), self.feature_importances[&apos;cumulative_importance&apos;], &apos;r-&apos;)        plt.xlabel(&apos;Number of Features&apos;, size = 14); plt.ylabel(&apos;Cumulative Importance&apos;, size = 14);         plt.title(&apos;Cumulative Feature Importance&apos;, size = 16);        if threshold:            # Index of minimum number of features needed for cumulative importance threshold            # np.where returns the index so need to add 1 to have correct number            importance_index = np.min(np.where(self.feature_importances[&apos;cumulative_importance&apos;] &gt; threshold))            plt.vlines(x = importance_index + 1, ymin = 0, ymax = 1, linestyles=&apos;--&apos;, colors = &apos;blue&apos;)            plt.show();            print(&apos;%d features required for %0.2f of cumulative importance&apos; % (importance_index + 1, threshold))    def reset_plot(self):        plt.rcParams = plt.rcParamsDefault</code></pre><h3 id="2-nmf-list-py-代码分析："><a href="#2-nmf-list-py-代码分析：" class="headerlink" title="2. nmf_list.py 代码分析："></a><strong>2. nmf_list.py 代码分析：</strong></h3><pre><code>import pickleimport numpy as npimport pandas as pdfrom collections import Counterfrom sklearn.decomposition import NMFfrom sklearn.preprocessing import LabelEncoderfrom sklearn.feature_extraction.text import TfidfVectorizerimport tqdmfrom gensim.models import FastText, Word2Vecimport multiprocessingclass nmf_list(object):    def __init__(self,data,by_name,to_list,nmf_n,top_n):        self.data = data        self.by_name = by_name        self.to_list = to_list        self.nmf_n = nmf_n        self.top_n = top_n    def run(self,tf_n):        df_all = self.data.groupby(self.by_name)[self.to_list].apply(lambda x :&apos;|&apos;.join(x)).reset_index()        self.data =df_all.copy()        print(&apos;bulid word_fre&apos;)    # 词频的构建    def word_fre(x):        word_dict = []        x = x.split(&apos;|&apos;)        docs = []        for doc in x:            doc = doc.split()            docs.append(doc)            word_dict.extend(doc)        word_dict = Counter(word_dict)        new_word_dict = {}        for key,value in word_dict.items():            new_word_dict[key] = [value,0]        del word_dict          del x        for doc in docs:            doc = Counter(doc)            for word in doc.keys():                new_word_dict[word][1] += 1        return new_word_dict     self.data[&apos;word_fre&apos;] = self.data[self.to_list].apply(word_fre)    print(&apos;bulid top_&apos; + str(self.top_n))    # 设定100个高频词    def top_100(word_dict):        return sorted(word_dict.items(),key = lambda x:(x[1][1],x[1][0]),reverse = True)[:self.top_n]    self.data[&apos;top_&apos;+str(self.top_n)] = self.data[&apos;word_fre&apos;].apply(top_100)    def top_100_word(word_list):        words = []        for i in word_list:            i = list(i)            words.append(i[0])        return words     self.data[&apos;top_&apos;+str(self.top_n)+&apos;_word&apos;] = self.data[&apos;top_&apos; + str(self.top_n)].apply(top_100_word)    # print(&apos;top_&apos;+str(self.top_n)+&apos;_word的shape&apos;)    print(self.data.shape)    word_list = []    for i in self.data[&apos;top_&apos;+str(self.top_n)+&apos;_word&apos;].values:        word_list.extend(i)    word_list = Counter(word_list)    word_list = sorted(word_list.items(),key = lambda x:x[1],reverse = True)    user_fre = []    for i in word_list:        i = list(i)        user_fre.append(i[1]/self.data[self.by_name].nunique())    stop_words = []    for i,j in zip(word_list,user_fre):        if j&gt;0.5:            i = list(i)            stop_words.append(i[0])    print(&apos;start title_feature&apos;)    # 讲融合后的taglist当作一句话进行文本处理    self.data[&apos;title_feature&apos;] = self.data[self.to_list].apply(lambda x: x.split(&apos;|&apos;))    self.data[&apos;title_feature&apos;] = self.data[&apos;title_feature&apos;].apply(lambda line: [w for w in line if w not in stop_words])    self.data[&apos;title_feature&apos;] = self.data[&apos;title_feature&apos;].apply(lambda x: &apos; &apos;.join(x))    print(&apos;start NMF&apos;)    # 使用tfidf对元素进行处理    tfidf_vectorizer = TfidfVectorizer(ngram_range=(tf_n,tf_n))    tfidf = tfidf_vectorizer.fit_transform(self.data[&apos;title_feature&apos;].values)    #使用nmf算法，提取文本的主题分布    text_nmf = NMF(n_components=self.nmf_n).fit_transform(tfidf)    # 整理并输出文件    name = [str(tf_n) + self.to_list + &apos;_&apos; +str(x) for x in range(1,self.nmf_n+1)]    tag_list = pd.DataFrame(text_nmf)    print(tag_list.shape)    tag_list.columns = name    tag_list[self.by_name] = self.data[self.by_name]    column_name = [self.by_name] + name    tag_list = tag_list[column_name]    return tag_list</code></pre><h3 id="3-model-py-代码分析："><a href="#3-model-py-代码分析：" class="headerlink" title="3. model.py  代码分析："></a><strong>3. model.py  代码分析：</strong></h3><pre><code>import gcimport pandas as pdimport numpy as npimport osimport timeimport lightgbm as lgbfrom copy import deepcopyfrom sklearn.model_selection import StratifiedKFoldfrom sklearn.metrics import f1_scorefrom sklearn import metricsfrom sklearn.metrics import precision_recall_fscore_supportimport warningsfrom glob import globfrom scipy.sparse import csr_matrixstart_t = time.time()print(&apos;ww_900_start&apos;)pd.set_option(&apos;display.max_columns&apos;, 100)warnings.filterwarnings(&apos;ignore&apos;)# 添加需要提取的特征def group_feature(df, key, target, aggs,flag):       agg_dict = {}    for ag in aggs:        agg_dict[&apos;{}_{}_{}&apos;.format(target,ag,flag)] = ag    print(agg_dict)    t = df.groupby(key)[target].agg(agg_dict).reset_index()    return t# 计算两个经纬度之间的haversine距离def haversine_dist(lat1,lng1,lat2,lng2):    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))    radius = 6371  # Earth&apos;s radius taken from google    lat = lat2 - lat1    lng = lng2 - lng1    d = np.sin(lat/2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng/2) ** 2    h = 2 * radius * np.arcsin(np.sqrt(d))    return h# 提取特征def extract_feature(df, train, flag):    if (flag == &apos;on_night&apos;) or (flag == &apos;on_day&apos;):         t = group_feature(df, &apos;ship&apos;,&apos;speed&apos;,[&apos;max&apos;,&apos;mean&apos;,&apos;median&apos;,&apos;std&apos;,&apos;skew&apos;],flag)        train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)    if flag == &quot;0&quot;:        t = group_feature(df, &apos;ship&apos;,&apos;direction&apos;,[&apos;max&apos;,&apos;median&apos;,&apos;mean&apos;,&apos;std&apos;,&apos;skew&apos;],flag)        train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)     elif flag == &quot;1&quot;:        t = group_feature(df, &apos;ship&apos;,&apos;speed&apos;,[&apos;max&apos;,&apos;mean&apos;,&apos;median&apos;,&apos;std&apos;,&apos;skew&apos;],flag)        train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)        t = group_feature(df, &apos;ship&apos;,&apos;direction&apos;,[&apos;max&apos;,&apos;median&apos;,&apos;mean&apos;,&apos;std&apos;,&apos;skew&apos;],flag)        train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)         hour_nunique = df.groupby(&apos;ship&apos;)[&apos;speed&apos;].nunique().to_dict()        train[&apos;speed_nunique_{}&apos;.format(flag)] = train[&apos;ship&apos;].map(hour_nunique)           hour_nunique = df.groupby(&apos;ship&apos;)[&apos;direction&apos;].nunique().to_dict()        train[&apos;direction_nunique_{}&apos;.format(flag)] = train[&apos;ship&apos;].map(hour_nunique)      t = group_feature(df, &apos;ship&apos;,&apos;x&apos;,[&apos;max&apos;,&apos;min&apos;,&apos;mean&apos;,&apos;median&apos;,&apos;std&apos;,&apos;skew&apos;],flag)    train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)    t = group_feature(df, &apos;ship&apos;,&apos;y&apos;,[&apos;max&apos;,&apos;min&apos;,&apos;mean&apos;,&apos;median&apos;,&apos;std&apos;,&apos;skew&apos;],flag)    train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)    t = group_feature(df, &apos;ship&apos;,&apos;base_dis_diff&apos;,[&apos;max&apos;,&apos;min&apos;,&apos;mean&apos;,&apos;std&apos;,&apos;skew&apos;],flag)    train = pd.merge(train, t, on=&apos;ship&apos;, how=&apos;left&apos;)    train[&apos;x_max_x_min_{}&apos;.format(flag)] = train[&apos;x_max_{}&apos;.format(flag)] - train[&apos;x_min_{}&apos;.format(flag)]    train[&apos;y_max_y_min_{}&apos;.format(flag)] = train[&apos;y_max_{}&apos;.format(flag)] - train[&apos;y_min_{}&apos;.format(flag)]    train[&apos;y_max_x_min_{}&apos;.format(flag)] = train[&apos;y_max_{}&apos;.format(flag)] - train[&apos;x_min_{}&apos;.format(flag)]    train[&apos;x_max_y_min_{}&apos;.format(flag)] = train[&apos;x_max_{}&apos;.format(flag)] - train[&apos;y_min_{}&apos;.format(flag)]    train[&apos;slope_{}&apos;.format(flag)] = train[&apos;y_max_y_min_{}&apos;.format(flag)] / np.where(train[&apos;x_max_x_min_{}&apos;.format(flag)]==0, 0.001, train[&apos;x_max_x_min_{}&apos;.format(flag)])    train[&apos;area_{}&apos;.format(flag)] = train[&apos;x_max_x_min_{}&apos;.format(flag)] * train[&apos;y_max_y_min_{}&apos;.format(flag)]    mode_hour = df.groupby(&apos;ship&apos;)[&apos;hour&apos;].agg(lambda x:x.value_counts().index[0]).to_dict()    train[&apos;mode_hour_{}&apos;.format(flag)] = train[&apos;ship&apos;].map(mode_hour)    train[&apos;slope_median_{}&apos;.format(flag)] = train[&apos;y_median_{}&apos;.format(flag)] / np.where(train[&apos;x_median_{}&apos;.format(flag)]==0, 0.001, train[&apos;x_median_{}&apos;.format(flag)])    return train# 提取数据def get_data(files, is_sort=True, sort_column=&quot;time&quot;):    datas = [pd.read_csv(f) for f in files]    if is_sort:        dfs = [df.sort_values(by=sort_column, ascending=True, na_position=&apos;last&apos;) for df in datas]    df = pd.concat(datas, axis=0, ignore_index=True)    return df# 处理提取文件数据def extract_dt(df):    df[&apos;time&apos;] = pd.to_datetime(df[&apos;time&apos;], format=&apos;%m%d %H:%M:%S&apos;)    df[&apos;date&apos;] = df[&apos;time&apos;].dt.date    df[&apos;hour&apos;] = df[&apos;time&apos;].dt.hour    df[&apos;x_dis_diff&apos;] = (df[&apos;x&apos;] - 6165599).abs()    df[&apos;y_dis_diff&apos;] = (df[&apos;y&apos;] - 5202660).abs()    df[&apos;base_dis_diff&apos;] = ((df[&apos;x_dis_diff&apos;]**2)+(df[&apos;y_dis_diff&apos;]**2))**0.5        del df[&apos;x_dis_diff&apos;],df[&apos;y_dis_diff&apos;]        df[&quot;x&quot;] = df[&quot;x&quot;] / 1e6    df[&quot;y&quot;] = df[&quot;y&quot;] / 1e6        df[&apos;day_nig&apos;] = 0    df.loc[(df[&apos;hour&apos;] &gt; 5) &amp; (df[&apos;hour&apos;] &lt; 20),&apos;day_nig&apos;] = 1    return dftrain_files = glob(&quot;tcdata/hy_round2_train_20200225/*.csv&quot;)test_files = glob(&quot;tcdata/hy_round2_testB_20200312/*.csv&quot;)train_files = sorted(train_files)test_files = sorted(test_files)train = get_data(train_files)train.columns = [&apos;ship&apos;,&apos;x&apos;,&apos;y&apos;,&apos;speed&apos;,&apos;direction&apos;,&apos;time&apos;,&apos;type&apos;]test = get_data(test_files)test.columns = [&apos;ship&apos;,&apos;x&apos;,&apos;y&apos;,&apos;speed&apos;,&apos;direction&apos;,&apos;time&apos;]train = extract_dt(train)test = extract_dt(test)train_label = train.drop_duplicates([&apos;ship&apos;],keep = &apos;first&apos;)test_label = test.drop_duplicates([&apos;ship&apos;],keep = &apos;first&apos;)train_label[&apos;type&apos;] = train_label[&apos;type&apos;].map({&apos;围网&apos;:0,&apos;刺网&apos;:1,&apos;拖网&apos;:2})num = train_label.shape[0]data_label = train_label.append(test_label)data =train.append(test)# 将数据分成speed为0和非0、白天和晚上data_1 = data[data[&apos;speed&apos;]==0]data_2 = data[data[&apos;speed&apos;]!=0]data_label = extract_feature(data_1, data_label,&quot;0&quot;)data_label = extract_feature(data_2, data_label,&quot;1&quot;)data_1 = data[data[&apos;day_nig&apos;] == 0]data_2 = data[data[&apos;day_nig&apos;] == 1]data_label = extract_feature(data_1, data_label,&quot;on_night&quot;)data_label = extract_feature(data_2, data_label,&quot;on_day&quot;)# 读取NMF降维后的特征if os.path.isfile(&apos;nmf_testb.csv&apos;):    nmf_fea = pd.read_csv(&apos;nmf_testb.csv&apos;)    data_label = data_label.merge(nmf_fea,on=&apos;ship&apos;,how = &apos;left&apos;)    del nmf_feaelse:    for j in range(1,4):        print(&apos;********* {} *******&apos;.format(j))        for i in [&apos;speed&apos;,&apos;x&apos;,&apos;y&apos;]:            data[i + &apos;_str&apos;] = data[i].astype(str)            from nmf_list import nmf_list            nmf = nmf_list(data,&apos;ship&apos;,i + &apos;_str&apos;,8,2)            nmf_a = nmf.run(j)            data_label = data_label.merge(nmf_a,on = &apos;ship&apos;,how = &apos;left&apos;)first = &quot;0&quot;second = &quot;1&quot;data_label[&apos;direction_median_ratio&apos;] = data_label[&apos;direction_median_{}&apos;.format(second)] / data_label[&apos;direction_median_{}&apos;.format(first)]data_label[&apos;slope_ratio&apos;] = data_label[&apos;slope_{}&apos;.format(second)] / data_label[&apos;slope_{}&apos;.format(first)] data_label[&apos;slope_mean_ratio&apos;] = data_label[&apos;slope_median_{}&apos;.format(second)] / data_label[&apos;slope_median_{}&apos;.format(first)]first = &quot;on_night&quot;second = &quot;on_day&quot;data_label[&apos;speed_median_ratio&apos;] = data_label[&apos;speed_median_{}&apos;.format(second)] / data_label[&apos;speed_median_{}&apos;.format(first)] data_label[&apos;speed_std_ratio&apos;] = data_label[&apos;speed_std_{}&apos;.format(second)] / data_label[&apos;speed_std_{}&apos;.format(first)] # 计算特征flag = &apos;all&apos;for cc in [&apos;direction&apos;,&apos;speed&apos;]:    t = group_feature(data_label,cc, &apos;ship&apos;,[&apos;count&apos;],flag +cc+ &apos;x&apos;)    data_label = pd.merge(data_label, t, on=cc, how=&apos;left&apos;)  for i in [&quot;0&quot;,&quot;1&quot;]:    if i == &quot;1&quot;:        for j in [#                 &apos;slope_speed_cat_nunique_{}&apos;.format(i),#                   &apos;slope_mean_speed_cat_nunique_{}&apos;.format(i),                  &apos;speed_nunique_{}&apos;.format(i),                  &apos;direction_nunique_{}&apos;.format(i)                 ]:            t = group_feature(data_label,j, &apos;ship&apos;,[&apos;count&apos;],j+&quot;_count&quot;)            data_label = pd.merge(data_label, t, on=j, how=&apos;left&apos;)     for j in [           &apos;slope_median_{}&apos;.format(i),#               &apos;x_max_x_min_{}&apos;.format(i),#               &apos;y_max_y_min_{}&apos;.format(i)             ]:#         t = group_feature(data_label,j, &apos;ship&apos;,[&apos;count&apos;],j+&quot;_count&quot;)#         data_label = pd.merge(data_label, t, on=j, how=&apos;left&apos;)         t = group_feature(data_label,j, &apos;speed&apos;,[&apos;min&apos;,&apos;max&apos;,&apos;median&apos;,&apos;std&apos;,&apos;skew&apos;],j+&quot;_tongji&quot;)        data_label = pd.merge(data_label, t, on=j, how=&apos;left&apos;)        # t = group_feature(data_label,j, &apos;direction&apos;,[&apos;min&apos;,&apos;max&apos;,&apos;median&apos;,&apos;std&apos;,&apos;skew&apos;],j+&quot;_tongji&quot;)        # data_label = pd.merge(data_label, t, on=j, how=&apos;left&apos;)def cut_bins(raw_data, col_name=None, q=49):    features, bins = pd.qcut(raw_data[col_name], q=q, retbins=True, duplicates=&quot;drop&quot;)    labels = list(range(len(bins) - 1))    features, bins = pd.qcut(raw_data[col_name], labels=labels, q=q, retbins=True, duplicates=&quot;drop&quot;)    return features, bins, labelsMAX_CATE = 199data[&quot;x_cate&quot;], x_bins, x_labels = cut_bins(data, col_name=&quot;x&quot;, q=MAX_CATE)data[&quot;y_cate&quot;], y_bins, y_labels = cut_bins(data, col_name=&quot;y&quot;, q=MAX_CATE)# data[&quot;x_sub_y_cate&quot;], x_sub_y_bins, x_sub_y_labels = cut_bins(data, col_name=&quot;x_sub_y&quot;, q=MAX_CATE)data[&quot;distance_cate&quot;], dist_bins, dist_labels = cut_bins(data, col_name=&quot;base_dis_diff&quot;, q=MAX_CATE)data[&quot;speed_cate&quot;], speed_bins, speed_labels = cut_bins(data, col_name=&quot;speed&quot;, q=MAX_CATE)MAX_CATE = 120data[&quot;direct_cate&quot;], speed_bins, speed_labels = cut_bins(data, col_name=&quot;direction&quot;, q=MAX_CATE)if os.path.isfile(&apos;emb_testb.csv&apos;):    w2v_fea = pd.read_csv(&apos;emb_testb.csv&apos;)    data_label = data_label.merge(w2v_fea, on=&apos;ship&apos;, how=&apos;left&apos;)    del w2v_feaelse:    from gensim.models import Word2Vec    import gc    def emb(df, f1, f2):        emb_size = 23        print(&apos;====================================== {} {} ======================================&apos;.format(f1, f2))        tmp = df.groupby(f1, as_index=False)[f2].agg({&apos;{}_{}_list&apos;.format(f1, f2): list})        sentences = tmp[&apos;{}_{}_list&apos;.format(f1, f2)].values.tolist()        del tmp[&apos;{}_{}_list&apos;.format(f1, f2)]        for i in range(len(sentences)):            sentences[i] = [str(x) for x in sentences[i]]        model = Word2Vec(sentences, size=emb_size, window=5, min_count=3, sg=0, hs=1, seed=2222)        emb_matrix = []        for seq in sentences:            vec = []            for w in seq:                if w in model:                    vec.append(model[w])            if len(vec) &gt; 0:                emb_matrix.append(np.mean(vec, axis=0))            else:                emb_matrix.append([0] * emb_size)        emb_matrix = np.array(emb_matrix)        for i in range(emb_size):            tmp[&apos;{}_{}_emb_{}&apos;.format(f1, f2, i)] = emb_matrix[:, i]        del model, emb_matrix, sentences        return tmp    emb_cols = [        [&apos;ship&apos;, &apos;x_cate&apos;],        [&apos;ship&apos;, &apos;y_cate&apos;],        [&apos;ship&apos;, &apos;speed_cate&apos;],        [&apos;ship&apos;, &apos;distance_cate&apos;],        # [&apos;ship&apos;, &apos;direct_cate&apos;],    ]    for f1, f2 in emb_cols:        data_label = data_label.merge(emb(data, f1, f2), on=f1, how=&apos;left&apos;)    gc.collect()    # emb_list = [&apos;ship&apos;]    # for i in data_label.columns:    #     if &apos;_emb_&apos; in i:    #         emb_list.append(i)    # data_label[emb_list].to_csv(&apos;emb_testb.csv&apos;,index=False)print(&apos;feature done&apos;)train_label = data_label[:num]test_label = data_label[num:]features = [x for x in train_label.columns if x not in [&apos;ship&apos;,&apos;type&apos;,&apos;time&apos;,&apos;x&apos;,&apos;y&apos;,&apos;diff_time&apos;,&apos;date&apos;,&apos;day_nig&apos;,&apos;direction&apos;,&apos;speed&apos;,&apos;hour&apos;,                                                       &apos;speed_many&apos;,&apos;dire_diff&apos;,&apos;direction_str&apos;,&apos;speed_str&apos;,&apos;dis&apos;,&apos;x_speed&apos;,&apos;y_speed&apos;] ]target = &apos;type&apos;# 特征选择from feature_selector import FeatureSelectorfs = FeatureSelector(data = train_label[features], labels = train_label[target])fs.identify_zero_importance(task = &apos;classification&apos;, eval_metric = &apos;multiclass&apos;,                            n_iterations = 10, early_stopping = True)fs.identify_low_importance(cumulative_importance = 0.97)low_importance_features = fs.ops[&apos;low_importance&apos;]print(&apos;====low_importance_features=====&apos;)print(low_importance_features)for i in low_importance_features:features.remove(i)print(&apos;feature number&apos;,len(features))gc.collect()# 评价指标def macro_f1(y_hat, data):    y_true = data.get_label()    y_hat = y_hat.reshape(-1, y_true.shape[0])    y_hat = np.argmax(y_hat, axis=0)    f1_multi = precision_recall_fscore_support(y_true, y_hat, labels=[0, 1, 2])[2]    f1_macro =  f1_score(y_true, y_hat, average =&quot;macro&quot;)    assert np.mean(f1_multi) ==  f1_macro    return &apos;f1&apos;, f1_macro, Truedef f1_single(y_hat, data, index=0):    y_true = data.get_label()    y_hat = y_hat.reshape(-1, y_true.shape[0])    y_hat = np.argmax(y_hat, axis=0)    f1_multi = precision_recall_fscore_support(y_true, y_hat, labels=[0, 1, 2])[2]    f1_s = round(f1_multi[index], 4)    return &apos;f1_{}&apos;.format(index), f1_s, True# 构造模型train_X = train_label[features]test_X = test_label[features]print(train_X.shape, test_X.shape)train_y = train_label[target]params = {        &apos;task&apos;:&apos;train&apos;,         &apos;num_leaves&apos;: 63,        &apos;objective&apos;: &apos;multiclass&apos;,        &apos;num_class&apos;: 3,        &apos;metric&apos;: &apos;None&apos;, # [f1_0, f1_1, f1_2],        &apos;min_data_in_leaf&apos;: 10,        &apos;learning_rate&apos;: 0.01,        &apos;feature_fraction&apos;: 0.7,        &apos;bagging_fraction&apos;: 0.95,        &apos;early_stopping_rounds&apos;: 2000,#         &apos;lambda_l1&apos;: 0.1,#         &apos;lambda_l2&apos;: 0.1,        &quot;first_metric_only&quot;: True,        &apos;bagging_freq&apos;: 3,         &apos;max_bin&apos;: 255,        &apos;random_state&apos;: 42,        &apos;verbose&apos; : -1    }models = []test_preds = []val_preds = []oof_seed = np.zeros((len(train_label), 3))seed = [2222,2018778]for j in seed:    print(&quot;+++++++++++++++++ seed {} ++++++++++++&quot;.format(str(j)))    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=j)    oof = np.zeros((len(train_label), 3))    for i, (trn_idx, val_idx) in enumerate(skf.split(train_X, train_y)):        print(&quot;-&quot; * 81)        print(&quot;[!] fold {}&quot;.format(i))        lgb_params = deepcopy(params)        # print(lgb_params)        trn_X = csr_matrix(train_X)[trn_idx]        trn_y = train_y.iloc[trn_idx]        val_X = csr_matrix(train_X)[val_idx]        val_y = train_y.iloc[val_idx]        dtrain = lgb.Dataset(trn_X, trn_y)         dval = lgb.Dataset(val_X, val_y)         model = lgb.train(lgb_params,                dtrain,                num_boost_round=400000,               valid_sets=[dval],                feval=lambda preds, train_data: [                   macro_f1(preds, train_data),                   f1_single(preds, train_data, index=0),                   f1_single(preds, train_data, index=1),                   f1_single(preds, train_data, index=2)],               verbose_eval=-1)        models.append(model)        # print(model.best_iteration)        val_pred = model.predict(val_X, iteration=model.best_iteration)        oof[val_idx] = val_pred        val_y = train_y.iloc[val_idx]        val_pred = np.argmax(val_pred, axis=1)        print(str(i), &apos;val f1&apos;, metrics.f1_score(val_y, val_pred, average=&apos;macro&apos;))        test_preds.append(model.predict(test_X, iteration=model.best_iteration))        print(&quot;[!] fold {} finish\n&quot;.format(i))        del dtrain, dval        gc.collect()    val_pred = np.argmax(oof, axis=1)    print(str(j), &apos;every_flod val f1&apos;, metrics.f1_score(train_y, val_pred, average=&apos;macro&apos;))    oof_seed += oof/len(seed)oof1 = np.argmax(oof_seed, axis=1)print(&apos;oof f1&apos;, metrics.f1_score(oof1,train_y, average=&apos;macro&apos;))val_score = np.round(metrics.f1_score(oof1, train_y, average=&apos;macro&apos;),6)def ensemble_predictions(predictions, weights=None, type_=&quot;linear&quot;):    if not weights:        print(&quot;[!] AVE_WGT&quot;)        weights = [1./ len(predictions) for _ in range(len(predictions))]    assert len(predictions) == len(weights)    if np.sum(weights) != 1.0:        weights = [w / np.sum(weights) for w in weights]    print(&quot;[!] weights = {}&quot;.format(weights))    assert np.isclose(np.sum(weights), 1.0)    if type_ == &quot;linear&quot;:        res = np.average(predictions, weights=weights, axis=0)    elif type_ == &quot;harmonic&quot;:        res = np.average([1 / p for p in predictions], weights=weights, axis=0)        return 1 / res    elif type_ == &quot;geometric&quot;:        numerator = np.average(            [np.log(p) for p in predictions], weights=weights, axis=0        )        res = np.exp(numerator / sum(weights))        return res    elif type_ == &quot;rank&quot;:        from scipy.stats import rankdata        res = np.average([rankdata(p) for p in predictions], weights=weights, axis=0)        return res / (len(res) + 1)    return res    def merge(prob, number=-1, index=0):        from copy import deepcopy        new_prob = deepcopy(prob)        top = np.argsort(prob[:, index])[::-1][: number]        print(top[: 4])        for i in range(len(new_prob)):            pad_value = np.array([0, 0, 0])            pad_value[index] = 1            if i in top:                new_prob[i, ] = pad_value            else:                new_prob[i, index] = 0.        return new_probtest_pred_prob = ensemble_predictions(test_preds)test_pred = test_pred_prob.argmax(axis=1)test_pro = test_label[[&apos;ship&apos;]]test_pro[&apos;pro_1&apos;] = test_pred_prob[:,0]test_pro[&apos;pro_2&apos;] = test_pred_prob[:,1]test_pro[&apos;pro_3&apos;] = test_pred_prob[:,2]pred_pro = merge(test_pro[[&apos;pro_1&apos;, &apos;pro_2&apos;, &apos;pro_3&apos;]].values, 900,0)test_pred = pred_pro.argmax(axis=1)test_data = test_label[[&apos;ship&apos;]]test_data[&quot;label&quot;] = test_predtest_data[&quot;label&quot;] = test_data[&quot;label&quot;].map({0:&apos;围网&apos;,1:&apos;刺网&apos;,2:&apos;拖网&apos;})# test_data[&apos;label&apos;][:100] = &apos;刺网&apos;test_data[[&quot;ship&quot;, &quot;label&quot;]].to_csv(&quot;result.csv&quot;, index=False, header=None)print(test_data[&quot;label&quot;].value_counts())print(&apos;runtime:&apos;, time.time() - start_t)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2020-5-30-赛题解读&quot;&gt;&lt;a href=&quot;#2020-5-30-赛题解读&quot; class=&quot;headerlink&quot; title=&quot;2020.5.30 赛题解读&quot;&gt;&lt;/a&gt;2020.5.30 赛题解读&lt;/h2&gt;&lt;h3 id=&quot;赛题背景：渔船作业分类&quot;&gt;&lt;a href=&quot;#赛题背景：渔船作业分类&quot; class=&quot;headerlink&quot; title=&quot;赛题背景：渔船作业分类&quot;&gt;&lt;/a&gt;赛题背景：渔船作业分类&lt;/h3&gt;&lt;p&gt;本赛题基于位置数据对海上目标进行智能识别和作业行为分析，要求选手通过分析渔船北斗设备位置数据，得出该船的生产作业行为，具体判断出是拖网作业、围网作业还是流刺网作业。初赛将提供11000条(其中7000条训练数据、2000条testA、2000条testB)渔船轨迹北斗数据。&lt;/p&gt;
    
    </summary>
    
    
      <category term="竞赛" scheme="https://liangggggg.github.io/categories/%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="算法竞赛" scheme="https://liangggggg.github.io/tags/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"/>
    
  </entry>
  
</feed>
